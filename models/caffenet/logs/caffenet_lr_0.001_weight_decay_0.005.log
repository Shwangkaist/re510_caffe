I0522 10:13:13.023319 19861 upgrade_proto.cpp:1113] snapshot_prefix was a directory and is replaced to ./data/trained_models/caffenet/solver
I0522 10:13:13.025064 19861 caffe.cpp:204] Using GPUs 0
I0522 10:13:13.040637 19861 caffe.cpp:209] GPU 0: TITAN RTX
I0522 10:13:13.495944 19861 solver.cpp:45] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.001
display: 20
max_iter: 80000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 20000
snapshot: 10000
snapshot_prefix: "./data/trained_models/caffenet/solver"
solver_mode: GPU
device_id: 0
net: "./models/caffenet/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I0522 10:13:13.517989 19861 solver.cpp:102] Creating training net from net file: ./models/caffenet/train_val.prototxt
I0522 10:13:13.518707 19861 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0522 10:13:13.518720 19861 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 10:13:13.518854 19861 net.cpp:53] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 200
    mean_file: "./data/mean_lmdb_train/gtsrb_train_mean.binaryproto"
  }
  data_param {
    source: "./data/lmdb_train"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 43
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0522 10:13:13.518961 19861 layer_factory.hpp:77] Creating layer data
I0522 10:13:13.523380 19861 db_lmdb.cpp:35] Opened lmdb ./data/lmdb_train
I0522 10:13:13.547868 19861 net.cpp:86] Creating Layer data
I0522 10:13:13.547879 19861 net.cpp:382] data -> data
I0522 10:13:13.547909 19861 net.cpp:382] data -> label
I0522 10:13:13.547936 19861 data_transformer.cpp:25] Loading mean file from: ./data/mean_lmdb_train/gtsrb_train_mean.binaryproto
I0522 10:13:13.579526 19861 data_layer.cpp:45] output data size: 256,3,200,200
I0522 10:13:13.872265 19861 net.cpp:124] Setting up data
I0522 10:13:13.872306 19861 net.cpp:131] Top shape: 256 3 200 200 (30720000)
I0522 10:13:13.872310 19861 net.cpp:131] Top shape: 256 (256)
I0522 10:13:13.872313 19861 net.cpp:139] Memory required for data: 122881024
I0522 10:13:13.872324 19861 layer_factory.hpp:77] Creating layer conv1
I0522 10:13:13.872354 19861 net.cpp:86] Creating Layer conv1
I0522 10:13:13.872359 19861 net.cpp:408] conv1 <- data
I0522 10:13:13.872375 19861 net.cpp:382] conv1 -> conv1
I0522 10:13:15.222851 19861 net.cpp:124] Setting up conv1
I0522 10:13:15.222883 19861 net.cpp:131] Top shape: 256 96 48 48 (56623104)
I0522 10:13:15.222887 19861 net.cpp:139] Memory required for data: 349373440
I0522 10:13:15.222909 19861 layer_factory.hpp:77] Creating layer relu1
I0522 10:13:15.222920 19861 net.cpp:86] Creating Layer relu1
I0522 10:13:15.222923 19861 net.cpp:408] relu1 <- conv1
I0522 10:13:15.222929 19861 net.cpp:369] relu1 -> conv1 (in-place)
I0522 10:13:15.223349 19861 net.cpp:124] Setting up relu1
I0522 10:13:15.223357 19861 net.cpp:131] Top shape: 256 96 48 48 (56623104)
I0522 10:13:15.223361 19861 net.cpp:139] Memory required for data: 575865856
I0522 10:13:15.223362 19861 layer_factory.hpp:77] Creating layer pool1
I0522 10:13:15.223367 19861 net.cpp:86] Creating Layer pool1
I0522 10:13:15.223369 19861 net.cpp:408] pool1 <- conv1
I0522 10:13:15.223373 19861 net.cpp:382] pool1 -> pool1
I0522 10:13:15.223410 19861 net.cpp:124] Setting up pool1
I0522 10:13:15.223417 19861 net.cpp:131] Top shape: 256 96 24 24 (14155776)
I0522 10:13:15.223418 19861 net.cpp:139] Memory required for data: 632488960
I0522 10:13:15.223420 19861 layer_factory.hpp:77] Creating layer norm1
I0522 10:13:15.223429 19861 net.cpp:86] Creating Layer norm1
I0522 10:13:15.223453 19861 net.cpp:408] norm1 <- pool1
I0522 10:13:15.223456 19861 net.cpp:382] norm1 -> norm1
I0522 10:13:15.223878 19861 net.cpp:124] Setting up norm1
I0522 10:13:15.223886 19861 net.cpp:131] Top shape: 256 96 24 24 (14155776)
I0522 10:13:15.223888 19861 net.cpp:139] Memory required for data: 689112064
I0522 10:13:15.223891 19861 layer_factory.hpp:77] Creating layer conv2
I0522 10:13:15.223901 19861 net.cpp:86] Creating Layer conv2
I0522 10:13:15.223903 19861 net.cpp:408] conv2 <- norm1
I0522 10:13:15.223907 19861 net.cpp:382] conv2 -> conv2
I0522 10:13:15.231047 19861 net.cpp:124] Setting up conv2
I0522 10:13:15.231060 19861 net.cpp:131] Top shape: 256 256 24 24 (37748736)
I0522 10:13:15.231062 19861 net.cpp:139] Memory required for data: 840107008
I0522 10:13:15.231070 19861 layer_factory.hpp:77] Creating layer relu2
I0522 10:13:15.231074 19861 net.cpp:86] Creating Layer relu2
I0522 10:13:15.231076 19861 net.cpp:408] relu2 <- conv2
I0522 10:13:15.231081 19861 net.cpp:369] relu2 -> conv2 (in-place)
I0522 10:13:15.231487 19861 net.cpp:124] Setting up relu2
I0522 10:13:15.231496 19861 net.cpp:131] Top shape: 256 256 24 24 (37748736)
I0522 10:13:15.231498 19861 net.cpp:139] Memory required for data: 991101952
I0522 10:13:15.231500 19861 layer_factory.hpp:77] Creating layer pool2
I0522 10:13:15.231504 19861 net.cpp:86] Creating Layer pool2
I0522 10:13:15.231506 19861 net.cpp:408] pool2 <- conv2
I0522 10:13:15.231510 19861 net.cpp:382] pool2 -> pool2
I0522 10:13:15.231539 19861 net.cpp:124] Setting up pool2
I0522 10:13:15.231542 19861 net.cpp:131] Top shape: 256 256 12 12 (9437184)
I0522 10:13:15.231544 19861 net.cpp:139] Memory required for data: 1028850688
I0522 10:13:15.231546 19861 layer_factory.hpp:77] Creating layer norm2
I0522 10:13:15.231554 19861 net.cpp:86] Creating Layer norm2
I0522 10:13:15.231556 19861 net.cpp:408] norm2 <- pool2
I0522 10:13:15.231559 19861 net.cpp:382] norm2 -> norm2
I0522 10:13:15.231837 19861 net.cpp:124] Setting up norm2
I0522 10:13:15.231842 19861 net.cpp:131] Top shape: 256 256 12 12 (9437184)
I0522 10:13:15.231844 19861 net.cpp:139] Memory required for data: 1066599424
I0522 10:13:15.231846 19861 layer_factory.hpp:77] Creating layer conv3
I0522 10:13:15.231853 19861 net.cpp:86] Creating Layer conv3
I0522 10:13:15.231855 19861 net.cpp:408] conv3 <- norm2
I0522 10:13:15.231859 19861 net.cpp:382] conv3 -> conv3
I0522 10:13:15.242163 19861 net.cpp:124] Setting up conv3
I0522 10:13:15.242177 19861 net.cpp:131] Top shape: 256 384 12 12 (14155776)
I0522 10:13:15.242178 19861 net.cpp:139] Memory required for data: 1123222528
I0522 10:13:15.242185 19861 layer_factory.hpp:77] Creating layer relu3
I0522 10:13:15.242189 19861 net.cpp:86] Creating Layer relu3
I0522 10:13:15.242192 19861 net.cpp:408] relu3 <- conv3
I0522 10:13:15.242197 19861 net.cpp:369] relu3 -> conv3 (in-place)
I0522 10:13:15.242470 19861 net.cpp:124] Setting up relu3
I0522 10:13:15.242476 19861 net.cpp:131] Top shape: 256 384 12 12 (14155776)
I0522 10:13:15.242478 19861 net.cpp:139] Memory required for data: 1179845632
I0522 10:13:15.242480 19861 layer_factory.hpp:77] Creating layer conv4
I0522 10:13:15.242487 19861 net.cpp:86] Creating Layer conv4
I0522 10:13:15.242489 19861 net.cpp:408] conv4 <- conv3
I0522 10:13:15.242493 19861 net.cpp:382] conv4 -> conv4
I0522 10:13:15.254312 19861 net.cpp:124] Setting up conv4
I0522 10:13:15.254420 19861 net.cpp:131] Top shape: 256 384 12 12 (14155776)
I0522 10:13:15.254428 19861 net.cpp:139] Memory required for data: 1236468736
I0522 10:13:15.254437 19861 layer_factory.hpp:77] Creating layer relu4
I0522 10:13:15.254448 19861 net.cpp:86] Creating Layer relu4
I0522 10:13:15.254452 19861 net.cpp:408] relu4 <- conv4
I0522 10:13:15.254459 19861 net.cpp:369] relu4 -> conv4 (in-place)
I0522 10:13:15.254930 19861 net.cpp:124] Setting up relu4
I0522 10:13:15.254940 19861 net.cpp:131] Top shape: 256 384 12 12 (14155776)
I0522 10:13:15.254942 19861 net.cpp:139] Memory required for data: 1293091840
I0522 10:13:15.254945 19861 layer_factory.hpp:77] Creating layer conv5
I0522 10:13:15.254985 19861 net.cpp:86] Creating Layer conv5
I0522 10:13:15.254988 19861 net.cpp:408] conv5 <- conv4
I0522 10:13:15.254994 19861 net.cpp:382] conv5 -> conv5
I0522 10:13:15.263984 19861 net.cpp:124] Setting up conv5
I0522 10:13:15.263998 19861 net.cpp:131] Top shape: 256 256 12 12 (9437184)
I0522 10:13:15.264001 19861 net.cpp:139] Memory required for data: 1330840576
I0522 10:13:15.264014 19861 layer_factory.hpp:77] Creating layer relu5
I0522 10:13:15.264019 19861 net.cpp:86] Creating Layer relu5
I0522 10:13:15.264021 19861 net.cpp:408] relu5 <- conv5
I0522 10:13:15.264026 19861 net.cpp:369] relu5 -> conv5 (in-place)
I0522 10:13:15.264425 19861 net.cpp:124] Setting up relu5
I0522 10:13:15.264432 19861 net.cpp:131] Top shape: 256 256 12 12 (9437184)
I0522 10:13:15.264434 19861 net.cpp:139] Memory required for data: 1368589312
I0522 10:13:15.264437 19861 layer_factory.hpp:77] Creating layer pool5
I0522 10:13:15.264442 19861 net.cpp:86] Creating Layer pool5
I0522 10:13:15.264444 19861 net.cpp:408] pool5 <- conv5
I0522 10:13:15.264448 19861 net.cpp:382] pool5 -> pool5
I0522 10:13:15.264479 19861 net.cpp:124] Setting up pool5
I0522 10:13:15.264484 19861 net.cpp:131] Top shape: 256 256 6 6 (2359296)
I0522 10:13:15.264487 19861 net.cpp:139] Memory required for data: 1378026496
I0522 10:13:15.264488 19861 layer_factory.hpp:77] Creating layer fc6
I0522 10:13:15.264495 19861 net.cpp:86] Creating Layer fc6
I0522 10:13:15.264497 19861 net.cpp:408] fc6 <- pool5
I0522 10:13:15.264501 19861 net.cpp:382] fc6 -> fc6
I0522 10:13:15.577294 19861 net.cpp:124] Setting up fc6
I0522 10:13:15.577338 19861 net.cpp:131] Top shape: 256 4096 (1048576)
I0522 10:13:15.577340 19861 net.cpp:139] Memory required for data: 1382220800
I0522 10:13:15.577353 19861 layer_factory.hpp:77] Creating layer relu6
I0522 10:13:15.577364 19861 net.cpp:86] Creating Layer relu6
I0522 10:13:15.577368 19861 net.cpp:408] relu6 <- fc6
I0522 10:13:15.577374 19861 net.cpp:369] relu6 -> fc6 (in-place)
I0522 10:13:15.577822 19861 net.cpp:124] Setting up relu6
I0522 10:13:15.577836 19861 net.cpp:131] Top shape: 256 4096 (1048576)
I0522 10:13:15.577837 19861 net.cpp:139] Memory required for data: 1386415104
I0522 10:13:15.577839 19861 layer_factory.hpp:77] Creating layer drop6
I0522 10:13:15.577847 19861 net.cpp:86] Creating Layer drop6
I0522 10:13:15.577848 19861 net.cpp:408] drop6 <- fc6
I0522 10:13:15.577852 19861 net.cpp:369] drop6 -> fc6 (in-place)
I0522 10:13:15.577878 19861 net.cpp:124] Setting up drop6
I0522 10:13:15.577883 19861 net.cpp:131] Top shape: 256 4096 (1048576)
I0522 10:13:15.577885 19861 net.cpp:139] Memory required for data: 1390609408
I0522 10:13:15.577888 19861 layer_factory.hpp:77] Creating layer fc7
I0522 10:13:15.577893 19861 net.cpp:86] Creating Layer fc7
I0522 10:13:15.577895 19861 net.cpp:408] fc7 <- fc6
I0522 10:13:15.577898 19861 net.cpp:382] fc7 -> fc7
I0522 10:13:15.700171 19861 net.cpp:124] Setting up fc7
I0522 10:13:15.700214 19861 net.cpp:131] Top shape: 256 4096 (1048576)
I0522 10:13:15.700217 19861 net.cpp:139] Memory required for data: 1394803712
I0522 10:13:15.700232 19861 layer_factory.hpp:77] Creating layer relu7
I0522 10:13:15.700245 19861 net.cpp:86] Creating Layer relu7
I0522 10:13:15.700248 19861 net.cpp:408] relu7 <- fc7
I0522 10:13:15.700256 19861 net.cpp:369] relu7 -> fc7 (in-place)
I0522 10:13:15.701084 19861 net.cpp:124] Setting up relu7
I0522 10:13:15.701099 19861 net.cpp:131] Top shape: 256 4096 (1048576)
I0522 10:13:15.701102 19861 net.cpp:139] Memory required for data: 1398998016
I0522 10:13:15.701103 19861 layer_factory.hpp:77] Creating layer drop7
I0522 10:13:15.701112 19861 net.cpp:86] Creating Layer drop7
I0522 10:13:15.701113 19861 net.cpp:408] drop7 <- fc7
I0522 10:13:15.701117 19861 net.cpp:369] drop7 -> fc7 (in-place)
I0522 10:13:15.701135 19861 net.cpp:124] Setting up drop7
I0522 10:13:15.701139 19861 net.cpp:131] Top shape: 256 4096 (1048576)
I0522 10:13:15.701141 19861 net.cpp:139] Memory required for data: 1403192320
I0522 10:13:15.701143 19861 layer_factory.hpp:77] Creating layer fc8
I0522 10:13:15.701149 19861 net.cpp:86] Creating Layer fc8
I0522 10:13:15.701185 19861 net.cpp:408] fc8 <- fc7
I0522 10:13:15.701189 19861 net.cpp:382] fc8 -> fc8
I0522 10:13:15.703109 19861 net.cpp:124] Setting up fc8
I0522 10:13:15.703115 19861 net.cpp:131] Top shape: 256 43 (11008)
I0522 10:13:15.703117 19861 net.cpp:139] Memory required for data: 1403236352
I0522 10:13:15.703120 19861 layer_factory.hpp:77] Creating layer loss
I0522 10:13:15.703125 19861 net.cpp:86] Creating Layer loss
I0522 10:13:15.703126 19861 net.cpp:408] loss <- fc8
I0522 10:13:15.703128 19861 net.cpp:408] loss <- label
I0522 10:13:15.703135 19861 net.cpp:382] loss -> loss
I0522 10:13:15.703150 19861 layer_factory.hpp:77] Creating layer loss
I0522 10:13:15.703593 19861 net.cpp:124] Setting up loss
I0522 10:13:15.703600 19861 net.cpp:131] Top shape: (1)
I0522 10:13:15.703603 19861 net.cpp:134]     with loss weight 1
I0522 10:13:15.703630 19861 net.cpp:139] Memory required for data: 1403236356
I0522 10:13:15.703632 19861 net.cpp:200] loss needs backward computation.
I0522 10:13:15.703639 19861 net.cpp:200] fc8 needs backward computation.
I0522 10:13:15.703642 19861 net.cpp:200] drop7 needs backward computation.
I0522 10:13:15.703644 19861 net.cpp:200] relu7 needs backward computation.
I0522 10:13:15.703645 19861 net.cpp:200] fc7 needs backward computation.
I0522 10:13:15.703647 19861 net.cpp:200] drop6 needs backward computation.
I0522 10:13:15.703649 19861 net.cpp:200] relu6 needs backward computation.
I0522 10:13:15.703651 19861 net.cpp:200] fc6 needs backward computation.
I0522 10:13:15.703653 19861 net.cpp:200] pool5 needs backward computation.
I0522 10:13:15.703655 19861 net.cpp:200] relu5 needs backward computation.
I0522 10:13:15.703657 19861 net.cpp:200] conv5 needs backward computation.
I0522 10:13:15.703660 19861 net.cpp:200] relu4 needs backward computation.
I0522 10:13:15.703661 19861 net.cpp:200] conv4 needs backward computation.
I0522 10:13:15.703663 19861 net.cpp:200] relu3 needs backward computation.
I0522 10:13:15.703665 19861 net.cpp:200] conv3 needs backward computation.
I0522 10:13:15.703668 19861 net.cpp:200] norm2 needs backward computation.
I0522 10:13:15.703670 19861 net.cpp:200] pool2 needs backward computation.
I0522 10:13:15.703672 19861 net.cpp:200] relu2 needs backward computation.
I0522 10:13:15.703675 19861 net.cpp:200] conv2 needs backward computation.
I0522 10:13:15.703676 19861 net.cpp:200] norm1 needs backward computation.
I0522 10:13:15.703678 19861 net.cpp:200] pool1 needs backward computation.
I0522 10:13:15.703680 19861 net.cpp:200] relu1 needs backward computation.
I0522 10:13:15.703682 19861 net.cpp:200] conv1 needs backward computation.
I0522 10:13:15.703685 19861 net.cpp:202] data does not need backward computation.
I0522 10:13:15.703685 19861 net.cpp:244] This network produces output loss
I0522 10:13:15.703696 19861 net.cpp:257] Network initialization done.
I0522 10:13:15.703989 19861 solver.cpp:190] Creating test net (#0) specified by net file: ./models/caffenet/train_val.prototxt
I0522 10:13:15.704015 19861 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0522 10:13:15.704142 19861 net.cpp:53] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 200
    mean_file: "./data/mean_lmdb_test/gtsrb_test_mean.binaryproto"
  }
  data_param {
    source: "./data/lmdb_test"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 43
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0522 10:13:15.704228 19861 layer_factory.hpp:77] Creating layer data
I0522 10:13:15.725585 19861 db_lmdb.cpp:35] Opened lmdb ./data/lmdb_test
I0522 10:13:15.736191 19861 net.cpp:86] Creating Layer data
I0522 10:13:15.736198 19861 net.cpp:382] data -> data
I0522 10:13:15.736204 19861 net.cpp:382] data -> label
I0522 10:13:15.736212 19861 data_transformer.cpp:25] Loading mean file from: ./data/mean_lmdb_test/gtsrb_test_mean.binaryproto
I0522 10:13:15.742934 19861 data_layer.cpp:45] output data size: 50,3,200,200
I0522 10:13:15.809114 19861 net.cpp:124] Setting up data
I0522 10:13:15.809149 19861 net.cpp:131] Top shape: 50 3 200 200 (6000000)
I0522 10:13:15.809152 19861 net.cpp:131] Top shape: 50 (50)
I0522 10:13:15.809154 19861 net.cpp:139] Memory required for data: 24000200
I0522 10:13:15.809161 19861 layer_factory.hpp:77] Creating layer label_data_1_split
I0522 10:13:15.809175 19861 net.cpp:86] Creating Layer label_data_1_split
I0522 10:13:15.809178 19861 net.cpp:408] label_data_1_split <- label
I0522 10:13:15.809185 19861 net.cpp:382] label_data_1_split -> label_data_1_split_0
I0522 10:13:15.809195 19861 net.cpp:382] label_data_1_split -> label_data_1_split_1
I0522 10:13:15.809413 19861 net.cpp:124] Setting up label_data_1_split
I0522 10:13:15.809419 19861 net.cpp:131] Top shape: 50 (50)
I0522 10:13:15.809422 19861 net.cpp:131] Top shape: 50 (50)
I0522 10:13:15.809424 19861 net.cpp:139] Memory required for data: 24000600
I0522 10:13:15.809427 19861 layer_factory.hpp:77] Creating layer conv1
I0522 10:13:15.809442 19861 net.cpp:86] Creating Layer conv1
I0522 10:13:15.809442 19861 net.cpp:408] conv1 <- data
I0522 10:13:15.809449 19861 net.cpp:382] conv1 -> conv1
I0522 10:13:15.813156 19861 net.cpp:124] Setting up conv1
I0522 10:13:15.813167 19861 net.cpp:131] Top shape: 50 96 48 48 (11059200)
I0522 10:13:15.813169 19861 net.cpp:139] Memory required for data: 68237400
I0522 10:13:15.813177 19861 layer_factory.hpp:77] Creating layer relu1
I0522 10:13:15.813181 19861 net.cpp:86] Creating Layer relu1
I0522 10:13:15.813184 19861 net.cpp:408] relu1 <- conv1
I0522 10:13:15.813186 19861 net.cpp:369] relu1 -> conv1 (in-place)
I0522 10:13:15.813504 19861 net.cpp:124] Setting up relu1
I0522 10:13:15.813513 19861 net.cpp:131] Top shape: 50 96 48 48 (11059200)
I0522 10:13:15.813514 19861 net.cpp:139] Memory required for data: 112474200
I0522 10:13:15.813516 19861 layer_factory.hpp:77] Creating layer pool1
I0522 10:13:15.813521 19861 net.cpp:86] Creating Layer pool1
I0522 10:13:15.813524 19861 net.cpp:408] pool1 <- conv1
I0522 10:13:15.813526 19861 net.cpp:382] pool1 -> pool1
I0522 10:13:15.813552 19861 net.cpp:124] Setting up pool1
I0522 10:13:15.813556 19861 net.cpp:131] Top shape: 50 96 24 24 (2764800)
I0522 10:13:15.813558 19861 net.cpp:139] Memory required for data: 123533400
I0522 10:13:15.813560 19861 layer_factory.hpp:77] Creating layer norm1
I0522 10:13:15.813565 19861 net.cpp:86] Creating Layer norm1
I0522 10:13:15.813567 19861 net.cpp:408] norm1 <- pool1
I0522 10:13:15.813570 19861 net.cpp:382] norm1 -> norm1
I0522 10:13:15.813889 19861 net.cpp:124] Setting up norm1
I0522 10:13:15.813896 19861 net.cpp:131] Top shape: 50 96 24 24 (2764800)
I0522 10:13:15.813897 19861 net.cpp:139] Memory required for data: 134592600
I0522 10:13:15.813899 19861 layer_factory.hpp:77] Creating layer conv2
I0522 10:13:15.813905 19861 net.cpp:86] Creating Layer conv2
I0522 10:13:15.813906 19861 net.cpp:408] conv2 <- norm1
I0522 10:13:15.813910 19861 net.cpp:382] conv2 -> conv2
I0522 10:13:15.820705 19861 net.cpp:124] Setting up conv2
I0522 10:13:15.820715 19861 net.cpp:131] Top shape: 50 256 24 24 (7372800)
I0522 10:13:15.820717 19861 net.cpp:139] Memory required for data: 164083800
I0522 10:13:15.820724 19861 layer_factory.hpp:77] Creating layer relu2
I0522 10:13:15.820727 19861 net.cpp:86] Creating Layer relu2
I0522 10:13:15.820729 19861 net.cpp:408] relu2 <- conv2
I0522 10:13:15.820731 19861 net.cpp:369] relu2 -> conv2 (in-place)
I0522 10:13:15.821125 19861 net.cpp:124] Setting up relu2
I0522 10:13:15.821149 19861 net.cpp:131] Top shape: 50 256 24 24 (7372800)
I0522 10:13:15.821151 19861 net.cpp:139] Memory required for data: 193575000
I0522 10:13:15.821153 19861 layer_factory.hpp:77] Creating layer pool2
I0522 10:13:15.821158 19861 net.cpp:86] Creating Layer pool2
I0522 10:13:15.821159 19861 net.cpp:408] pool2 <- conv2
I0522 10:13:15.821163 19861 net.cpp:382] pool2 -> pool2
I0522 10:13:15.821187 19861 net.cpp:124] Setting up pool2
I0522 10:13:15.821190 19861 net.cpp:131] Top shape: 50 256 12 12 (1843200)
I0522 10:13:15.821192 19861 net.cpp:139] Memory required for data: 200947800
I0522 10:13:15.821193 19861 layer_factory.hpp:77] Creating layer norm2
I0522 10:13:15.821197 19861 net.cpp:86] Creating Layer norm2
I0522 10:13:15.821198 19861 net.cpp:408] norm2 <- pool2
I0522 10:13:15.821200 19861 net.cpp:382] norm2 -> norm2
I0522 10:13:15.821409 19861 net.cpp:124] Setting up norm2
I0522 10:13:15.821414 19861 net.cpp:131] Top shape: 50 256 12 12 (1843200)
I0522 10:13:15.821416 19861 net.cpp:139] Memory required for data: 208320600
I0522 10:13:15.821418 19861 layer_factory.hpp:77] Creating layer conv3
I0522 10:13:15.821422 19861 net.cpp:86] Creating Layer conv3
I0522 10:13:15.821424 19861 net.cpp:408] conv3 <- norm2
I0522 10:13:15.821427 19861 net.cpp:382] conv3 -> conv3
I0522 10:13:15.830289 19861 net.cpp:124] Setting up conv3
I0522 10:13:15.830305 19861 net.cpp:131] Top shape: 50 384 12 12 (2764800)
I0522 10:13:15.830307 19861 net.cpp:139] Memory required for data: 219379800
I0522 10:13:15.830313 19861 layer_factory.hpp:77] Creating layer relu3
I0522 10:13:15.830318 19861 net.cpp:86] Creating Layer relu3
I0522 10:13:15.830320 19861 net.cpp:408] relu3 <- conv3
I0522 10:13:15.830324 19861 net.cpp:369] relu3 -> conv3 (in-place)
I0522 10:13:15.830746 19861 net.cpp:124] Setting up relu3
I0522 10:13:15.830754 19861 net.cpp:131] Top shape: 50 384 12 12 (2764800)
I0522 10:13:15.830755 19861 net.cpp:139] Memory required for data: 230439000
I0522 10:13:15.830757 19861 layer_factory.hpp:77] Creating layer conv4
I0522 10:13:15.830763 19861 net.cpp:86] Creating Layer conv4
I0522 10:13:15.830765 19861 net.cpp:408] conv4 <- conv3
I0522 10:13:15.830768 19861 net.cpp:382] conv4 -> conv4
I0522 10:13:15.838115 19861 net.cpp:124] Setting up conv4
I0522 10:13:15.838127 19861 net.cpp:131] Top shape: 50 384 12 12 (2764800)
I0522 10:13:15.838129 19861 net.cpp:139] Memory required for data: 241498200
I0522 10:13:15.838133 19861 layer_factory.hpp:77] Creating layer relu4
I0522 10:13:15.838138 19861 net.cpp:86] Creating Layer relu4
I0522 10:13:15.838140 19861 net.cpp:408] relu4 <- conv4
I0522 10:13:15.838143 19861 net.cpp:369] relu4 -> conv4 (in-place)
I0522 10:13:15.838605 19861 net.cpp:124] Setting up relu4
I0522 10:13:15.838614 19861 net.cpp:131] Top shape: 50 384 12 12 (2764800)
I0522 10:13:15.838616 19861 net.cpp:139] Memory required for data: 252557400
I0522 10:13:15.838618 19861 layer_factory.hpp:77] Creating layer conv5
I0522 10:13:15.838626 19861 net.cpp:86] Creating Layer conv5
I0522 10:13:15.838627 19861 net.cpp:408] conv5 <- conv4
I0522 10:13:15.838631 19861 net.cpp:382] conv5 -> conv5
I0522 10:13:15.850780 19861 net.cpp:124] Setting up conv5
I0522 10:13:15.850795 19861 net.cpp:131] Top shape: 50 256 12 12 (1843200)
I0522 10:13:15.850796 19861 net.cpp:139] Memory required for data: 259930200
I0522 10:13:15.850805 19861 layer_factory.hpp:77] Creating layer relu5
I0522 10:13:15.850811 19861 net.cpp:86] Creating Layer relu5
I0522 10:13:15.850813 19861 net.cpp:408] relu5 <- conv5
I0522 10:13:15.850816 19861 net.cpp:369] relu5 -> conv5 (in-place)
I0522 10:13:15.851218 19861 net.cpp:124] Setting up relu5
I0522 10:13:15.851227 19861 net.cpp:131] Top shape: 50 256 12 12 (1843200)
I0522 10:13:15.851227 19861 net.cpp:139] Memory required for data: 267303000
I0522 10:13:15.851229 19861 layer_factory.hpp:77] Creating layer pool5
I0522 10:13:15.851236 19861 net.cpp:86] Creating Layer pool5
I0522 10:13:15.851238 19861 net.cpp:408] pool5 <- conv5
I0522 10:13:15.851241 19861 net.cpp:382] pool5 -> pool5
I0522 10:13:15.851269 19861 net.cpp:124] Setting up pool5
I0522 10:13:15.851290 19861 net.cpp:131] Top shape: 50 256 6 6 (460800)
I0522 10:13:15.851292 19861 net.cpp:139] Memory required for data: 269146200
I0522 10:13:15.851294 19861 layer_factory.hpp:77] Creating layer fc6
I0522 10:13:15.851300 19861 net.cpp:86] Creating Layer fc6
I0522 10:13:15.851300 19861 net.cpp:408] fc6 <- pool5
I0522 10:13:15.851303 19861 net.cpp:382] fc6 -> fc6
I0522 10:13:16.188848 19861 net.cpp:124] Setting up fc6
I0522 10:13:16.188895 19861 net.cpp:131] Top shape: 50 4096 (204800)
I0522 10:13:16.188897 19861 net.cpp:139] Memory required for data: 269965400
I0522 10:13:16.188912 19861 layer_factory.hpp:77] Creating layer relu6
I0522 10:13:16.188925 19861 net.cpp:86] Creating Layer relu6
I0522 10:13:16.188930 19861 net.cpp:408] relu6 <- fc6
I0522 10:13:16.188937 19861 net.cpp:369] relu6 -> fc6 (in-place)
I0522 10:13:16.189972 19861 net.cpp:124] Setting up relu6
I0522 10:13:16.189986 19861 net.cpp:131] Top shape: 50 4096 (204800)
I0522 10:13:16.189988 19861 net.cpp:139] Memory required for data: 270784600
I0522 10:13:16.189991 19861 layer_factory.hpp:77] Creating layer drop6
I0522 10:13:16.190001 19861 net.cpp:86] Creating Layer drop6
I0522 10:13:16.190001 19861 net.cpp:408] drop6 <- fc6
I0522 10:13:16.190006 19861 net.cpp:369] drop6 -> fc6 (in-place)
I0522 10:13:16.190026 19861 net.cpp:124] Setting up drop6
I0522 10:13:16.190028 19861 net.cpp:131] Top shape: 50 4096 (204800)
I0522 10:13:16.190029 19861 net.cpp:139] Memory required for data: 271603800
I0522 10:13:16.190032 19861 layer_factory.hpp:77] Creating layer fc7
I0522 10:13:16.190038 19861 net.cpp:86] Creating Layer fc7
I0522 10:13:16.190039 19861 net.cpp:408] fc7 <- fc6
I0522 10:13:16.190043 19861 net.cpp:382] fc7 -> fc7
I0522 10:13:16.331663 19861 net.cpp:124] Setting up fc7
I0522 10:13:16.331722 19861 net.cpp:131] Top shape: 50 4096 (204800)
I0522 10:13:16.331724 19861 net.cpp:139] Memory required for data: 272423000
I0522 10:13:16.331738 19861 layer_factory.hpp:77] Creating layer relu7
I0522 10:13:16.331758 19861 net.cpp:86] Creating Layer relu7
I0522 10:13:16.331761 19861 net.cpp:408] relu7 <- fc7
I0522 10:13:16.331770 19861 net.cpp:369] relu7 -> fc7 (in-place)
I0522 10:13:16.332387 19861 net.cpp:124] Setting up relu7
I0522 10:13:16.332403 19861 net.cpp:131] Top shape: 50 4096 (204800)
I0522 10:13:16.332406 19861 net.cpp:139] Memory required for data: 273242200
I0522 10:13:16.332407 19861 layer_factory.hpp:77] Creating layer drop7
I0522 10:13:16.332415 19861 net.cpp:86] Creating Layer drop7
I0522 10:13:16.332417 19861 net.cpp:408] drop7 <- fc7
I0522 10:13:16.332422 19861 net.cpp:369] drop7 -> fc7 (in-place)
I0522 10:13:16.332442 19861 net.cpp:124] Setting up drop7
I0522 10:13:16.332444 19861 net.cpp:131] Top shape: 50 4096 (204800)
I0522 10:13:16.332446 19861 net.cpp:139] Memory required for data: 274061400
I0522 10:13:16.332448 19861 layer_factory.hpp:77] Creating layer fc8
I0522 10:13:16.332455 19861 net.cpp:86] Creating Layer fc8
I0522 10:13:16.332458 19861 net.cpp:408] fc8 <- fc7
I0522 10:13:16.332460 19861 net.cpp:382] fc8 -> fc8
I0522 10:13:16.333622 19861 net.cpp:124] Setting up fc8
I0522 10:13:16.333631 19861 net.cpp:131] Top shape: 50 43 (2150)
I0522 10:13:16.333632 19861 net.cpp:139] Memory required for data: 274070000
I0522 10:13:16.333636 19861 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0522 10:13:16.333642 19861 net.cpp:86] Creating Layer fc8_fc8_0_split
I0522 10:13:16.333642 19861 net.cpp:408] fc8_fc8_0_split <- fc8
I0522 10:13:16.333647 19861 net.cpp:382] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0522 10:13:16.333649 19861 net.cpp:382] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0522 10:13:16.333669 19861 net.cpp:124] Setting up fc8_fc8_0_split
I0522 10:13:16.333673 19861 net.cpp:131] Top shape: 50 43 (2150)
I0522 10:13:16.333675 19861 net.cpp:131] Top shape: 50 43 (2150)
I0522 10:13:16.333676 19861 net.cpp:139] Memory required for data: 274087200
I0522 10:13:16.333678 19861 layer_factory.hpp:77] Creating layer accuracy
I0522 10:13:16.333683 19861 net.cpp:86] Creating Layer accuracy
I0522 10:13:16.333714 19861 net.cpp:408] accuracy <- fc8_fc8_0_split_0
I0522 10:13:16.333715 19861 net.cpp:408] accuracy <- label_data_1_split_0
I0522 10:13:16.333719 19861 net.cpp:382] accuracy -> accuracy
I0522 10:13:16.333724 19861 net.cpp:124] Setting up accuracy
I0522 10:13:16.333727 19861 net.cpp:131] Top shape: (1)
I0522 10:13:16.333729 19861 net.cpp:139] Memory required for data: 274087204
I0522 10:13:16.333730 19861 layer_factory.hpp:77] Creating layer loss
I0522 10:13:16.333734 19861 net.cpp:86] Creating Layer loss
I0522 10:13:16.333735 19861 net.cpp:408] loss <- fc8_fc8_0_split_1
I0522 10:13:16.333739 19861 net.cpp:408] loss <- label_data_1_split_1
I0522 10:13:16.333741 19861 net.cpp:382] loss -> loss
I0522 10:13:16.333747 19861 layer_factory.hpp:77] Creating layer loss
I0522 10:13:16.334476 19861 net.cpp:124] Setting up loss
I0522 10:13:16.334484 19861 net.cpp:131] Top shape: (1)
I0522 10:13:16.334486 19861 net.cpp:134]     with loss weight 1
I0522 10:13:16.334506 19861 net.cpp:139] Memory required for data: 274087208
I0522 10:13:16.334509 19861 net.cpp:200] loss needs backward computation.
I0522 10:13:16.334511 19861 net.cpp:202] accuracy does not need backward computation.
I0522 10:13:16.334514 19861 net.cpp:200] fc8_fc8_0_split needs backward computation.
I0522 10:13:16.334517 19861 net.cpp:200] fc8 needs backward computation.
I0522 10:13:16.334518 19861 net.cpp:200] drop7 needs backward computation.
I0522 10:13:16.334519 19861 net.cpp:200] relu7 needs backward computation.
I0522 10:13:16.334522 19861 net.cpp:200] fc7 needs backward computation.
I0522 10:13:16.334523 19861 net.cpp:200] drop6 needs backward computation.
I0522 10:13:16.334524 19861 net.cpp:200] relu6 needs backward computation.
I0522 10:13:16.334527 19861 net.cpp:200] fc6 needs backward computation.
I0522 10:13:16.334529 19861 net.cpp:200] pool5 needs backward computation.
I0522 10:13:16.334532 19861 net.cpp:200] relu5 needs backward computation.
I0522 10:13:16.334533 19861 net.cpp:200] conv5 needs backward computation.
I0522 10:13:16.334535 19861 net.cpp:200] relu4 needs backward computation.
I0522 10:13:16.334537 19861 net.cpp:200] conv4 needs backward computation.
I0522 10:13:16.334538 19861 net.cpp:200] relu3 needs backward computation.
I0522 10:13:16.334540 19861 net.cpp:200] conv3 needs backward computation.
I0522 10:13:16.334544 19861 net.cpp:200] norm2 needs backward computation.
I0522 10:13:16.334547 19861 net.cpp:200] pool2 needs backward computation.
I0522 10:13:16.334548 19861 net.cpp:200] relu2 needs backward computation.
I0522 10:13:16.334550 19861 net.cpp:200] conv2 needs backward computation.
I0522 10:13:16.334553 19861 net.cpp:200] norm1 needs backward computation.
I0522 10:13:16.334555 19861 net.cpp:200] pool1 needs backward computation.
I0522 10:13:16.334558 19861 net.cpp:200] relu1 needs backward computation.
I0522 10:13:16.334559 19861 net.cpp:200] conv1 needs backward computation.
I0522 10:13:16.334563 19861 net.cpp:202] label_data_1_split does not need backward computation.
I0522 10:13:16.334565 19861 net.cpp:202] data does not need backward computation.
I0522 10:13:16.334566 19861 net.cpp:244] This network produces output accuracy
I0522 10:13:16.334568 19861 net.cpp:244] This network produces output loss
I0522 10:13:16.334581 19861 net.cpp:257] Network initialization done.
I0522 10:13:16.334700 19861 solver.cpp:57] Solver scaffolding done.
I0522 10:13:16.335009 19861 caffe.cpp:239] Starting Optimization
I0522 10:13:16.335027 19861 solver.cpp:289] Solving CaffeNet
I0522 10:13:16.335031 19861 solver.cpp:290] Learning Rate Policy: step
I0522 10:13:16.336544 19861 solver.cpp:347] Iteration 0, Testing net (#0)
I0522 10:13:16.416540 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:13:25.022408 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:13:28.948808 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:13:33.102484 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:13:36.920683 19861 solver.cpp:414]     Test net output #0: accuracy = 0.0356202
I0522 10:13:36.920837 19861 solver.cpp:414]     Test net output #1: loss = 3.8848 (* 1 = 3.8848 loss)
I0522 10:13:37.015187 19861 solver.cpp:239] Iteration 0 (-1.86171e-35 iter/s, 20.6801s/20 iters), loss = 4.17878
I0522 10:13:37.017539 19861 solver.cpp:258]     Train net output #0: loss = 4.17878 (* 1 = 4.17878 loss)
I0522 10:13:37.017557 19861 sgd_solver.cpp:112] Iteration 0, lr = 0.001
I0522 10:13:39.480450 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:13:40.317150 19861 solver.cpp:239] Iteration 20 (6.06135 iter/s, 3.29959s/20 iters), loss = 3.74836
I0522 10:13:40.317193 19861 solver.cpp:258]     Train net output #0: loss = 3.74836 (* 1 = 3.74836 loss)
I0522 10:13:40.317198 19861 sgd_solver.cpp:112] Iteration 20, lr = 0.001
I0522 10:13:43.989450 19861 solver.cpp:239] Iteration 40 (5.44629 iter/s, 3.67223s/20 iters), loss = 3.87889
I0522 10:13:43.989786 19861 solver.cpp:258]     Train net output #0: loss = 3.87889 (* 1 = 3.87889 loss)
I0522 10:13:43.989795 19861 sgd_solver.cpp:112] Iteration 40, lr = 0.001
I0522 10:13:47.930022 19861 solver.cpp:239] Iteration 60 (5.07586 iter/s, 3.94022s/20 iters), loss = 3.67524
I0522 10:13:47.944144 19861 solver.cpp:258]     Train net output #0: loss = 3.67524 (* 1 = 3.67524 loss)
I0522 10:13:47.944160 19861 sgd_solver.cpp:112] Iteration 60, lr = 0.001
I0522 10:13:51.694918 19861 solver.cpp:239] Iteration 80 (5.33225 iter/s, 3.75076s/20 iters), loss = 3.62503
I0522 10:13:51.694983 19861 solver.cpp:258]     Train net output #0: loss = 3.62503 (* 1 = 3.62503 loss)
I0522 10:13:51.694986 19861 sgd_solver.cpp:112] Iteration 80, lr = 0.001
I0522 10:13:55.049968 19861 solver.cpp:239] Iteration 100 (5.96131 iter/s, 3.35497s/20 iters), loss = 3.55123
I0522 10:13:55.050045 19861 solver.cpp:258]     Train net output #0: loss = 3.55123 (* 1 = 3.55123 loss)
I0522 10:13:55.050052 19861 sgd_solver.cpp:112] Iteration 100, lr = 0.001
I0522 10:13:58.947310 19861 solver.cpp:239] Iteration 120 (5.13183 iter/s, 3.89725s/20 iters), loss = 3.52742
I0522 10:13:58.957496 19861 solver.cpp:258]     Train net output #0: loss = 3.52742 (* 1 = 3.52742 loss)
I0522 10:13:58.957504 19861 sgd_solver.cpp:112] Iteration 120, lr = 0.001
I0522 10:14:02.663992 19861 solver.cpp:239] Iteration 140 (5.39596 iter/s, 3.70647s/20 iters), loss = 3.37651
I0522 10:14:02.664044 19861 solver.cpp:258]     Train net output #0: loss = 3.37651 (* 1 = 3.37651 loss)
I0522 10:14:02.664049 19861 sgd_solver.cpp:112] Iteration 140, lr = 0.001
I0522 10:14:04.678148 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:14:05.820257 19861 solver.cpp:239] Iteration 160 (6.3368 iter/s, 3.15617s/20 iters), loss = 3.41613
I0522 10:14:05.830309 19861 solver.cpp:258]     Train net output #0: loss = 3.41613 (* 1 = 3.41613 loss)
I0522 10:14:05.830317 19861 sgd_solver.cpp:112] Iteration 160, lr = 0.001
I0522 10:14:07.825398 19861 solver.cpp:239] Iteration 180 (10.0248 iter/s, 1.99505s/20 iters), loss = 3.33968
I0522 10:14:07.825510 19861 solver.cpp:258]     Train net output #0: loss = 3.33968 (* 1 = 3.33968 loss)
I0522 10:14:07.825515 19861 sgd_solver.cpp:112] Iteration 180, lr = 0.001
I0522 10:14:11.385915 19861 solver.cpp:239] Iteration 200 (5.61738 iter/s, 3.56038s/20 iters), loss = 3.44802
I0522 10:14:11.385993 19861 solver.cpp:258]     Train net output #0: loss = 3.44802 (* 1 = 3.44802 loss)
I0522 10:14:11.385999 19861 sgd_solver.cpp:112] Iteration 200, lr = 0.001
I0522 10:14:13.397723 19861 solver.cpp:239] Iteration 220 (9.94184 iter/s, 2.0117s/20 iters), loss = 3.15945
I0522 10:14:13.407078 19861 solver.cpp:258]     Train net output #0: loss = 3.15945 (* 1 = 3.15945 loss)
I0522 10:14:13.407085 19861 sgd_solver.cpp:112] Iteration 220, lr = 0.001
I0522 10:14:15.390945 19861 solver.cpp:239] Iteration 240 (10.0815 iter/s, 1.98384s/20 iters), loss = 2.99953
I0522 10:14:15.391484 19861 solver.cpp:258]     Train net output #0: loss = 2.99953 (* 1 = 2.99953 loss)
I0522 10:14:15.391492 19861 sgd_solver.cpp:112] Iteration 240, lr = 0.001
I0522 10:14:17.389397 19861 solver.cpp:239] Iteration 260 (10.0105 iter/s, 1.9979s/20 iters), loss = 3.10909
I0522 10:14:17.389451 19861 solver.cpp:258]     Train net output #0: loss = 3.10909 (* 1 = 3.10909 loss)
I0522 10:14:17.389457 19861 sgd_solver.cpp:112] Iteration 260, lr = 0.001
I0522 10:14:19.960870 19861 solver.cpp:239] Iteration 280 (7.77786 iter/s, 2.5714s/20 iters), loss = 2.75775
I0522 10:14:19.971235 19861 solver.cpp:258]     Train net output #0: loss = 2.75775 (* 1 = 2.75775 loss)
I0522 10:14:19.971240 19861 sgd_solver.cpp:112] Iteration 280, lr = 0.001
I0522 10:14:22.936043 19861 solver.cpp:239] Iteration 300 (6.74586 iter/s, 2.96478s/20 iters), loss = 2.84007
I0522 10:14:22.936115 19861 solver.cpp:258]     Train net output #0: loss = 2.84007 (* 1 = 2.84007 loss)
I0522 10:14:22.936120 19861 sgd_solver.cpp:112] Iteration 300, lr = 0.001
I0522 10:14:23.388061 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:14:24.946441 19861 solver.cpp:239] Iteration 320 (9.94876 iter/s, 2.0103s/20 iters), loss = 2.63628
I0522 10:14:24.946508 19861 solver.cpp:258]     Train net output #0: loss = 2.63628 (* 1 = 2.63628 loss)
I0522 10:14:24.946512 19861 sgd_solver.cpp:112] Iteration 320, lr = 0.001
I0522 10:14:26.980969 19861 solver.cpp:239] Iteration 340 (9.83074 iter/s, 2.03444s/20 iters), loss = 2.494
I0522 10:14:26.981055 19861 solver.cpp:258]     Train net output #0: loss = 2.494 (* 1 = 2.494 loss)
I0522 10:14:26.981060 19861 sgd_solver.cpp:112] Iteration 340, lr = 0.001
I0522 10:14:29.019868 19861 solver.cpp:239] Iteration 360 (9.8098 iter/s, 2.03878s/20 iters), loss = 2.24742
I0522 10:14:29.019955 19861 solver.cpp:258]     Train net output #0: loss = 2.24742 (* 1 = 2.24742 loss)
I0522 10:14:29.019963 19861 sgd_solver.cpp:112] Iteration 360, lr = 0.001
I0522 10:14:32.629914 19861 solver.cpp:239] Iteration 380 (5.54025 iter/s, 3.60994s/20 iters), loss = 2.17725
I0522 10:14:32.639957 19861 solver.cpp:258]     Train net output #0: loss = 2.17725 (* 1 = 2.17725 loss)
I0522 10:14:32.639964 19861 sgd_solver.cpp:112] Iteration 380, lr = 0.001
I0522 10:14:34.656651 19861 solver.cpp:239] Iteration 400 (9.91739 iter/s, 2.01666s/20 iters), loss = 2.22923
I0522 10:14:34.656735 19861 solver.cpp:258]     Train net output #0: loss = 2.22923 (* 1 = 2.22923 loss)
I0522 10:14:34.656739 19861 sgd_solver.cpp:112] Iteration 400, lr = 0.001
I0522 10:14:36.737462 19861 solver.cpp:239] Iteration 420 (9.6121 iter/s, 2.08071s/20 iters), loss = 2.04367
I0522 10:14:36.747036 19861 solver.cpp:258]     Train net output #0: loss = 2.04367 (* 1 = 2.04367 loss)
I0522 10:14:36.747045 19861 sgd_solver.cpp:112] Iteration 420, lr = 0.001
I0522 10:14:38.763609 19861 solver.cpp:239] Iteration 440 (9.91789 iter/s, 2.01656s/20 iters), loss = 2.00087
I0522 10:14:38.773342 19861 solver.cpp:258]     Train net output #0: loss = 2.00087 (* 1 = 2.00087 loss)
I0522 10:14:38.773350 19861 sgd_solver.cpp:112] Iteration 440, lr = 0.001
I0522 10:14:40.755582 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:14:41.216192 19861 solver.cpp:239] Iteration 460 (8.18726 iter/s, 2.44282s/20 iters), loss = 1.91571
I0522 10:14:41.230001 19861 solver.cpp:258]     Train net output #0: loss = 1.91571 (* 1 = 1.91571 loss)
I0522 10:14:41.230011 19861 sgd_solver.cpp:112] Iteration 460, lr = 0.001
I0522 10:14:44.360241 19861 solver.cpp:239] Iteration 480 (6.38933 iter/s, 3.13022s/20 iters), loss = 1.93273
I0522 10:14:44.369840 19861 solver.cpp:258]     Train net output #0: loss = 1.93273 (* 1 = 1.93273 loss)
I0522 10:14:44.369848 19861 sgd_solver.cpp:112] Iteration 480, lr = 0.001
I0522 10:14:46.386453 19861 solver.cpp:239] Iteration 500 (9.91775 iter/s, 2.01659s/20 iters), loss = 1.9352
I0522 10:14:46.396420 19861 solver.cpp:258]     Train net output #0: loss = 1.9352 (* 1 = 1.9352 loss)
I0522 10:14:46.396430 19861 sgd_solver.cpp:112] Iteration 500, lr = 0.001
I0522 10:14:48.413161 19861 solver.cpp:239] Iteration 520 (9.91704 iter/s, 2.01673s/20 iters), loss = 1.82508
I0522 10:14:48.422704 19861 solver.cpp:258]     Train net output #0: loss = 1.82508 (* 1 = 1.82508 loss)
I0522 10:14:48.422713 19861 sgd_solver.cpp:112] Iteration 520, lr = 0.001
I0522 10:14:50.423208 19861 solver.cpp:239] Iteration 540 (9.99755 iter/s, 2.00049s/20 iters), loss = 1.84393
I0522 10:14:50.432740 19861 solver.cpp:258]     Train net output #0: loss = 1.84393 (* 1 = 1.84393 loss)
I0522 10:14:50.432749 19861 sgd_solver.cpp:112] Iteration 540, lr = 0.001
I0522 10:14:53.947938 19861 solver.cpp:239] Iteration 560 (5.68961 iter/s, 3.51518s/20 iters), loss = 1.71898
I0522 10:14:53.959919 19861 solver.cpp:258]     Train net output #0: loss = 1.71898 (* 1 = 1.71898 loss)
I0522 10:14:53.959928 19861 sgd_solver.cpp:112] Iteration 560, lr = 0.001
I0522 10:14:55.979501 19861 solver.cpp:239] Iteration 580 (9.90354 iter/s, 2.01948s/20 iters), loss = 1.68331
I0522 10:14:55.989162 19861 solver.cpp:258]     Train net output #0: loss = 1.68331 (* 1 = 1.68331 loss)
I0522 10:14:55.989176 19861 sgd_solver.cpp:112] Iteration 580, lr = 0.001
I0522 10:14:58.073376 19861 solver.cpp:239] Iteration 600 (9.59601 iter/s, 2.0842s/20 iters), loss = 1.56759
I0522 10:14:58.082914 19861 solver.cpp:258]     Train net output #0: loss = 1.56759 (* 1 = 1.56759 loss)
I0522 10:14:58.082926 19861 sgd_solver.cpp:112] Iteration 600, lr = 0.001
I0522 10:14:59.146374 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:15:00.115211 19861 solver.cpp:239] Iteration 620 (9.8412 iter/s, 2.03227s/20 iters), loss = 1.65561
I0522 10:15:00.115303 19861 solver.cpp:258]     Train net output #0: loss = 1.65561 (* 1 = 1.65561 loss)
I0522 10:15:00.115309 19861 sgd_solver.cpp:112] Iteration 620, lr = 0.001
I0522 10:15:02.160223 19861 solver.cpp:239] Iteration 640 (9.78045 iter/s, 2.0449s/20 iters), loss = 1.42235
I0522 10:15:02.171762 19861 solver.cpp:258]     Train net output #0: loss = 1.42235 (* 1 = 1.42235 loss)
I0522 10:15:02.171772 19861 sgd_solver.cpp:112] Iteration 640, lr = 0.001
I0522 10:15:05.731976 19861 solver.cpp:239] Iteration 660 (5.61766 iter/s, 3.5602s/20 iters), loss = 1.49232
I0522 10:15:05.732061 19861 solver.cpp:258]     Train net output #0: loss = 1.49232 (* 1 = 1.49232 loss)
I0522 10:15:05.732065 19861 sgd_solver.cpp:112] Iteration 660, lr = 0.001
I0522 10:15:07.777045 19861 solver.cpp:239] Iteration 680 (9.78013 iter/s, 2.04496s/20 iters), loss = 1.41258
I0522 10:15:07.786521 19861 solver.cpp:258]     Train net output #0: loss = 1.41258 (* 1 = 1.41258 loss)
I0522 10:15:07.786531 19861 sgd_solver.cpp:112] Iteration 680, lr = 0.001
I0522 10:15:09.804720 19861 solver.cpp:239] Iteration 700 (9.9099 iter/s, 2.01818s/20 iters), loss = 1.3871
I0522 10:15:09.814227 19861 solver.cpp:258]     Train net output #0: loss = 1.3871 (* 1 = 1.3871 loss)
I0522 10:15:09.814236 19861 sgd_solver.cpp:112] Iteration 700, lr = 0.001
I0522 10:15:11.827771 19861 solver.cpp:239] Iteration 720 (9.93283 iter/s, 2.01352s/20 iters), loss = 1.48514
I0522 10:15:11.837703 19861 solver.cpp:258]     Train net output #0: loss = 1.48514 (* 1 = 1.48514 loss)
I0522 10:15:11.837711 19861 sgd_solver.cpp:112] Iteration 720, lr = 0.001
I0522 10:15:13.850944 19861 solver.cpp:239] Iteration 740 (9.93435 iter/s, 2.01322s/20 iters), loss = 1.42202
I0522 10:15:13.851042 19861 solver.cpp:258]     Train net output #0: loss = 1.42202 (* 1 = 1.42202 loss)
I0522 10:15:13.851052 19861 sgd_solver.cpp:112] Iteration 740, lr = 0.001
I0522 10:15:17.446169 19861 solver.cpp:239] Iteration 760 (5.5631 iter/s, 3.59512s/20 iters), loss = 1.29315
I0522 10:15:17.446455 19861 solver.cpp:258]     Train net output #0: loss = 1.29315 (* 1 = 1.29315 loss)
I0522 10:15:17.446460 19861 sgd_solver.cpp:112] Iteration 760, lr = 0.001
I0522 10:15:17.833226 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:15:19.480643 19861 solver.cpp:239] Iteration 780 (9.83204 iter/s, 2.03417s/20 iters), loss = 1.26061
I0522 10:15:19.490084 19861 solver.cpp:258]     Train net output #0: loss = 1.26061 (* 1 = 1.26061 loss)
I0522 10:15:19.490094 19861 sgd_solver.cpp:112] Iteration 780, lr = 0.001
I0522 10:15:21.512248 19861 solver.cpp:239] Iteration 800 (9.89052 iter/s, 2.02214s/20 iters), loss = 1.21628
I0522 10:15:21.521795 19861 solver.cpp:258]     Train net output #0: loss = 1.21628 (* 1 = 1.21628 loss)
I0522 10:15:21.521802 19861 sgd_solver.cpp:112] Iteration 800, lr = 0.001
I0522 10:15:23.562772 19861 solver.cpp:239] Iteration 820 (9.79928 iter/s, 2.04097s/20 iters), loss = 1.09985
I0522 10:15:23.572888 19861 solver.cpp:258]     Train net output #0: loss = 1.09985 (* 1 = 1.09985 loss)
I0522 10:15:23.572938 19861 sgd_solver.cpp:112] Iteration 820, lr = 0.001
I0522 10:15:25.601148 19861 solver.cpp:239] Iteration 840 (9.86084 iter/s, 2.02823s/20 iters), loss = 1.15391
I0522 10:15:25.612923 19861 solver.cpp:258]     Train net output #0: loss = 1.15391 (* 1 = 1.15391 loss)
I0522 10:15:25.612938 19861 sgd_solver.cpp:112] Iteration 840, lr = 0.001
I0522 10:15:29.167500 19861 solver.cpp:239] Iteration 860 (5.62656 iter/s, 3.55457s/20 iters), loss = 1.23165
I0522 10:15:29.176888 19861 solver.cpp:258]     Train net output #0: loss = 1.23165 (* 1 = 1.23165 loss)
I0522 10:15:29.176895 19861 sgd_solver.cpp:112] Iteration 860, lr = 0.001
I0522 10:15:31.204084 19861 solver.cpp:239] Iteration 880 (9.86597 iter/s, 2.02717s/20 iters), loss = 1.01824
I0522 10:15:31.213500 19861 solver.cpp:258]     Train net output #0: loss = 1.01824 (* 1 = 1.01824 loss)
I0522 10:15:31.213510 19861 sgd_solver.cpp:112] Iteration 880, lr = 0.001
I0522 10:15:33.234855 19861 solver.cpp:239] Iteration 900 (9.8945 iter/s, 2.02132s/20 iters), loss = 1.03573
I0522 10:15:33.244488 19861 solver.cpp:258]     Train net output #0: loss = 1.03573 (* 1 = 1.03573 loss)
I0522 10:15:33.244496 19861 sgd_solver.cpp:112] Iteration 900, lr = 0.001
I0522 10:15:34.950011 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:15:35.279423 19861 solver.cpp:239] Iteration 920 (9.8284 iter/s, 2.03492s/20 iters), loss = 0.978163
I0522 10:15:35.289041 19861 solver.cpp:258]     Train net output #0: loss = 0.978163 (* 1 = 0.978163 loss)
I0522 10:15:35.289050 19861 sgd_solver.cpp:112] Iteration 920, lr = 0.001
I0522 10:15:37.584941 19861 solver.cpp:239] Iteration 940 (8.71127 iter/s, 2.29588s/20 iters), loss = 1.00992
I0522 10:15:37.585057 19861 solver.cpp:258]     Train net output #0: loss = 1.00992 (* 1 = 1.00992 loss)
I0522 10:15:37.585062 19861 sgd_solver.cpp:112] Iteration 940, lr = 0.001
I0522 10:15:40.922049 19861 solver.cpp:239] Iteration 960 (5.99701 iter/s, 3.335s/20 iters), loss = 0.967331
I0522 10:15:40.931655 19861 solver.cpp:258]     Train net output #0: loss = 0.967331 (* 1 = 0.967331 loss)
I0522 10:15:40.931668 19861 sgd_solver.cpp:112] Iteration 960, lr = 0.001
I0522 10:15:42.962160 19861 solver.cpp:239] Iteration 980 (9.84986 iter/s, 2.03049s/20 iters), loss = 0.8915
I0522 10:15:42.971513 19861 solver.cpp:258]     Train net output #0: loss = 0.8915 (* 1 = 0.8915 loss)
I0522 10:15:42.971524 19861 sgd_solver.cpp:112] Iteration 980, lr = 0.001
I0522 10:15:44.837473 19861 solver.cpp:347] Iteration 1000, Testing net (#0)
I0522 10:15:45.203181 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:15:48.863046 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:15:54.298267 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:15:58.090653 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:16:03.215585 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:16:06.580493 19861 solver.cpp:414]     Test net output #0: accuracy = 0.6125
I0522 10:16:06.580576 19861 solver.cpp:414]     Test net output #1: loss = 1.18922 (* 1 = 1.18922 loss)
I0522 10:16:06.681134 19861 solver.cpp:239] Iteration 1000 (0.843571 iter/s, 23.7087s/20 iters), loss = 0.89411
I0522 10:16:06.711412 19861 solver.cpp:258]     Train net output #0: loss = 0.89411 (* 1 = 0.89411 loss)
I0522 10:16:06.712203 19861 sgd_solver.cpp:112] Iteration 1000, lr = 0.001
I0522 10:16:09.580725 19861 solver.cpp:239] Iteration 1020 (6.96902 iter/s, 2.86985s/20 iters), loss = 0.704529
I0522 10:16:09.589939 19861 solver.cpp:258]     Train net output #0: loss = 0.704529 (* 1 = 0.704529 loss)
I0522 10:16:09.589946 19861 sgd_solver.cpp:112] Iteration 1020, lr = 0.001
I0522 10:16:11.611389 19861 solver.cpp:239] Iteration 1040 (9.89393 iter/s, 2.02144s/20 iters), loss = 0.687719
I0522 10:16:11.620589 19861 solver.cpp:258]     Train net output #0: loss = 0.687719 (* 1 = 0.687719 loss)
I0522 10:16:11.620594 19861 sgd_solver.cpp:112] Iteration 1040, lr = 0.001
I0522 10:16:13.651898 19861 solver.cpp:239] Iteration 1060 (9.84589 iter/s, 2.0313s/20 iters), loss = 0.801572
I0522 10:16:13.661140 19861 solver.cpp:258]     Train net output #0: loss = 0.801572 (* 1 = 0.801572 loss)
I0522 10:16:13.661147 19861 sgd_solver.cpp:112] Iteration 1060, lr = 0.001
I0522 10:16:14.725224 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:16:15.700935 19861 solver.cpp:239] Iteration 1080 (9.80495 iter/s, 2.03979s/20 iters), loss = 0.723403
I0522 10:16:15.710078 19861 solver.cpp:258]     Train net output #0: loss = 0.723403 (* 1 = 0.723403 loss)
I0522 10:16:15.710085 19861 sgd_solver.cpp:112] Iteration 1080, lr = 0.001
I0522 10:16:17.739408 19861 solver.cpp:239] Iteration 1100 (9.85554 iter/s, 2.02931s/20 iters), loss = 0.608564
I0522 10:16:17.748819 19861 solver.cpp:258]     Train net output #0: loss = 0.608564 (* 1 = 0.608564 loss)
I0522 10:16:17.748829 19861 sgd_solver.cpp:112] Iteration 1100, lr = 0.001
I0522 10:16:19.767297 19861 solver.cpp:239] Iteration 1120 (9.90849 iter/s, 2.01847s/20 iters), loss = 0.708017
I0522 10:16:19.776535 19861 solver.cpp:258]     Train net output #0: loss = 0.708017 (* 1 = 0.708017 loss)
I0522 10:16:19.776552 19861 sgd_solver.cpp:112] Iteration 1120, lr = 0.001
I0522 10:16:21.804961 19861 solver.cpp:239] Iteration 1140 (9.85985 iter/s, 2.02843s/20 iters), loss = 0.550907
I0522 10:16:21.814092 19861 solver.cpp:258]     Train net output #0: loss = 0.550907 (* 1 = 0.550907 loss)
I0522 10:16:21.814100 19861 sgd_solver.cpp:112] Iteration 1140, lr = 0.001
I0522 10:16:23.833351 19861 solver.cpp:239] Iteration 1160 (9.90465 iter/s, 2.01925s/20 iters), loss = 0.665873
I0522 10:16:23.842497 19861 solver.cpp:258]     Train net output #0: loss = 0.665873 (* 1 = 0.665873 loss)
I0522 10:16:23.842509 19861 sgd_solver.cpp:112] Iteration 1160, lr = 0.001
I0522 10:16:24.281858 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:16:25.859853 19861 solver.cpp:239] Iteration 1180 (9.91398 iter/s, 2.01735s/20 iters), loss = 0.774692
I0522 10:16:25.868974 19861 solver.cpp:258]     Train net output #0: loss = 0.774692 (* 1 = 0.774692 loss)
I0522 10:16:25.868981 19861 sgd_solver.cpp:112] Iteration 1180, lr = 0.001
I0522 10:16:27.912894 19861 solver.cpp:239] Iteration 1200 (9.78515 iter/s, 2.04391s/20 iters), loss = 0.646521
I0522 10:16:27.922183 19861 solver.cpp:258]     Train net output #0: loss = 0.646521 (* 1 = 0.646521 loss)
I0522 10:16:27.922189 19861 sgd_solver.cpp:112] Iteration 1200, lr = 0.001
I0522 10:16:30.016281 19861 solver.cpp:239] Iteration 1220 (9.55068 iter/s, 2.09409s/20 iters), loss = 0.563724
I0522 10:16:30.025609 19861 solver.cpp:258]     Train net output #0: loss = 0.563724 (* 1 = 0.563724 loss)
I0522 10:16:30.025616 19861 sgd_solver.cpp:112] Iteration 1220, lr = 0.001
I0522 10:16:30.355963 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:16:32.131404 19861 solver.cpp:239] Iteration 1240 (9.49772 iter/s, 2.10577s/20 iters), loss = 0.638291
I0522 10:16:32.141158 19861 solver.cpp:258]     Train net output #0: loss = 0.638291 (* 1 = 0.638291 loss)
I0522 10:16:32.141172 19861 sgd_solver.cpp:112] Iteration 1240, lr = 0.001
I0522 10:16:34.250885 19861 solver.cpp:239] Iteration 1260 (9.47991 iter/s, 2.10972s/20 iters), loss = 0.453473
I0522 10:16:34.250928 19861 solver.cpp:258]     Train net output #0: loss = 0.453473 (* 1 = 0.453473 loss)
I0522 10:16:34.250931 19861 sgd_solver.cpp:112] Iteration 1260, lr = 0.001
I0522 10:16:36.361941 19861 solver.cpp:239] Iteration 1280 (9.47425 iter/s, 2.11099s/20 iters), loss = 0.553466
I0522 10:16:36.362040 19861 solver.cpp:258]     Train net output #0: loss = 0.553466 (* 1 = 0.553466 loss)
I0522 10:16:36.362048 19861 sgd_solver.cpp:112] Iteration 1280, lr = 0.001
I0522 10:16:38.415391 19861 solver.cpp:239] Iteration 1300 (9.74027 iter/s, 2.05333s/20 iters), loss = 0.569149
I0522 10:16:38.426033 19861 solver.cpp:258]     Train net output #0: loss = 0.569149 (* 1 = 0.569149 loss)
I0522 10:16:38.426039 19861 sgd_solver.cpp:112] Iteration 1300, lr = 0.001
I0522 10:16:40.480911 19861 solver.cpp:239] Iteration 1320 (9.73301 iter/s, 2.05486s/20 iters), loss = 0.506212
I0522 10:16:40.480976 19861 solver.cpp:258]     Train net output #0: loss = 0.506212 (* 1 = 0.506212 loss)
I0522 10:16:40.480980 19861 sgd_solver.cpp:112] Iteration 1320, lr = 0.001
I0522 10:16:42.976130 19861 solver.cpp:239] Iteration 1340 (8.01555 iter/s, 2.49515s/20 iters), loss = 0.466163
I0522 10:16:42.985868 19861 solver.cpp:258]     Train net output #0: loss = 0.466163 (* 1 = 0.466163 loss)
I0522 10:16:42.985875 19861 sgd_solver.cpp:112] Iteration 1340, lr = 0.001
I0522 10:16:45.078470 19861 solver.cpp:239] Iteration 1360 (9.55759 iter/s, 2.09258s/20 iters), loss = 0.530224
I0522 10:16:45.078573 19861 solver.cpp:258]     Train net output #0: loss = 0.530224 (* 1 = 0.530224 loss)
I0522 10:16:45.078579 19861 sgd_solver.cpp:112] Iteration 1360, lr = 0.001
I0522 10:16:46.825441 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:16:47.185726 19861 solver.cpp:239] Iteration 1380 (9.4915 iter/s, 2.10715s/20 iters), loss = 0.418848
I0522 10:16:47.185770 19861 solver.cpp:258]     Train net output #0: loss = 0.418848 (* 1 = 0.418848 loss)
I0522 10:16:47.185829 19861 sgd_solver.cpp:112] Iteration 1380, lr = 0.001
I0522 10:16:49.317958 19861 solver.cpp:239] Iteration 1400 (9.38007 iter/s, 2.13218s/20 iters), loss = 0.449064
I0522 10:16:49.318008 19861 solver.cpp:258]     Train net output #0: loss = 0.449064 (* 1 = 0.449064 loss)
I0522 10:16:49.318012 19861 sgd_solver.cpp:112] Iteration 1400, lr = 0.001
I0522 10:16:51.437503 19861 solver.cpp:239] Iteration 1420 (9.43628 iter/s, 2.11948s/20 iters), loss = 0.394368
I0522 10:16:51.437781 19861 solver.cpp:258]     Train net output #0: loss = 0.394368 (* 1 = 0.394368 loss)
I0522 10:16:51.437786 19861 sgd_solver.cpp:112] Iteration 1420, lr = 0.001
I0522 10:16:53.580858 19861 solver.cpp:239] Iteration 1440 (9.33243 iter/s, 2.14306s/20 iters), loss = 0.331385
I0522 10:16:53.580914 19861 solver.cpp:258]     Train net output #0: loss = 0.331385 (* 1 = 0.331385 loss)
I0522 10:16:53.580917 19861 sgd_solver.cpp:112] Iteration 1440, lr = 0.001
I0522 10:16:56.105571 19861 solver.cpp:239] Iteration 1460 (7.922 iter/s, 2.52461s/20 iters), loss = 0.432149
I0522 10:16:56.105706 19861 solver.cpp:258]     Train net output #0: loss = 0.432149 (* 1 = 0.432149 loss)
I0522 10:16:56.105722 19861 sgd_solver.cpp:112] Iteration 1460, lr = 0.001
I0522 10:16:58.364231 19861 solver.cpp:239] Iteration 1480 (8.85532 iter/s, 2.25853s/20 iters), loss = 0.454771
I0522 10:16:58.373883 19861 solver.cpp:258]     Train net output #0: loss = 0.454771 (* 1 = 0.454771 loss)
I0522 10:16:58.373888 19861 sgd_solver.cpp:112] Iteration 1480, lr = 0.001
I0522 10:17:00.553318 19861 solver.cpp:239] Iteration 1500 (9.17677 iter/s, 2.17942s/20 iters), loss = 0.424086
I0522 10:17:00.564887 19861 solver.cpp:258]     Train net output #0: loss = 0.424086 (* 1 = 0.424086 loss)
I0522 10:17:00.564893 19861 sgd_solver.cpp:112] Iteration 1500, lr = 0.001
I0522 10:17:02.674585 19861 solver.cpp:239] Iteration 1520 (9.48007 iter/s, 2.10969s/20 iters), loss = 0.393221
I0522 10:17:02.674639 19861 solver.cpp:258]     Train net output #0: loss = 0.393221 (* 1 = 0.393221 loss)
I0522 10:17:02.674643 19861 sgd_solver.cpp:112] Iteration 1520, lr = 0.001
I0522 10:17:03.693990 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:17:05.058279 19861 solver.cpp:239] Iteration 1540 (8.39059 iter/s, 2.38362s/20 iters), loss = 0.355124
I0522 10:17:05.068581 19861 solver.cpp:258]     Train net output #0: loss = 0.355124 (* 1 = 0.355124 loss)
I0522 10:17:05.068588 19861 sgd_solver.cpp:112] Iteration 1540, lr = 0.001
I0522 10:17:07.209229 19861 solver.cpp:239] Iteration 1560 (9.34299 iter/s, 2.14064s/20 iters), loss = 0.275047
I0522 10:17:07.209280 19861 solver.cpp:258]     Train net output #0: loss = 0.275047 (* 1 = 0.275047 loss)
I0522 10:17:07.209282 19861 sgd_solver.cpp:112] Iteration 1560, lr = 0.001
I0522 10:17:09.375636 19861 solver.cpp:239] Iteration 1580 (9.23215 iter/s, 2.16634s/20 iters), loss = 0.304283
I0522 10:17:09.390599 19861 solver.cpp:258]     Train net output #0: loss = 0.304283 (* 1 = 0.304283 loss)
I0522 10:17:09.390606 19861 sgd_solver.cpp:112] Iteration 1580, lr = 0.001
I0522 10:17:11.537326 19861 solver.cpp:239] Iteration 1600 (9.31657 iter/s, 2.14671s/20 iters), loss = 0.325307
I0522 10:17:11.550209 19861 solver.cpp:258]     Train net output #0: loss = 0.325307 (* 1 = 0.325307 loss)
I0522 10:17:11.550217 19861 sgd_solver.cpp:112] Iteration 1600, lr = 0.001
I0522 10:17:14.026727 19861 solver.cpp:239] Iteration 1620 (8.07588 iter/s, 2.47651s/20 iters), loss = 0.309841
I0522 10:17:14.036146 19861 solver.cpp:258]     Train net output #0: loss = 0.309841 (* 1 = 0.309841 loss)
I0522 10:17:14.036154 19861 sgd_solver.cpp:112] Iteration 1620, lr = 0.001
I0522 10:17:16.194931 19861 solver.cpp:239] Iteration 1640 (9.26457 iter/s, 2.15876s/20 iters), loss = 0.402056
I0522 10:17:16.195016 19861 solver.cpp:258]     Train net output #0: loss = 0.402056 (* 1 = 0.402056 loss)
I0522 10:17:16.195020 19861 sgd_solver.cpp:112] Iteration 1640, lr = 0.001
I0522 10:17:18.352097 19861 solver.cpp:239] Iteration 1660 (9.27196 iter/s, 2.15704s/20 iters), loss = 0.331288
I0522 10:17:18.352217 19861 solver.cpp:258]     Train net output #0: loss = 0.331288 (* 1 = 0.331288 loss)
I0522 10:17:18.352233 19861 sgd_solver.cpp:112] Iteration 1660, lr = 0.001
I0522 10:17:20.776633 19861 solver.cpp:239] Iteration 1680 (8.2494 iter/s, 2.42442s/20 iters), loss = 0.317934
I0522 10:17:20.776687 19861 solver.cpp:258]     Train net output #0: loss = 0.317934 (* 1 = 0.317934 loss)
I0522 10:17:20.776693 19861 sgd_solver.cpp:112] Iteration 1680, lr = 0.001
I0522 10:17:21.092536 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:17:23.028882 19861 solver.cpp:239] Iteration 1700 (8.88026 iter/s, 2.25219s/20 iters), loss = 0.35223
I0522 10:17:23.029247 19861 solver.cpp:258]     Train net output #0: loss = 0.35223 (* 1 = 0.35223 loss)
I0522 10:17:23.029251 19861 sgd_solver.cpp:112] Iteration 1700, lr = 0.001
I0522 10:17:25.236630 19861 solver.cpp:239] Iteration 1720 (9.0605 iter/s, 2.20738s/20 iters), loss = 0.301578
I0522 10:17:25.245712 19861 solver.cpp:258]     Train net output #0: loss = 0.301578 (* 1 = 0.301578 loss)
I0522 10:17:25.245720 19861 sgd_solver.cpp:112] Iteration 1720, lr = 0.001
I0522 10:17:27.745898 19861 solver.cpp:239] Iteration 1740 (7.99942 iter/s, 2.50018s/20 iters), loss = 0.255384
I0522 10:17:27.745954 19861 solver.cpp:258]     Train net output #0: loss = 0.255384 (* 1 = 0.255384 loss)
I0522 10:17:27.745957 19861 sgd_solver.cpp:112] Iteration 1740, lr = 0.001
I0522 10:17:30.018801 19861 solver.cpp:239] Iteration 1760 (8.79955 iter/s, 2.27284s/20 iters), loss = 0.326455
I0522 10:17:30.018857 19861 solver.cpp:258]     Train net output #0: loss = 0.326455 (* 1 = 0.326455 loss)
I0522 10:17:30.018860 19861 sgd_solver.cpp:112] Iteration 1760, lr = 0.001
I0522 10:17:32.287710 19861 solver.cpp:239] Iteration 1780 (8.81505 iter/s, 2.26885s/20 iters), loss = 0.289525
I0522 10:17:32.287767 19861 solver.cpp:258]     Train net output #0: loss = 0.289525 (* 1 = 0.289525 loss)
I0522 10:17:32.287770 19861 sgd_solver.cpp:112] Iteration 1780, lr = 0.001
I0522 10:17:34.820457 19861 solver.cpp:239] Iteration 1800 (7.89674 iter/s, 2.53269s/20 iters), loss = 0.330671
I0522 10:17:34.820497 19861 solver.cpp:258]     Train net output #0: loss = 0.330671 (* 1 = 0.330671 loss)
I0522 10:17:34.820500 19861 sgd_solver.cpp:112] Iteration 1800, lr = 0.001
I0522 10:17:37.101063 19861 solver.cpp:239] Iteration 1820 (8.76978 iter/s, 2.28056s/20 iters), loss = 0.336438
I0522 10:17:37.101125 19861 solver.cpp:258]     Train net output #0: loss = 0.336438 (* 1 = 0.336438 loss)
I0522 10:17:37.101128 19861 sgd_solver.cpp:112] Iteration 1820, lr = 0.001
I0522 10:17:38.923986 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:17:39.363517 19861 solver.cpp:239] Iteration 1840 (8.84022 iter/s, 2.26239s/20 iters), loss = 0.25222
I0522 10:17:39.363571 19861 solver.cpp:258]     Train net output #0: loss = 0.25222 (* 1 = 0.25222 loss)
I0522 10:17:39.363576 19861 sgd_solver.cpp:112] Iteration 1840, lr = 0.001
I0522 10:17:41.904055 19861 solver.cpp:239] Iteration 1860 (7.87255 iter/s, 2.54047s/20 iters), loss = 0.168917
I0522 10:17:41.904115 19861 solver.cpp:258]     Train net output #0: loss = 0.168917 (* 1 = 0.168917 loss)
I0522 10:17:41.904119 19861 sgd_solver.cpp:112] Iteration 1860, lr = 0.001
I0522 10:17:44.163543 19861 solver.cpp:239] Iteration 1880 (8.85185 iter/s, 2.25942s/20 iters), loss = 0.22207
I0522 10:17:44.163616 19861 solver.cpp:258]     Train net output #0: loss = 0.22207 (* 1 = 0.22207 loss)
I0522 10:17:44.163621 19861 sgd_solver.cpp:112] Iteration 1880, lr = 0.001
I0522 10:17:46.416163 19861 solver.cpp:239] Iteration 1900 (8.87888 iter/s, 2.25254s/20 iters), loss = 0.187112
I0522 10:17:46.416234 19861 solver.cpp:258]     Train net output #0: loss = 0.187112 (* 1 = 0.187112 loss)
I0522 10:17:46.416237 19861 sgd_solver.cpp:112] Iteration 1900, lr = 0.001
I0522 10:17:48.862586 19861 solver.cpp:239] Iteration 1920 (8.17548 iter/s, 2.44634s/20 iters), loss = 0.219046
I0522 10:17:48.862656 19861 solver.cpp:258]     Train net output #0: loss = 0.219046 (* 1 = 0.219046 loss)
I0522 10:17:48.862660 19861 sgd_solver.cpp:112] Iteration 1920, lr = 0.001
I0522 10:17:51.122964 19861 solver.cpp:239] Iteration 1940 (8.84838 iter/s, 2.2603s/20 iters), loss = 0.316246
I0522 10:17:51.123023 19861 solver.cpp:258]     Train net output #0: loss = 0.316246 (* 1 = 0.316246 loss)
I0522 10:17:51.123026 19861 sgd_solver.cpp:112] Iteration 1940, lr = 0.001
I0522 10:17:53.369262 19861 solver.cpp:239] Iteration 1960 (8.9038 iter/s, 2.24623s/20 iters), loss = 0.167064
I0522 10:17:53.369504 19861 solver.cpp:258]     Train net output #0: loss = 0.167064 (* 1 = 0.167064 loss)
I0522 10:17:53.369509 19861 sgd_solver.cpp:112] Iteration 1960, lr = 0.001
I0522 10:17:56.029690 19861 solver.cpp:239] Iteration 1980 (7.5183 iter/s, 2.66018s/20 iters), loss = 0.181694
I0522 10:17:56.029762 19861 solver.cpp:258]     Train net output #0: loss = 0.181694 (* 1 = 0.181694 loss)
I0522 10:17:56.029767 19861 sgd_solver.cpp:112] Iteration 1980, lr = 0.001
I0522 10:17:57.075848 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:17:58.092499 19861 solver.cpp:347] Iteration 2000, Testing net (#0)
I0522 10:17:58.500252 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:18:01.346204 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:18:02.643586 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:18:06.578820 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:18:10.687606 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:18:14.141840 19861 solver.cpp:414]     Test net output #0: accuracy = 0.795221
I0522 10:18:14.141880 19861 solver.cpp:414]     Test net output #1: loss = 0.757577 (* 1 = 0.757577 loss)
I0522 10:18:14.238610 19861 solver.cpp:239] Iteration 2000 (1.09836 iter/s, 18.2089s/20 iters), loss = 0.222895
I0522 10:18:14.241888 19861 solver.cpp:258]     Train net output #0: loss = 0.222895 (* 1 = 0.222895 loss)
I0522 10:18:14.241899 19861 sgd_solver.cpp:112] Iteration 2000, lr = 0.001
I0522 10:18:16.420011 19861 solver.cpp:239] Iteration 2020 (9.1822 iter/s, 2.17813s/20 iters), loss = 0.177702
I0522 10:18:16.433264 19861 solver.cpp:258]     Train net output #0: loss = 0.177702 (* 1 = 0.177702 loss)
I0522 10:18:16.433270 19861 sgd_solver.cpp:112] Iteration 2020, lr = 0.001
I0522 10:18:18.757479 19861 solver.cpp:239] Iteration 2040 (8.60508 iter/s, 2.32421s/20 iters), loss = 0.210192
I0522 10:18:18.766934 19861 solver.cpp:258]     Train net output #0: loss = 0.210192 (* 1 = 0.210192 loss)
I0522 10:18:18.766942 19861 sgd_solver.cpp:112] Iteration 2040, lr = 0.001
I0522 10:18:20.886250 19861 solver.cpp:239] Iteration 2060 (9.43699 iter/s, 2.11932s/20 iters), loss = 0.131727
I0522 10:18:20.886277 19861 solver.cpp:258]     Train net output #0: loss = 0.131727 (* 1 = 0.131727 loss)
I0522 10:18:20.886281 19861 sgd_solver.cpp:112] Iteration 2060, lr = 0.001
I0522 10:18:22.999523 19861 solver.cpp:239] Iteration 2080 (9.46416 iter/s, 2.11324s/20 iters), loss = 0.158794
I0522 10:18:23.009387 19861 solver.cpp:258]     Train net output #0: loss = 0.158794 (* 1 = 0.158794 loss)
I0522 10:18:23.009393 19861 sgd_solver.cpp:112] Iteration 2080, lr = 0.001
I0522 10:18:25.123606 19861 solver.cpp:239] Iteration 2100 (9.45978 iter/s, 2.11421s/20 iters), loss = 0.136745
I0522 10:18:25.123858 19861 solver.cpp:258]     Train net output #0: loss = 0.136745 (* 1 = 0.136745 loss)
I0522 10:18:25.123863 19861 sgd_solver.cpp:112] Iteration 2100, lr = 0.001
I0522 10:18:27.572495 19861 solver.cpp:239] Iteration 2120 (8.16783 iter/s, 2.44863s/20 iters), loss = 0.160533
I0522 10:18:27.584342 19861 solver.cpp:258]     Train net output #0: loss = 0.160533 (* 1 = 0.160533 loss)
I0522 10:18:27.584352 19861 sgd_solver.cpp:112] Iteration 2120, lr = 0.001
I0522 10:18:29.685384 19861 solver.cpp:239] Iteration 2140 (9.51912 iter/s, 2.10104s/20 iters), loss = 0.117763
I0522 10:18:29.685437 19861 solver.cpp:258]     Train net output #0: loss = 0.117763 (* 1 = 0.117763 loss)
I0522 10:18:29.685441 19861 sgd_solver.cpp:112] Iteration 2140, lr = 0.001
I0522 10:18:29.954381 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:18:31.829727 19861 solver.cpp:239] Iteration 2160 (9.32716 iter/s, 2.14428s/20 iters), loss = 0.210978
I0522 10:18:31.839134 19861 solver.cpp:258]     Train net output #0: loss = 0.210978 (* 1 = 0.210978 loss)
I0522 10:18:31.839143 19861 sgd_solver.cpp:112] Iteration 2160, lr = 0.001
I0522 10:18:34.133713 19861 solver.cpp:239] Iteration 2180 (8.71622 iter/s, 2.29457s/20 iters), loss = 0.161778
I0522 10:18:34.146955 19861 solver.cpp:258]     Train net output #0: loss = 0.161778 (* 1 = 0.161778 loss)
I0522 10:18:34.146962 19861 sgd_solver.cpp:112] Iteration 2180, lr = 0.001
I0522 10:18:36.269493 19861 solver.cpp:239] Iteration 2200 (9.42264 iter/s, 2.12255s/20 iters), loss = 0.131127
I0522 10:18:36.269520 19861 solver.cpp:258]     Train net output #0: loss = 0.131127 (* 1 = 0.131127 loss)
I0522 10:18:36.269523 19861 sgd_solver.cpp:112] Iteration 2200, lr = 0.001
I0522 10:18:38.421759 19861 solver.cpp:239] Iteration 2220 (9.29269 iter/s, 2.15223s/20 iters), loss = 0.13373
I0522 10:18:38.421811 19861 solver.cpp:258]     Train net output #0: loss = 0.13373 (* 1 = 0.13373 loss)
I0522 10:18:38.421815 19861 sgd_solver.cpp:112] Iteration 2220, lr = 0.001
I0522 10:18:40.559336 19861 solver.cpp:239] Iteration 2240 (9.3567 iter/s, 2.13751s/20 iters), loss = 0.147462
I0522 10:18:40.573251 19861 solver.cpp:258]     Train net output #0: loss = 0.147462 (* 1 = 0.147462 loss)
I0522 10:18:40.573261 19861 sgd_solver.cpp:112] Iteration 2240, lr = 0.001
I0522 10:18:41.425846 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:18:43.002058 19861 solver.cpp:239] Iteration 2260 (8.23454 iter/s, 2.42879s/20 iters), loss = 0.118443
I0522 10:18:43.002140 19861 solver.cpp:258]     Train net output #0: loss = 0.118443 (* 1 = 0.118443 loss)
I0522 10:18:43.002144 19861 sgd_solver.cpp:112] Iteration 2260, lr = 0.001
I0522 10:18:45.165081 19861 solver.cpp:239] Iteration 2280 (9.2467 iter/s, 2.16293s/20 iters), loss = 0.142282
I0522 10:18:45.179265 19861 solver.cpp:258]     Train net output #0: loss = 0.142282 (* 1 = 0.142282 loss)
I0522 10:18:45.179271 19861 sgd_solver.cpp:112] Iteration 2280, lr = 0.001
I0522 10:18:46.836155 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:18:47.334143 19861 solver.cpp:239] Iteration 2300 (9.28127 iter/s, 2.15488s/20 iters), loss = 0.122763
I0522 10:18:47.344764 19861 solver.cpp:258]     Train net output #0: loss = 0.122763 (* 1 = 0.122763 loss)
I0522 10:18:47.344772 19861 sgd_solver.cpp:112] Iteration 2300, lr = 0.001
I0522 10:18:49.798250 19861 solver.cpp:239] Iteration 2320 (8.15175 iter/s, 2.45346s/20 iters), loss = 0.124739
I0522 10:18:49.798363 19861 solver.cpp:258]     Train net output #0: loss = 0.124739 (* 1 = 0.124739 loss)
I0522 10:18:49.798369 19861 sgd_solver.cpp:112] Iteration 2320, lr = 0.001
I0522 10:18:51.938112 19861 solver.cpp:239] Iteration 2340 (9.34697 iter/s, 2.13973s/20 iters), loss = 0.109244
I0522 10:18:51.948094 19861 solver.cpp:258]     Train net output #0: loss = 0.109244 (* 1 = 0.109244 loss)
I0522 10:18:51.948102 19861 sgd_solver.cpp:112] Iteration 2340, lr = 0.001
I0522 10:18:54.108561 19861 solver.cpp:239] Iteration 2360 (9.25727 iter/s, 2.16046s/20 iters), loss = 0.174737
I0522 10:18:54.117686 19861 solver.cpp:258]     Train net output #0: loss = 0.174737 (* 1 = 0.174737 loss)
I0522 10:18:54.117720 19861 sgd_solver.cpp:112] Iteration 2360, lr = 0.001
I0522 10:18:56.250308 19861 solver.cpp:239] Iteration 2380 (9.37815 iter/s, 2.13262s/20 iters), loss = 0.202037
I0522 10:18:56.250526 19861 solver.cpp:258]     Train net output #0: loss = 0.202037 (* 1 = 0.202037 loss)
I0522 10:18:56.250531 19861 sgd_solver.cpp:112] Iteration 2380, lr = 0.001
I0522 10:18:58.843297 19861 solver.cpp:239] Iteration 2400 (7.71383 iter/s, 2.59274s/20 iters), loss = 0.180675
I0522 10:18:58.843410 19861 solver.cpp:258]     Train net output #0: loss = 0.180674 (* 1 = 0.180674 loss)
I0522 10:18:58.843416 19861 sgd_solver.cpp:112] Iteration 2400, lr = 0.001
I0522 10:19:00.987712 19861 solver.cpp:239] Iteration 2420 (9.32715 iter/s, 2.14428s/20 iters), loss = 0.113932
I0522 10:19:00.987799 19861 solver.cpp:258]     Train net output #0: loss = 0.113932 (* 1 = 0.113932 loss)
I0522 10:19:00.987805 19861 sgd_solver.cpp:112] Iteration 2420, lr = 0.001
I0522 10:19:03.137542 19861 solver.cpp:239] Iteration 2440 (9.30352 iter/s, 2.14972s/20 iters), loss = 0.103369
I0522 10:19:03.137624 19861 solver.cpp:258]     Train net output #0: loss = 0.103369 (* 1 = 0.103369 loss)
I0522 10:19:03.137631 19861 sgd_solver.cpp:112] Iteration 2440, lr = 0.001
I0522 10:19:04.287557 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:19:05.503010 19861 solver.cpp:239] Iteration 2460 (8.45536 iter/s, 2.36536s/20 iters), loss = 0.145866
I0522 10:19:05.503108 19861 solver.cpp:258]     Train net output #0: loss = 0.145866 (* 1 = 0.145866 loss)
I0522 10:19:05.503113 19861 sgd_solver.cpp:112] Iteration 2460, lr = 0.001
I0522 10:19:07.661960 19861 solver.cpp:239] Iteration 2480 (9.2642 iter/s, 2.15885s/20 iters), loss = 0.136147
I0522 10:19:07.662014 19861 solver.cpp:258]     Train net output #0: loss = 0.136147 (* 1 = 0.136147 loss)
I0522 10:19:07.662019 19861 sgd_solver.cpp:112] Iteration 2480, lr = 0.001
I0522 10:19:09.834548 19861 solver.cpp:239] Iteration 2500 (9.20586 iter/s, 2.17253s/20 iters), loss = 0.0896301
I0522 10:19:09.834602 19861 solver.cpp:258]     Train net output #0: loss = 0.0896301 (* 1 = 0.0896301 loss)
I0522 10:19:09.834607 19861 sgd_solver.cpp:112] Iteration 2500, lr = 0.001
I0522 10:19:12.200264 19861 solver.cpp:239] Iteration 2520 (8.45437 iter/s, 2.36564s/20 iters), loss = 0.0902251
I0522 10:19:12.200352 19861 solver.cpp:258]     Train net output #0: loss = 0.0902251 (* 1 = 0.0902251 loss)
I0522 10:19:12.200359 19861 sgd_solver.cpp:112] Iteration 2520, lr = 0.001
I0522 10:19:14.371799 19861 solver.cpp:239] Iteration 2540 (9.21054 iter/s, 2.17142s/20 iters), loss = 0.118173
I0522 10:19:14.371889 19861 solver.cpp:258]     Train net output #0: loss = 0.118172 (* 1 = 0.118172 loss)
I0522 10:19:14.371894 19861 sgd_solver.cpp:112] Iteration 2540, lr = 0.001
I0522 10:19:16.533680 19861 solver.cpp:239] Iteration 2560 (9.25164 iter/s, 2.16178s/20 iters), loss = 0.0860331
I0522 10:19:16.547726 19861 solver.cpp:258]     Train net output #0: loss = 0.086033 (* 1 = 0.086033 loss)
I0522 10:19:16.547735 19861 sgd_solver.cpp:112] Iteration 2560, lr = 0.001
I0522 10:19:18.986898 19861 solver.cpp:239] Iteration 2580 (8.19953 iter/s, 2.43916s/20 iters), loss = 0.158122
I0522 10:19:19.000658 19861 solver.cpp:258]     Train net output #0: loss = 0.158122 (* 1 = 0.158122 loss)
I0522 10:19:19.000666 19861 sgd_solver.cpp:112] Iteration 2580, lr = 0.001
I0522 10:19:21.131467 19861 solver.cpp:239] Iteration 2600 (9.38613 iter/s, 2.1308s/20 iters), loss = 0.101446
I0522 10:19:21.131521 19861 solver.cpp:258]     Train net output #0: loss = 0.101446 (* 1 = 0.101446 loss)
I0522 10:19:21.131527 19861 sgd_solver.cpp:112] Iteration 2600, lr = 0.001
I0522 10:19:21.327041 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:19:23.258236 19861 solver.cpp:239] Iteration 2620 (9.4043 iter/s, 2.12669s/20 iters), loss = 0.0709023
I0522 10:19:23.258338 19861 solver.cpp:258]     Train net output #0: loss = 0.0709023 (* 1 = 0.0709023 loss)
I0522 10:19:23.258344 19861 sgd_solver.cpp:112] Iteration 2620, lr = 0.001
I0522 10:19:25.664351 19861 solver.cpp:239] Iteration 2640 (8.31251 iter/s, 2.40601s/20 iters), loss = 0.125716
I0522 10:19:25.674764 19861 solver.cpp:258]     Train net output #0: loss = 0.125716 (* 1 = 0.125716 loss)
I0522 10:19:25.674837 19861 sgd_solver.cpp:112] Iteration 2640, lr = 0.001
I0522 10:19:27.915683 19861 solver.cpp:239] Iteration 2660 (8.92492 iter/s, 2.24092s/20 iters), loss = 0.0777193
I0522 10:19:27.925495 19861 solver.cpp:258]     Train net output #0: loss = 0.0777193 (* 1 = 0.0777193 loss)
I0522 10:19:27.925506 19861 sgd_solver.cpp:112] Iteration 2660, lr = 0.001
I0522 10:19:30.055979 19861 solver.cpp:239] Iteration 2680 (9.38757 iter/s, 2.13048s/20 iters), loss = 0.0893773
I0522 10:19:30.056053 19861 solver.cpp:258]     Train net output #0: loss = 0.0893772 (* 1 = 0.0893772 loss)
I0522 10:19:30.056058 19861 sgd_solver.cpp:112] Iteration 2680, lr = 0.001
I0522 10:19:32.310587 19861 solver.cpp:239] Iteration 2700 (8.87103 iter/s, 2.25453s/20 iters), loss = 0.102992
I0522 10:19:32.310638 19861 solver.cpp:258]     Train net output #0: loss = 0.102992 (* 1 = 0.102992 loss)
I0522 10:19:32.310643 19861 sgd_solver.cpp:112] Iteration 2700, lr = 0.001
I0522 10:19:34.739426 19861 solver.cpp:239] Iteration 2720 (8.23456 iter/s, 2.42879s/20 iters), loss = 0.0862425
I0522 10:19:34.748831 19861 solver.cpp:258]     Train net output #0: loss = 0.0862425 (* 1 = 0.0862425 loss)
I0522 10:19:34.748838 19861 sgd_solver.cpp:112] Iteration 2720, lr = 0.001
I0522 10:19:36.910523 19861 solver.cpp:239] Iteration 2740 (9.25208 iter/s, 2.16168s/20 iters), loss = 0.1023
I0522 10:19:36.910594 19861 solver.cpp:258]     Train net output #0: loss = 0.1023 (* 1 = 0.1023 loss)
I0522 10:19:36.910598 19861 sgd_solver.cpp:112] Iteration 2740, lr = 0.001
I0522 10:19:38.526175 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:19:39.090597 19861 solver.cpp:239] Iteration 2760 (9.17439 iter/s, 2.17998s/20 iters), loss = 0.10099
I0522 10:19:39.090682 19861 solver.cpp:258]     Train net output #0: loss = 0.10099 (* 1 = 0.10099 loss)
I0522 10:19:39.090685 19861 sgd_solver.cpp:112] Iteration 2760, lr = 0.001
I0522 10:19:41.548738 19861 solver.cpp:239] Iteration 2780 (8.13651 iter/s, 2.45806s/20 iters), loss = 0.0897296
I0522 10:19:41.548779 19861 solver.cpp:258]     Train net output #0: loss = 0.0897295 (* 1 = 0.0897295 loss)
I0522 10:19:41.548782 19861 sgd_solver.cpp:112] Iteration 2780, lr = 0.001
I0522 10:19:43.770045 19861 solver.cpp:239] Iteration 2800 (9.00391 iter/s, 2.22126s/20 iters), loss = 0.0680261
I0522 10:19:43.770130 19861 solver.cpp:258]     Train net output #0: loss = 0.0680261 (* 1 = 0.0680261 loss)
I0522 10:19:43.770134 19861 sgd_solver.cpp:112] Iteration 2800, lr = 0.001
I0522 10:19:45.910908 19861 solver.cpp:239] Iteration 2820 (9.34243 iter/s, 2.14077s/20 iters), loss = 0.0953055
I0522 10:19:45.910960 19861 solver.cpp:258]     Train net output #0: loss = 0.0953055 (* 1 = 0.0953055 loss)
I0522 10:19:45.910964 19861 sgd_solver.cpp:112] Iteration 2820, lr = 0.001
I0522 10:19:48.320093 19861 solver.cpp:239] Iteration 2840 (8.30175 iter/s, 2.40913s/20 iters), loss = 0.0968278
I0522 10:19:48.320149 19861 solver.cpp:258]     Train net output #0: loss = 0.0968277 (* 1 = 0.0968277 loss)
I0522 10:19:48.320153 19861 sgd_solver.cpp:112] Iteration 2840, lr = 0.001
I0522 10:19:50.511941 19861 solver.cpp:239] Iteration 2860 (9.12505 iter/s, 2.19177s/20 iters), loss = 0.096665
I0522 10:19:50.512024 19861 solver.cpp:258]     Train net output #0: loss = 0.0966649 (* 1 = 0.0966649 loss)
I0522 10:19:50.512029 19861 sgd_solver.cpp:112] Iteration 2860, lr = 0.001
I0522 10:19:52.722718 19861 solver.cpp:239] Iteration 2880 (9.047 iter/s, 2.21068s/20 iters), loss = 0.0982175
I0522 10:19:52.722791 19861 solver.cpp:258]     Train net output #0: loss = 0.0982175 (* 1 = 0.0982175 loss)
I0522 10:19:52.722795 19861 sgd_solver.cpp:112] Iteration 2880, lr = 0.001
I0522 10:19:55.226928 19861 solver.cpp:239] Iteration 2900 (7.98679 iter/s, 2.50413s/20 iters), loss = 0.0876546
I0522 10:19:55.226982 19861 solver.cpp:258]     Train net output #0: loss = 0.0876546 (* 1 = 0.0876546 loss)
I0522 10:19:55.226989 19861 sgd_solver.cpp:112] Iteration 2900, lr = 0.001
I0522 10:19:56.114444 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:19:57.371690 19861 solver.cpp:239] Iteration 2920 (9.32534 iter/s, 2.14469s/20 iters), loss = 0.0851808
I0522 10:19:57.386023 19861 solver.cpp:258]     Train net output #0: loss = 0.0851807 (* 1 = 0.0851807 loss)
I0522 10:19:57.386067 19861 sgd_solver.cpp:112] Iteration 2920, lr = 0.001
I0522 10:19:59.545519 19861 solver.cpp:239] Iteration 2940 (9.26144 iter/s, 2.15949s/20 iters), loss = 0.0963009
I0522 10:19:59.554987 19861 solver.cpp:258]     Train net output #0: loss = 0.0963009 (* 1 = 0.0963009 loss)
I0522 10:19:59.554994 19861 sgd_solver.cpp:112] Iteration 2940, lr = 0.001
I0522 10:20:01.811164 19861 solver.cpp:239] Iteration 2960 (8.86456 iter/s, 2.25618s/20 iters), loss = 0.0462382
I0522 10:20:01.821306 19861 solver.cpp:258]     Train net output #0: loss = 0.0462382 (* 1 = 0.0462382 loss)
I0522 10:20:01.821314 19861 sgd_solver.cpp:112] Iteration 2960, lr = 0.001
I0522 10:20:04.188700 19861 solver.cpp:239] Iteration 2980 (8.44813 iter/s, 2.36739s/20 iters), loss = 0.0718885
I0522 10:20:04.188760 19861 solver.cpp:258]     Train net output #0: loss = 0.0718885 (* 1 = 0.0718885 loss)
I0522 10:20:04.188766 19861 sgd_solver.cpp:112] Iteration 2980, lr = 0.001
I0522 10:20:06.195214 19861 solver.cpp:347] Iteration 3000, Testing net (#0)
I0522 10:20:06.781234 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:20:11.077560 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:20:11.393446 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:20:15.062930 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:20:19.165741 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:20:22.461146 19861 solver.cpp:414]     Test net output #0: accuracy = 0.838142
I0522 10:20:22.461261 19861 solver.cpp:414]     Test net output #1: loss = 0.682432 (* 1 = 0.682432 loss)
I0522 10:20:22.563628 19861 solver.cpp:239] Iteration 3000 (1.08844 iter/s, 18.375s/20 iters), loss = 0.0831702
I0522 10:20:22.566210 19861 solver.cpp:258]     Train net output #0: loss = 0.0831702 (* 1 = 0.0831702 loss)
I0522 10:20:22.566220 19861 sgd_solver.cpp:112] Iteration 3000, lr = 0.001
I0522 10:20:24.993496 19861 solver.cpp:239] Iteration 3020 (8.23968 iter/s, 2.42728s/20 iters), loss = 0.0522488
I0522 10:20:24.993562 19861 solver.cpp:258]     Train net output #0: loss = 0.0522487 (* 1 = 0.0522487 loss)
I0522 10:20:24.993567 19861 sgd_solver.cpp:112] Iteration 3020, lr = 0.001
I0522 10:20:27.163116 19861 solver.cpp:239] Iteration 3040 (9.21851 iter/s, 2.16955s/20 iters), loss = 0.0860044
I0522 10:20:27.163161 19861 solver.cpp:258]     Train net output #0: loss = 0.0860044 (* 1 = 0.0860044 loss)
I0522 10:20:27.163164 19861 sgd_solver.cpp:112] Iteration 3040, lr = 0.001
I0522 10:20:29.288990 19861 solver.cpp:239] Iteration 3060 (9.40808 iter/s, 2.12583s/20 iters), loss = 0.0643417
I0522 10:20:29.289016 19861 solver.cpp:258]     Train net output #0: loss = 0.0643416 (* 1 = 0.0643416 loss)
I0522 10:20:29.289019 19861 sgd_solver.cpp:112] Iteration 3060, lr = 0.001
I0522 10:20:29.449084 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:20:31.485652 19861 solver.cpp:239] Iteration 3080 (9.10542 iter/s, 2.19649s/20 iters), loss = 0.0665091
I0522 10:20:31.487510 19861 solver.cpp:258]     Train net output #0: loss = 0.0665091 (* 1 = 0.0665091 loss)
I0522 10:20:31.487519 19861 sgd_solver.cpp:112] Iteration 3080, lr = 0.001
I0522 10:20:33.987195 19861 solver.cpp:239] Iteration 3100 (8.0011 iter/s, 2.49966s/20 iters), loss = 0.0432561
I0522 10:20:33.996842 19861 solver.cpp:258]     Train net output #0: loss = 0.0432561 (* 1 = 0.0432561 loss)
I0522 10:20:33.996850 19861 sgd_solver.cpp:112] Iteration 3100, lr = 0.001
I0522 10:20:36.026744 19861 solver.cpp:239] Iteration 3120 (9.85275 iter/s, 2.02989s/20 iters), loss = 0.0400969
I0522 10:20:36.036494 19861 solver.cpp:258]     Train net output #0: loss = 0.0400969 (* 1 = 0.0400969 loss)
I0522 10:20:36.036504 19861 sgd_solver.cpp:112] Iteration 3120, lr = 0.001
I0522 10:20:38.068542 19861 solver.cpp:239] Iteration 3140 (9.84234 iter/s, 2.03204s/20 iters), loss = 0.0736252
I0522 10:20:38.078516 19861 solver.cpp:258]     Train net output #0: loss = 0.0736251 (* 1 = 0.0736251 loss)
I0522 10:20:38.078523 19861 sgd_solver.cpp:112] Iteration 3140, lr = 0.001
I0522 10:20:40.112193 19861 solver.cpp:239] Iteration 3160 (9.83448 iter/s, 2.03366s/20 iters), loss = 0.0631366
I0522 10:20:40.121714 19861 solver.cpp:258]     Train net output #0: loss = 0.0631366 (* 1 = 0.0631366 loss)
I0522 10:20:40.121722 19861 sgd_solver.cpp:112] Iteration 3160, lr = 0.001
I0522 10:20:43.455926 19861 solver.cpp:239] Iteration 3180 (5.99842 iter/s, 3.33421s/20 iters), loss = 0.057074
I0522 10:20:43.465104 19861 solver.cpp:258]     Train net output #0: loss = 0.057074 (* 1 = 0.057074 loss)
I0522 10:20:43.465113 19861 sgd_solver.cpp:112] Iteration 3180, lr = 0.001
I0522 10:20:45.839881 19861 solver.cpp:239] Iteration 3200 (8.42188 iter/s, 2.37477s/20 iters), loss = 0.0818714
I0522 10:20:45.849303 19861 solver.cpp:258]     Train net output #0: loss = 0.0818714 (* 1 = 0.0818714 loss)
I0522 10:20:45.849313 19861 sgd_solver.cpp:112] Iteration 3200, lr = 0.001
I0522 10:20:47.327035 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:20:47.886308 19861 solver.cpp:239] Iteration 3220 (9.8184 iter/s, 2.03699s/20 iters), loss = 0.11478
I0522 10:20:47.895808 19861 solver.cpp:258]     Train net output #0: loss = 0.11478 (* 1 = 0.11478 loss)
I0522 10:20:47.895818 19861 sgd_solver.cpp:112] Iteration 3220, lr = 0.001
I0522 10:20:49.935587 19861 solver.cpp:239] Iteration 3240 (9.80503 iter/s, 2.03977s/20 iters), loss = 0.0329585
I0522 10:20:49.935673 19861 solver.cpp:258]     Train net output #0: loss = 0.0329585 (* 1 = 0.0329585 loss)
I0522 10:20:49.935683 19861 sgd_solver.cpp:112] Iteration 3240, lr = 0.001
I0522 10:20:52.029143 19861 solver.cpp:239] Iteration 3260 (9.5537 iter/s, 2.09343s/20 iters), loss = 0.0742797
I0522 10:20:52.029291 19861 solver.cpp:258]     Train net output #0: loss = 0.0742797 (* 1 = 0.0742797 loss)
I0522 10:20:52.029305 19861 sgd_solver.cpp:112] Iteration 3260, lr = 0.001
I0522 10:20:55.643857 19861 solver.cpp:239] Iteration 3280 (5.53323 iter/s, 3.61452s/20 iters), loss = 0.0411007
I0522 10:20:55.643901 19861 solver.cpp:258]     Train net output #0: loss = 0.0411007 (* 1 = 0.0411007 loss)
I0522 10:20:55.643905 19861 sgd_solver.cpp:112] Iteration 3280, lr = 0.001
I0522 10:20:57.846333 19861 solver.cpp:239] Iteration 3300 (9.08094 iter/s, 2.20242s/20 iters), loss = 0.0498031
I0522 10:20:57.846427 19861 solver.cpp:258]     Train net output #0: loss = 0.0498031 (* 1 = 0.0498031 loss)
I0522 10:20:57.846432 19861 sgd_solver.cpp:112] Iteration 3300, lr = 0.001
I0522 10:20:59.959055 19861 solver.cpp:239] Iteration 3320 (9.46693 iter/s, 2.11262s/20 iters), loss = 0.0901887
I0522 10:20:59.969022 19861 solver.cpp:258]     Train net output #0: loss = 0.0901887 (* 1 = 0.0901887 loss)
I0522 10:20:59.969030 19861 sgd_solver.cpp:112] Iteration 3320, lr = 0.001
I0522 10:21:01.997638 19861 solver.cpp:239] Iteration 3340 (9.85896 iter/s, 2.02861s/20 iters), loss = 0.0550388
I0522 10:21:02.007238 19861 solver.cpp:258]     Train net output #0: loss = 0.0550388 (* 1 = 0.0550388 loss)
I0522 10:21:02.007252 19861 sgd_solver.cpp:112] Iteration 3340, lr = 0.001
I0522 10:21:05.198289 19861 solver.cpp:239] Iteration 3360 (6.26751 iter/s, 3.19106s/20 iters), loss = 0.0538416
I0522 10:21:05.207523 19861 solver.cpp:258]     Train net output #0: loss = 0.0538416 (* 1 = 0.0538416 loss)
I0522 10:21:05.207530 19861 sgd_solver.cpp:112] Iteration 3360, lr = 0.001
I0522 10:21:06.365916 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:21:07.628329 19861 solver.cpp:239] Iteration 3380 (8.2618 iter/s, 2.42078s/20 iters), loss = 0.0752569
I0522 10:21:07.638425 19861 solver.cpp:258]     Train net output #0: loss = 0.0752569 (* 1 = 0.0752569 loss)
I0522 10:21:07.638438 19861 sgd_solver.cpp:112] Iteration 3380, lr = 0.001
I0522 10:21:09.509943 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:21:09.670295 19861 solver.cpp:239] Iteration 3400 (9.84314 iter/s, 2.03187s/20 iters), loss = 0.0542203
I0522 10:21:09.679669 19861 solver.cpp:258]     Train net output #0: loss = 0.0542203 (* 1 = 0.0542203 loss)
I0522 10:21:09.679682 19861 sgd_solver.cpp:112] Iteration 3400, lr = 0.001
I0522 10:21:11.713479 19861 solver.cpp:239] Iteration 3420 (9.83382 iter/s, 2.0338s/20 iters), loss = 0.038688
I0522 10:21:11.722928 19861 solver.cpp:258]     Train net output #0: loss = 0.038688 (* 1 = 0.038688 loss)
I0522 10:21:11.722937 19861 sgd_solver.cpp:112] Iteration 3420, lr = 0.001
I0522 10:21:13.760918 19861 solver.cpp:239] Iteration 3440 (9.81373 iter/s, 2.03796s/20 iters), loss = 0.0452274
I0522 10:21:13.761013 19861 solver.cpp:258]     Train net output #0: loss = 0.0452274 (* 1 = 0.0452274 loss)
I0522 10:21:13.761020 19861 sgd_solver.cpp:112] Iteration 3440, lr = 0.001
I0522 10:21:17.338752 19861 solver.cpp:239] Iteration 3460 (5.59015 iter/s, 3.57772s/20 iters), loss = 0.0477613
I0522 10:21:17.338837 19861 solver.cpp:258]     Train net output #0: loss = 0.0477612 (* 1 = 0.0477612 loss)
I0522 10:21:17.338841 19861 sgd_solver.cpp:112] Iteration 3460, lr = 0.001
I0522 10:21:19.391419 19861 solver.cpp:239] Iteration 3480 (9.74392 iter/s, 2.05256s/20 iters), loss = 0.0474894
I0522 10:21:19.401026 19861 solver.cpp:258]     Train net output #0: loss = 0.0474894 (* 1 = 0.0474894 loss)
I0522 10:21:19.401036 19861 sgd_solver.cpp:112] Iteration 3480, lr = 0.001
I0522 10:21:21.442607 19861 solver.cpp:239] Iteration 3500 (9.79642 iter/s, 2.04156s/20 iters), loss = 0.0536656
I0522 10:21:21.452289 19861 solver.cpp:258]     Train net output #0: loss = 0.0536656 (* 1 = 0.0536656 loss)
I0522 10:21:21.452297 19861 sgd_solver.cpp:112] Iteration 3500, lr = 0.001
I0522 10:21:23.491748 19861 solver.cpp:239] Iteration 3520 (9.80662 iter/s, 2.03944s/20 iters), loss = 0.0408881
I0522 10:21:23.501456 19861 solver.cpp:258]     Train net output #0: loss = 0.0408881 (* 1 = 0.0408881 loss)
I0522 10:21:23.501464 19861 sgd_solver.cpp:112] Iteration 3520, lr = 0.001
I0522 10:21:23.542176 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:21:26.431365 19861 solver.cpp:239] Iteration 3540 (6.82614 iter/s, 2.92991s/20 iters), loss = 0.0380492
I0522 10:21:26.440749 19861 solver.cpp:258]     Train net output #0: loss = 0.0380491 (* 1 = 0.0380491 loss)
I0522 10:21:26.440755 19861 sgd_solver.cpp:112] Iteration 3540, lr = 0.001
I0522 10:21:29.174795 19861 solver.cpp:239] Iteration 3560 (7.3152 iter/s, 2.73403s/20 iters), loss = 0.0377854
I0522 10:21:29.184494 19861 solver.cpp:258]     Train net output #0: loss = 0.0377854 (* 1 = 0.0377854 loss)
I0522 10:21:29.184501 19861 sgd_solver.cpp:112] Iteration 3560, lr = 0.001
I0522 10:21:31.228121 19861 solver.cpp:239] Iteration 3580 (9.78655 iter/s, 2.04362s/20 iters), loss = 0.0275421
I0522 10:21:31.237819 19861 solver.cpp:258]     Train net output #0: loss = 0.027542 (* 1 = 0.027542 loss)
I0522 10:21:31.237829 19861 sgd_solver.cpp:112] Iteration 3580, lr = 0.001
I0522 10:21:33.278765 19861 solver.cpp:239] Iteration 3600 (9.79944 iter/s, 2.04093s/20 iters), loss = 0.0658925
I0522 10:21:33.288233 19861 solver.cpp:258]     Train net output #0: loss = 0.0658925 (* 1 = 0.0658925 loss)
I0522 10:21:33.288242 19861 sgd_solver.cpp:112] Iteration 3600, lr = 0.001
I0522 10:21:35.332985 19861 solver.cpp:239] Iteration 3620 (9.7812 iter/s, 2.04474s/20 iters), loss = 0.0354787
I0522 10:21:35.342582 19861 solver.cpp:258]     Train net output #0: loss = 0.0354787 (* 1 = 0.0354787 loss)
I0522 10:21:35.342592 19861 sgd_solver.cpp:112] Iteration 3620, lr = 0.001
I0522 10:21:38.974496 19861 solver.cpp:239] Iteration 3640 (5.50672 iter/s, 3.63192s/20 iters), loss = 0.0620546
I0522 10:21:38.974541 19861 solver.cpp:258]     Train net output #0: loss = 0.0620545 (* 1 = 0.0620545 loss)
I0522 10:21:38.974545 19861 sgd_solver.cpp:112] Iteration 3640, lr = 0.001
I0522 10:21:41.064399 19861 solver.cpp:239] Iteration 3660 (9.57014 iter/s, 2.08983s/20 iters), loss = 0.0684234
I0522 10:21:41.073874 19861 solver.cpp:258]     Train net output #0: loss = 0.0684233 (* 1 = 0.0684233 loss)
I0522 10:21:41.073884 19861 sgd_solver.cpp:112] Iteration 3660, lr = 0.001
I0522 10:21:42.481642 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:21:43.112200 19861 solver.cpp:239] Iteration 3680 (9.81204 iter/s, 2.03831s/20 iters), loss = 0.0549379
I0522 10:21:43.121879 19861 solver.cpp:258]     Train net output #0: loss = 0.0549379 (* 1 = 0.0549379 loss)
I0522 10:21:43.121889 19861 sgd_solver.cpp:112] Iteration 3680, lr = 0.001
I0522 10:21:45.160416 19861 solver.cpp:239] Iteration 3700 (9.81101 iter/s, 2.03853s/20 iters), loss = 0.0256002
I0522 10:21:45.169939 19861 solver.cpp:258]     Train net output #0: loss = 0.0256002 (* 1 = 0.0256002 loss)
I0522 10:21:45.169950 19861 sgd_solver.cpp:112] Iteration 3700, lr = 0.001
I0522 10:21:47.740461 19861 solver.cpp:239] Iteration 3720 (7.78051 iter/s, 2.57053s/20 iters), loss = 0.0294722
I0522 10:21:47.750844 19861 solver.cpp:258]     Train net output #0: loss = 0.0294722 (* 1 = 0.0294722 loss)
I0522 10:21:47.750854 19861 sgd_solver.cpp:112] Iteration 3720, lr = 0.001
I0522 10:21:50.833787 19861 solver.cpp:239] Iteration 3740 (6.48732 iter/s, 3.08294s/20 iters), loss = 0.0543002
I0522 10:21:50.843648 19861 solver.cpp:258]     Train net output #0: loss = 0.0543002 (* 1 = 0.0543002 loss)
I0522 10:21:50.843658 19861 sgd_solver.cpp:112] Iteration 3740, lr = 0.001
I0522 10:21:52.879002 19861 solver.cpp:239] Iteration 3760 (9.82643 iter/s, 2.03533s/20 iters), loss = 0.0483273
I0522 10:21:52.888360 19861 solver.cpp:258]     Train net output #0: loss = 0.0483273 (* 1 = 0.0483273 loss)
I0522 10:21:52.888368 19861 sgd_solver.cpp:112] Iteration 3760, lr = 0.001
I0522 10:21:54.937978 19861 solver.cpp:239] Iteration 3780 (9.75801 iter/s, 2.0496s/20 iters), loss = 0.0463819
I0522 10:21:54.947489 19861 solver.cpp:258]     Train net output #0: loss = 0.0463818 (* 1 = 0.0463818 loss)
I0522 10:21:54.947497 19861 sgd_solver.cpp:112] Iteration 3780, lr = 0.001
I0522 10:21:56.987066 19861 solver.cpp:239] Iteration 3800 (9.80603 iter/s, 2.03956s/20 iters), loss = 0.0302435
I0522 10:21:56.996420 19861 solver.cpp:258]     Train net output #0: loss = 0.0302435 (* 1 = 0.0302435 loss)
I0522 10:21:56.996428 19861 sgd_solver.cpp:112] Iteration 3800, lr = 0.001
I0522 10:22:00.439774 19861 solver.cpp:239] Iteration 3820 (5.80834 iter/s, 3.44333s/20 iters), loss = 0.0449199
I0522 10:22:00.466655 19861 solver.cpp:258]     Train net output #0: loss = 0.0449199 (* 1 = 0.0449199 loss)
I0522 10:22:00.466665 19861 sgd_solver.cpp:112] Iteration 3820, lr = 0.001
I0522 10:22:01.517530 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:22:03.100535 19861 solver.cpp:239] Iteration 3840 (7.59633 iter/s, 2.63285s/20 iters), loss = 0.0465914
I0522 10:22:03.100603 19861 solver.cpp:258]     Train net output #0: loss = 0.0465913 (* 1 = 0.0465913 loss)
I0522 10:22:03.100613 19861 sgd_solver.cpp:112] Iteration 3840, lr = 0.001
I0522 10:22:05.329111 19861 solver.cpp:239] Iteration 3860 (8.97464 iter/s, 2.2285s/20 iters), loss = 0.0658626
I0522 10:22:05.329385 19861 solver.cpp:258]     Train net output #0: loss = 0.0658626 (* 1 = 0.0658626 loss)
I0522 10:22:05.329392 19861 sgd_solver.cpp:112] Iteration 3860, lr = 0.001
I0522 10:22:07.491257 19861 solver.cpp:239] Iteration 3880 (9.25137 iter/s, 2.16184s/20 iters), loss = 0.0683686
I0522 10:22:07.503305 19861 solver.cpp:258]     Train net output #0: loss = 0.0683686 (* 1 = 0.0683686 loss)
I0522 10:22:07.503317 19861 sgd_solver.cpp:112] Iteration 3880, lr = 0.001
I0522 10:22:09.559561 19861 solver.cpp:239] Iteration 3900 (9.72643 iter/s, 2.05625s/20 iters), loss = 0.0371554
I0522 10:22:09.568961 19861 solver.cpp:258]     Train net output #0: loss = 0.0371554 (* 1 = 0.0371554 loss)
I0522 10:22:09.568970 19861 sgd_solver.cpp:112] Iteration 3900, lr = 0.001
I0522 10:22:12.513553 19861 solver.cpp:239] Iteration 3920 (6.79211 iter/s, 2.94459s/20 iters), loss = 0.0492995
I0522 10:22:12.523160 19861 solver.cpp:258]     Train net output #0: loss = 0.0492995 (* 1 = 0.0492995 loss)
I0522 10:22:12.523167 19861 sgd_solver.cpp:112] Iteration 3920, lr = 0.001
I0522 10:22:15.200546 19861 solver.cpp:239] Iteration 3940 (7.47001 iter/s, 2.67737s/20 iters), loss = 0.0240894
I0522 10:22:15.210076 19861 solver.cpp:258]     Train net output #0: loss = 0.0240893 (* 1 = 0.0240893 loss)
I0522 10:22:15.210084 19861 sgd_solver.cpp:112] Iteration 3940, lr = 0.001
I0522 10:22:17.247851 19861 solver.cpp:239] Iteration 3960 (9.81468 iter/s, 2.03776s/20 iters), loss = 0.038403
I0522 10:22:17.257408 19861 solver.cpp:258]     Train net output #0: loss = 0.038403 (* 1 = 0.038403 loss)
I0522 10:22:17.257416 19861 sgd_solver.cpp:112] Iteration 3960, lr = 0.001
I0522 10:22:19.290812 19861 solver.cpp:239] Iteration 3980 (9.8358 iter/s, 2.03339s/20 iters), loss = 0.0218304
I0522 10:22:19.300343 19861 solver.cpp:258]     Train net output #0: loss = 0.0218304 (* 1 = 0.0218304 loss)
I0522 10:22:19.300351 19861 sgd_solver.cpp:112] Iteration 3980, lr = 0.001
I0522 10:22:19.311234 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:22:21.202636 19861 solver.cpp:347] Iteration 4000, Testing net (#0)
I0522 10:22:22.639905 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:22:26.993798 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:22:29.771323 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:22:30.671017 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:22:35.710194 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:22:38.642801 19861 solver.cpp:414]     Test net output #0: accuracy = 0.845162
I0522 10:22:38.642848 19861 solver.cpp:414]     Test net output #1: loss = 0.736883 (* 1 = 0.736883 loss)
I0522 10:22:38.740130 19861 solver.cpp:239] Iteration 4000 (1.02881 iter/s, 19.4398s/20 iters), loss = 0.0169369
I0522 10:22:38.742213 19861 solver.cpp:258]     Train net output #0: loss = 0.0169369 (* 1 = 0.0169369 loss)
I0522 10:22:38.742226 19861 sgd_solver.cpp:112] Iteration 4000, lr = 0.001
I0522 10:22:40.929298 19861 solver.cpp:239] Iteration 4020 (9.14464 iter/s, 2.18707s/20 iters), loss = 0.0188979
I0522 10:22:40.929358 19861 solver.cpp:258]     Train net output #0: loss = 0.0188979 (* 1 = 0.0188979 loss)
I0522 10:22:40.929361 19861 sgd_solver.cpp:112] Iteration 4020, lr = 0.001
I0522 10:22:43.649492 19861 solver.cpp:239] Iteration 4040 (7.3526 iter/s, 2.72012s/20 iters), loss = 0.039048
I0522 10:22:43.659135 19861 solver.cpp:258]     Train net output #0: loss = 0.039048 (* 1 = 0.039048 loss)
I0522 10:22:43.659142 19861 sgd_solver.cpp:112] Iteration 4040, lr = 0.001
I0522 10:22:46.548269 19861 solver.cpp:239] Iteration 4060 (6.92257 iter/s, 2.8891s/20 iters), loss = 0.035549
I0522 10:22:46.557796 19861 solver.cpp:258]     Train net output #0: loss = 0.035549 (* 1 = 0.035549 loss)
I0522 10:22:46.557808 19861 sgd_solver.cpp:112] Iteration 4060, lr = 0.001
I0522 10:22:48.586185 19861 solver.cpp:239] Iteration 4080 (9.86011 iter/s, 2.02837s/20 iters), loss = 0.0597468
I0522 10:22:48.595765 19861 solver.cpp:258]     Train net output #0: loss = 0.0597468 (* 1 = 0.0597468 loss)
I0522 10:22:48.595782 19861 sgd_solver.cpp:112] Iteration 4080, lr = 0.001
I0522 10:22:50.626555 19861 solver.cpp:239] Iteration 4100 (9.8485 iter/s, 2.03077s/20 iters), loss = 0.0201131
I0522 10:22:50.636111 19861 solver.cpp:258]     Train net output #0: loss = 0.0201131 (* 1 = 0.0201131 loss)
I0522 10:22:50.636123 19861 sgd_solver.cpp:112] Iteration 4100, lr = 0.001
I0522 10:22:52.675460 19861 solver.cpp:239] Iteration 4120 (9.8072 iter/s, 2.03932s/20 iters), loss = 0.031234
I0522 10:22:52.687157 19861 solver.cpp:258]     Train net output #0: loss = 0.031234 (* 1 = 0.031234 loss)
I0522 10:22:52.687173 19861 sgd_solver.cpp:112] Iteration 4120, lr = 0.001
I0522 10:22:55.409425 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:22:56.257335 19861 solver.cpp:239] Iteration 4140 (5.60196 iter/s, 3.57018s/20 iters), loss = 0.0145161
I0522 10:22:56.257393 19861 solver.cpp:258]     Train net output #0: loss = 0.0145161 (* 1 = 0.0145161 loss)
I0522 10:22:56.257396 19861 sgd_solver.cpp:112] Iteration 4140, lr = 0.001
I0522 10:22:58.314772 19861 solver.cpp:239] Iteration 4160 (9.72118 iter/s, 2.05736s/20 iters), loss = 0.0455447
I0522 10:22:58.324376 19861 solver.cpp:258]     Train net output #0: loss = 0.0455446 (* 1 = 0.0455446 loss)
I0522 10:22:58.324383 19861 sgd_solver.cpp:112] Iteration 4160, lr = 0.001
I0522 10:23:00.363422 19861 solver.cpp:239] Iteration 4180 (9.80858 iter/s, 2.03903s/20 iters), loss = 0.0125739
I0522 10:23:00.363483 19861 solver.cpp:258]     Train net output #0: loss = 0.0125739 (* 1 = 0.0125739 loss)
I0522 10:23:00.363488 19861 sgd_solver.cpp:112] Iteration 4180, lr = 0.001
I0522 10:23:03.374398 19861 solver.cpp:239] Iteration 4200 (6.64251 iter/s, 3.01091s/20 iters), loss = 0.0580756
I0522 10:23:03.383666 19861 solver.cpp:258]     Train net output #0: loss = 0.0580756 (* 1 = 0.0580756 loss)
I0522 10:23:03.383672 19861 sgd_solver.cpp:112] Iteration 4200, lr = 0.001
I0522 10:23:05.426241 19861 solver.cpp:239] Iteration 4220 (9.79155 iter/s, 2.04258s/20 iters), loss = 0.0793604
I0522 10:23:05.435483 19861 solver.cpp:258]     Train net output #0: loss = 0.0793604 (* 1 = 0.0793604 loss)
I0522 10:23:05.435489 19861 sgd_solver.cpp:112] Iteration 4220, lr = 0.001
I0522 10:23:07.477331 19861 solver.cpp:239] Iteration 4240 (9.79508 iter/s, 2.04184s/20 iters), loss = 0.0512217
I0522 10:23:07.486629 19861 solver.cpp:258]     Train net output #0: loss = 0.0512217 (* 1 = 0.0512217 loss)
I0522 10:23:07.486636 19861 sgd_solver.cpp:112] Iteration 4240, lr = 0.001
I0522 10:23:09.533241 19861 solver.cpp:239] Iteration 4260 (9.77221 iter/s, 2.04662s/20 iters), loss = 0.0234188
I0522 10:23:09.542593 19861 solver.cpp:258]     Train net output #0: loss = 0.0234188 (* 1 = 0.0234188 loss)
I0522 10:23:09.542599 19861 sgd_solver.cpp:112] Iteration 4260, lr = 0.001
I0522 10:23:11.580252 19861 solver.cpp:239] Iteration 4280 (9.81524 iter/s, 2.03765s/20 iters), loss = 0.0267465
I0522 10:23:11.589912 19861 solver.cpp:258]     Train net output #0: loss = 0.0267465 (* 1 = 0.0267465 loss)
I0522 10:23:11.589920 19861 sgd_solver.cpp:112] Iteration 4280, lr = 0.001
I0522 10:23:12.256505 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:23:13.641638 19861 solver.cpp:239] Iteration 4300 (9.74793 iter/s, 2.05172s/20 iters), loss = 0.0445491
I0522 10:23:13.650717 19861 solver.cpp:258]     Train net output #0: loss = 0.0445491 (* 1 = 0.0445491 loss)
I0522 10:23:13.650722 19861 sgd_solver.cpp:112] Iteration 4300, lr = 0.001
I0522 10:23:15.687119 19861 solver.cpp:239] Iteration 4320 (9.82127 iter/s, 2.0364s/20 iters), loss = 0.0478901
I0522 10:23:15.696198 19861 solver.cpp:258]     Train net output #0: loss = 0.0478901 (* 1 = 0.0478901 loss)
I0522 10:23:15.696204 19861 sgd_solver.cpp:112] Iteration 4320, lr = 0.001
I0522 10:23:17.725956 19861 solver.cpp:239] Iteration 4340 (9.85341 iter/s, 2.02975s/20 iters), loss = 0.0687172
I0522 10:23:17.735052 19861 solver.cpp:258]     Train net output #0: loss = 0.0687172 (* 1 = 0.0687172 loss)
I0522 10:23:17.735059 19861 sgd_solver.cpp:112] Iteration 4340, lr = 0.001
I0522 10:23:19.769582 19861 solver.cpp:239] Iteration 4360 (9.83033 iter/s, 2.03452s/20 iters), loss = 0.041286
I0522 10:23:19.778690 19861 solver.cpp:258]     Train net output #0: loss = 0.041286 (* 1 = 0.041286 loss)
I0522 10:23:19.778697 19861 sgd_solver.cpp:112] Iteration 4360, lr = 0.001
I0522 10:23:21.815594 19861 solver.cpp:239] Iteration 4380 (9.81905 iter/s, 2.03686s/20 iters), loss = 0.0134591
I0522 10:23:21.825989 19861 solver.cpp:258]     Train net output #0: loss = 0.0134591 (* 1 = 0.0134591 loss)
I0522 10:23:21.826035 19861 sgd_solver.cpp:112] Iteration 4380, lr = 0.001
I0522 10:23:23.865286 19861 solver.cpp:239] Iteration 4400 (9.80718 iter/s, 2.03932s/20 iters), loss = 0.0406919
I0522 10:23:23.874655 19861 solver.cpp:258]     Train net output #0: loss = 0.0406919 (* 1 = 0.0406919 loss)
I0522 10:23:23.874663 19861 sgd_solver.cpp:112] Iteration 4400, lr = 0.001
I0522 10:23:25.957737 19861 solver.cpp:239] Iteration 4420 (9.60117 iter/s, 2.08308s/20 iters), loss = 0.015314
I0522 10:23:25.967599 19861 solver.cpp:258]     Train net output #0: loss = 0.0153139 (* 1 = 0.0153139 loss)
I0522 10:23:25.967607 19861 sgd_solver.cpp:112] Iteration 4420, lr = 0.001
I0522 10:23:27.988335 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:23:28.012501 19861 solver.cpp:239] Iteration 4440 (9.78047 iter/s, 2.04489s/20 iters), loss = 0.0679114
I0522 10:23:28.012553 19861 solver.cpp:258]     Train net output #0: loss = 0.0679114 (* 1 = 0.0679114 loss)
I0522 10:23:28.012557 19861 sgd_solver.cpp:112] Iteration 4440, lr = 0.001
I0522 10:23:30.065404 19861 solver.cpp:239] Iteration 4460 (9.7426 iter/s, 2.05284s/20 iters), loss = 0.0258246
I0522 10:23:30.074952 19861 solver.cpp:258]     Train net output #0: loss = 0.0258246 (* 1 = 0.0258246 loss)
I0522 10:23:30.074957 19861 sgd_solver.cpp:112] Iteration 4460, lr = 0.001
I0522 10:23:32.120579 19861 solver.cpp:239] Iteration 4480 (9.77707 iter/s, 2.0456s/20 iters), loss = 0.044257
I0522 10:23:32.120664 19861 solver.cpp:258]     Train net output #0: loss = 0.044257 (* 1 = 0.044257 loss)
I0522 10:23:32.120668 19861 sgd_solver.cpp:112] Iteration 4480, lr = 0.001
I0522 10:23:34.205881 19861 solver.cpp:239] Iteration 4500 (9.59136 iter/s, 2.08521s/20 iters), loss = 0.0130917
I0522 10:23:34.205926 19861 solver.cpp:258]     Train net output #0: loss = 0.0130917 (* 1 = 0.0130917 loss)
I0522 10:23:34.205986 19861 sgd_solver.cpp:112] Iteration 4500, lr = 0.001
I0522 10:23:36.686074 19861 solver.cpp:239] Iteration 4520 (8.06409 iter/s, 2.48013s/20 iters), loss = 0.039051
I0522 10:23:36.695868 19861 solver.cpp:258]     Train net output #0: loss = 0.039051 (* 1 = 0.039051 loss)
I0522 10:23:36.695880 19861 sgd_solver.cpp:112] Iteration 4520, lr = 0.001
I0522 10:23:38.769372 19861 solver.cpp:239] Iteration 4540 (9.64551 iter/s, 2.0735s/20 iters), loss = 0.0594299
I0522 10:23:38.779029 19861 solver.cpp:258]     Train net output #0: loss = 0.0594299 (* 1 = 0.0594299 loss)
I0522 10:23:38.779038 19861 sgd_solver.cpp:112] Iteration 4540, lr = 0.001
I0522 10:23:40.860430 19861 solver.cpp:239] Iteration 4560 (9.60902 iter/s, 2.08138s/20 iters), loss = 0.017686
I0522 10:23:40.860503 19861 solver.cpp:258]     Train net output #0: loss = 0.0176859 (* 1 = 0.0176859 loss)
I0522 10:23:40.860512 19861 sgd_solver.cpp:112] Iteration 4560, lr = 0.001
I0522 10:23:42.985131 19861 solver.cpp:239] Iteration 4580 (9.41345 iter/s, 2.12462s/20 iters), loss = 0.0271626
I0522 10:23:42.995810 19861 solver.cpp:258]     Train net output #0: loss = 0.0271626 (* 1 = 0.0271626 loss)
I0522 10:23:42.995820 19861 sgd_solver.cpp:112] Iteration 4580, lr = 0.001
I0522 10:23:44.077363 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:23:44.311758 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:23:45.068521 19861 solver.cpp:239] Iteration 4600 (9.64931 iter/s, 2.07269s/20 iters), loss = 0.0375535
I0522 10:23:45.077580 19861 solver.cpp:258]     Train net output #0: loss = 0.0375535 (* 1 = 0.0375535 loss)
I0522 10:23:45.077592 19861 sgd_solver.cpp:112] Iteration 4600, lr = 0.001
I0522 10:23:47.139370 19861 solver.cpp:239] Iteration 4620 (9.70047 iter/s, 2.06176s/20 iters), loss = 0.0270605
I0522 10:23:47.150671 19861 solver.cpp:258]     Train net output #0: loss = 0.0270605 (* 1 = 0.0270605 loss)
I0522 10:23:47.150691 19861 sgd_solver.cpp:112] Iteration 4620, lr = 0.001
I0522 10:23:49.656052 19861 solver.cpp:239] Iteration 4640 (7.9828 iter/s, 2.50539s/20 iters), loss = 0.018375
I0522 10:23:49.669210 19861 solver.cpp:258]     Train net output #0: loss = 0.018375 (* 1 = 0.018375 loss)
I0522 10:23:49.669217 19861 sgd_solver.cpp:112] Iteration 4640, lr = 0.001
I0522 10:23:51.804559 19861 solver.cpp:239] Iteration 4660 (9.36624 iter/s, 2.13533s/20 iters), loss = 0.0429034
I0522 10:23:51.804630 19861 solver.cpp:258]     Train net output #0: loss = 0.0429033 (* 1 = 0.0429033 loss)
I0522 10:23:51.804633 19861 sgd_solver.cpp:112] Iteration 4660, lr = 0.001
I0522 10:23:53.932821 19861 solver.cpp:239] Iteration 4680 (9.39766 iter/s, 2.12819s/20 iters), loss = 0.0475227
I0522 10:23:53.932853 19861 solver.cpp:258]     Train net output #0: loss = 0.0475227 (* 1 = 0.0475227 loss)
I0522 10:23:53.932857 19861 sgd_solver.cpp:112] Iteration 4680, lr = 0.001
I0522 10:23:56.079504 19861 solver.cpp:239] Iteration 4700 (9.31687 iter/s, 2.14664s/20 iters), loss = 0.0370536
I0522 10:23:56.090989 19861 solver.cpp:258]     Train net output #0: loss = 0.0370536 (* 1 = 0.0370536 loss)
I0522 10:23:56.090996 19861 sgd_solver.cpp:112] Iteration 4700, lr = 0.001
I0522 10:23:58.589740 19861 solver.cpp:239] Iteration 4720 (8.0041 iter/s, 2.49872s/20 iters), loss = 0.030296
I0522 10:23:58.589835 19861 solver.cpp:258]     Train net output #0: loss = 0.030296 (* 1 = 0.030296 loss)
I0522 10:23:58.589840 19861 sgd_solver.cpp:112] Iteration 4720, lr = 0.001
I0522 10:24:00.730394 19861 solver.cpp:239] Iteration 4740 (9.3434 iter/s, 2.14055s/20 iters), loss = 0.0214017
I0522 10:24:00.730456 19861 solver.cpp:258]     Train net output #0: loss = 0.0214017 (* 1 = 0.0214017 loss)
I0522 10:24:00.730461 19861 sgd_solver.cpp:112] Iteration 4740, lr = 0.001
I0522 10:24:01.377890 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:24:02.901770 19861 solver.cpp:239] Iteration 4760 (9.2111 iter/s, 2.17129s/20 iters), loss = 0.0314877
I0522 10:24:02.915072 19861 solver.cpp:258]     Train net output #0: loss = 0.0314876 (* 1 = 0.0314876 loss)
I0522 10:24:02.915079 19861 sgd_solver.cpp:112] Iteration 4760, lr = 0.001
I0522 10:24:05.066879 19861 solver.cpp:239] Iteration 4780 (9.29469 iter/s, 2.15177s/20 iters), loss = 0.0116494
I0522 10:24:05.067025 19861 solver.cpp:258]     Train net output #0: loss = 0.0116494 (* 1 = 0.0116494 loss)
I0522 10:24:05.067032 19861 sgd_solver.cpp:112] Iteration 4780, lr = 0.001
I0522 10:24:07.508097 19861 solver.cpp:239] Iteration 4800 (8.19319 iter/s, 2.44105s/20 iters), loss = 0.0189226
I0522 10:24:07.508183 19861 solver.cpp:258]     Train net output #0: loss = 0.0189226 (* 1 = 0.0189226 loss)
I0522 10:24:07.508280 19861 sgd_solver.cpp:112] Iteration 4800, lr = 0.001
I0522 10:24:09.662457 19861 solver.cpp:239] Iteration 4820 (9.28392 iter/s, 2.15426s/20 iters), loss = 0.0275097
I0522 10:24:09.675719 19861 solver.cpp:258]     Train net output #0: loss = 0.0275097 (* 1 = 0.0275097 loss)
I0522 10:24:09.675726 19861 sgd_solver.cpp:112] Iteration 4820, lr = 0.001
I0522 10:24:11.871516 19861 solver.cpp:239] Iteration 4840 (9.10831 iter/s, 2.1958s/20 iters), loss = 0.0207708
I0522 10:24:11.880601 19861 solver.cpp:258]     Train net output #0: loss = 0.0207708 (* 1 = 0.0207708 loss)
I0522 10:24:11.880610 19861 sgd_solver.cpp:112] Iteration 4840, lr = 0.001
I0522 10:24:14.264858 19861 solver.cpp:239] Iteration 4860 (8.3884 iter/s, 2.38424s/20 iters), loss = 0.0328077
I0522 10:24:14.264914 19861 solver.cpp:258]     Train net output #0: loss = 0.0328077 (* 1 = 0.0328077 loss)
I0522 10:24:14.264917 19861 sgd_solver.cpp:112] Iteration 4860, lr = 0.001
I0522 10:24:16.492624 19861 solver.cpp:239] Iteration 4880 (8.97805 iter/s, 2.22766s/20 iters), loss = 0.0197009
I0522 10:24:16.503054 19861 solver.cpp:258]     Train net output #0: loss = 0.0197009 (* 1 = 0.0197009 loss)
I0522 10:24:16.503068 19861 sgd_solver.cpp:112] Iteration 4880, lr = 0.001
I0522 10:24:18.610496 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:24:18.670984 19861 solver.cpp:239] Iteration 4900 (9.22545 iter/s, 2.16792s/20 iters), loss = 0.0281071
I0522 10:24:18.671067 19861 solver.cpp:258]     Train net output #0: loss = 0.0281071 (* 1 = 0.0281071 loss)
I0522 10:24:18.671072 19861 sgd_solver.cpp:112] Iteration 4900, lr = 0.001
I0522 10:24:20.844972 19861 solver.cpp:239] Iteration 4920 (9.20014 iter/s, 2.17388s/20 iters), loss = 0.045187
I0522 10:24:20.845049 19861 solver.cpp:258]     Train net output #0: loss = 0.045187 (* 1 = 0.045187 loss)
I0522 10:24:20.845053 19861 sgd_solver.cpp:112] Iteration 4920, lr = 0.001
I0522 10:24:23.294543 19861 solver.cpp:239] Iteration 4940 (8.16498 iter/s, 2.44949s/20 iters), loss = 0.016576
I0522 10:24:23.294590 19861 solver.cpp:258]     Train net output #0: loss = 0.016576 (* 1 = 0.016576 loss)
I0522 10:24:23.294595 19861 sgd_solver.cpp:112] Iteration 4940, lr = 0.001
I0522 10:24:25.424551 19861 solver.cpp:239] Iteration 4960 (9.39001 iter/s, 2.12992s/20 iters), loss = 0.0496163
I0522 10:24:25.434172 19861 solver.cpp:258]     Train net output #0: loss = 0.0496162 (* 1 = 0.0496162 loss)
I0522 10:24:25.434187 19861 sgd_solver.cpp:112] Iteration 4960, lr = 0.001
I0522 10:24:27.567261 19861 solver.cpp:239] Iteration 4980 (9.3761 iter/s, 2.13308s/20 iters), loss = 0.0191569
I0522 10:24:27.567314 19861 solver.cpp:258]     Train net output #0: loss = 0.0191568 (* 1 = 0.0191568 loss)
I0522 10:24:27.567318 19861 sgd_solver.cpp:112] Iteration 4980, lr = 0.001
I0522 10:24:29.558760 19861 solver.cpp:347] Iteration 5000, Testing net (#0)
I0522 10:24:30.630010 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:24:35.846896 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:24:40.153968 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:24:41.326932 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:24:44.278331 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:24:47.365167 19861 solver.cpp:414]     Test net output #0: accuracy = 0.863182
I0522 10:24:47.365239 19861 solver.cpp:414]     Test net output #1: loss = 0.721362 (* 1 = 0.721362 loss)
I0522 10:24:47.468190 19861 solver.cpp:239] Iteration 5000 (1.00498 iter/s, 19.9009s/20 iters), loss = 0.0305245
I0522 10:24:47.470816 19861 solver.cpp:258]     Train net output #0: loss = 0.0305245 (* 1 = 0.0305245 loss)
I0522 10:24:47.470835 19861 sgd_solver.cpp:112] Iteration 5000, lr = 0.001
I0522 10:24:49.618525 19861 solver.cpp:239] Iteration 5020 (9.31234 iter/s, 2.14769s/20 iters), loss = 0.0243377
I0522 10:24:49.618626 19861 solver.cpp:258]     Train net output #0: loss = 0.0243377 (* 1 = 0.0243377 loss)
I0522 10:24:49.618631 19861 sgd_solver.cpp:112] Iteration 5020, lr = 0.001
I0522 10:24:52.045861 19861 solver.cpp:239] Iteration 5040 (8.23984 iter/s, 2.42723s/20 iters), loss = 0.00674032
I0522 10:24:52.054940 19861 solver.cpp:258]     Train net output #0: loss = 0.00674031 (* 1 = 0.00674031 loss)
I0522 10:24:52.054946 19861 sgd_solver.cpp:112] Iteration 5040, lr = 0.001
I0522 10:24:53.373790 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:24:54.167673 19861 solver.cpp:239] Iteration 5060 (9.46651 iter/s, 2.11271s/20 iters), loss = 0.0462869
I0522 10:24:54.167770 19861 solver.cpp:258]     Train net output #0: loss = 0.0462869 (* 1 = 0.0462869 loss)
I0522 10:24:54.167776 19861 sgd_solver.cpp:112] Iteration 5060, lr = 0.001
I0522 10:24:56.321768 19861 solver.cpp:239] Iteration 5080 (9.28512 iter/s, 2.15398s/20 iters), loss = 0.0430689
I0522 10:24:56.321826 19861 solver.cpp:258]     Train net output #0: loss = 0.0430689 (* 1 = 0.0430689 loss)
I0522 10:24:56.321830 19861 sgd_solver.cpp:112] Iteration 5080, lr = 0.001
I0522 10:24:58.498090 19861 solver.cpp:239] Iteration 5100 (9.19013 iter/s, 2.17625s/20 iters), loss = 0.0147034
I0522 10:24:58.498199 19861 solver.cpp:258]     Train net output #0: loss = 0.0147034 (* 1 = 0.0147034 loss)
I0522 10:24:58.498214 19861 sgd_solver.cpp:112] Iteration 5100, lr = 0.001
I0522 10:25:00.999887 19861 solver.cpp:239] Iteration 5120 (8.00166 iter/s, 2.49948s/20 iters), loss = 0.021117
I0522 10:25:00.999971 19861 solver.cpp:258]     Train net output #0: loss = 0.021117 (* 1 = 0.021117 loss)
I0522 10:25:00.999976 19861 sgd_solver.cpp:112] Iteration 5120, lr = 0.001
I0522 10:25:03.149268 19861 solver.cpp:239] Iteration 5140 (9.30543 iter/s, 2.14928s/20 iters), loss = 0.03935
I0522 10:25:03.149327 19861 solver.cpp:258]     Train net output #0: loss = 0.03935 (* 1 = 0.03935 loss)
I0522 10:25:03.149333 19861 sgd_solver.cpp:112] Iteration 5140, lr = 0.001
I0522 10:25:05.281582 19861 solver.cpp:239] Iteration 5160 (9.37979 iter/s, 2.13224s/20 iters), loss = 0.0214862
I0522 10:25:05.281635 19861 solver.cpp:258]     Train net output #0: loss = 0.0214862 (* 1 = 0.0214862 loss)
I0522 10:25:05.281639 19861 sgd_solver.cpp:112] Iteration 5160, lr = 0.001
I0522 10:25:07.756299 19861 solver.cpp:239] Iteration 5180 (8.08195 iter/s, 2.47465s/20 iters), loss = 0.00890779
I0522 10:25:07.756368 19861 solver.cpp:258]     Train net output #0: loss = 0.00890778 (* 1 = 0.00890778 loss)
I0522 10:25:07.756376 19861 sgd_solver.cpp:112] Iteration 5180, lr = 0.001
I0522 10:25:09.879369 19861 solver.cpp:239] Iteration 5200 (9.4207 iter/s, 2.12298s/20 iters), loss = 0.0277732
I0522 10:25:09.888432 19861 solver.cpp:258]     Train net output #0: loss = 0.0277732 (* 1 = 0.0277732 loss)
I0522 10:25:09.888442 19861 sgd_solver.cpp:112] Iteration 5200, lr = 0.001
I0522 10:25:10.475410 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:25:12.038403 19861 solver.cpp:239] Iteration 5220 (9.30252 iter/s, 2.14996s/20 iters), loss = 0.0279836
I0522 10:25:12.051713 19861 solver.cpp:258]     Train net output #0: loss = 0.0279836 (* 1 = 0.0279836 loss)
I0522 10:25:12.051721 19861 sgd_solver.cpp:112] Iteration 5220, lr = 0.001
I0522 10:25:14.420336 19861 solver.cpp:239] Iteration 5240 (8.44376 iter/s, 2.36861s/20 iters), loss = 0.0152573
I0522 10:25:14.433382 19861 solver.cpp:258]     Train net output #0: loss = 0.0152572 (* 1 = 0.0152572 loss)
I0522 10:25:14.433390 19861 sgd_solver.cpp:112] Iteration 5240, lr = 0.001
I0522 10:25:16.560468 19861 solver.cpp:239] Iteration 5260 (9.4027 iter/s, 2.12705s/20 iters), loss = 0.0180908
I0522 10:25:16.570987 19861 solver.cpp:258]     Train net output #0: loss = 0.0180908 (* 1 = 0.0180908 loss)
I0522 10:25:16.570998 19861 sgd_solver.cpp:112] Iteration 5260, lr = 0.001
I0522 10:25:18.765982 19861 solver.cpp:239] Iteration 5280 (9.11166 iter/s, 2.19499s/20 iters), loss = 0.0198052
I0522 10:25:18.766042 19861 solver.cpp:258]     Train net output #0: loss = 0.0198052 (* 1 = 0.0198052 loss)
I0522 10:25:18.766047 19861 sgd_solver.cpp:112] Iteration 5280, lr = 0.001
I0522 10:25:21.058027 19861 solver.cpp:239] Iteration 5300 (8.72613 iter/s, 2.29197s/20 iters), loss = 0.0167953
I0522 10:25:21.072388 19861 solver.cpp:258]     Train net output #0: loss = 0.0167953 (* 1 = 0.0167953 loss)
I0522 10:25:21.072396 19861 sgd_solver.cpp:112] Iteration 5300, lr = 0.001
I0522 10:25:23.299252 19861 solver.cpp:239] Iteration 5320 (8.98123 iter/s, 2.22687s/20 iters), loss = 0.0156093
I0522 10:25:23.299279 19861 solver.cpp:258]     Train net output #0: loss = 0.0156093 (* 1 = 0.0156093 loss)
I0522 10:25:23.299283 19861 sgd_solver.cpp:112] Iteration 5320, lr = 0.001
I0522 10:25:25.427924 19861 solver.cpp:239] Iteration 5340 (9.39573 iter/s, 2.12863s/20 iters), loss = 0.0049635
I0522 10:25:25.427989 19861 solver.cpp:258]     Train net output #0: loss = 0.00496348 (* 1 = 0.00496348 loss)
I0522 10:25:25.427994 19861 sgd_solver.cpp:112] Iteration 5340, lr = 0.001
I0522 10:25:27.458003 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:25:27.598330 19861 solver.cpp:239] Iteration 5360 (9.21518 iter/s, 2.17033s/20 iters), loss = 0.0138252
I0522 10:25:27.598385 19861 solver.cpp:258]     Train net output #0: loss = 0.0138252 (* 1 = 0.0138252 loss)
I0522 10:25:27.598389 19861 sgd_solver.cpp:112] Iteration 5360, lr = 0.001
I0522 10:25:30.037420 19861 solver.cpp:239] Iteration 5380 (8.20001 iter/s, 2.43902s/20 iters), loss = 0.0228596
I0522 10:25:30.037478 19861 solver.cpp:258]     Train net output #0: loss = 0.0228596 (* 1 = 0.0228596 loss)
I0522 10:25:30.037484 19861 sgd_solver.cpp:112] Iteration 5380, lr = 0.001
I0522 10:25:32.168336 19861 solver.cpp:239] Iteration 5400 (9.38606 iter/s, 2.13082s/20 iters), loss = 0.0189956
I0522 10:25:32.168442 19861 solver.cpp:258]     Train net output #0: loss = 0.0189956 (* 1 = 0.0189956 loss)
I0522 10:25:32.168454 19861 sgd_solver.cpp:112] Iteration 5400, lr = 0.001
I0522 10:25:34.271373 19861 solver.cpp:239] Iteration 5420 (9.51061 iter/s, 2.10291s/20 iters), loss = 0.0236933
I0522 10:25:34.284787 19861 solver.cpp:258]     Train net output #0: loss = 0.0236933 (* 1 = 0.0236933 loss)
I0522 10:25:34.284801 19861 sgd_solver.cpp:112] Iteration 5420, lr = 0.001
I0522 10:25:36.708636 19861 solver.cpp:239] Iteration 5440 (8.2514 iter/s, 2.42383s/20 iters), loss = 0.0102139
I0522 10:25:36.722080 19861 solver.cpp:258]     Train net output #0: loss = 0.0102139 (* 1 = 0.0102139 loss)
I0522 10:25:36.722095 19861 sgd_solver.cpp:112] Iteration 5440, lr = 0.001
I0522 10:25:38.862215 19861 solver.cpp:239] Iteration 5460 (9.34527 iter/s, 2.14012s/20 iters), loss = 0.0206398
I0522 10:25:38.862293 19861 solver.cpp:258]     Train net output #0: loss = 0.0206398 (* 1 = 0.0206398 loss)
I0522 10:25:38.862298 19861 sgd_solver.cpp:112] Iteration 5460, lr = 0.001
I0522 10:25:41.019575 19861 solver.cpp:239] Iteration 5480 (9.27103 iter/s, 2.15726s/20 iters), loss = 0.0239321
I0522 10:25:41.019985 19861 solver.cpp:258]     Train net output #0: loss = 0.023932 (* 1 = 0.023932 loss)
I0522 10:25:41.019990 19861 sgd_solver.cpp:112] Iteration 5480, lr = 0.001
I0522 10:25:43.574833 19861 solver.cpp:239] Iteration 5500 (7.82827 iter/s, 2.55484s/20 iters), loss = 0.0143137
I0522 10:25:43.586926 19861 solver.cpp:258]     Train net output #0: loss = 0.0143137 (* 1 = 0.0143137 loss)
I0522 10:25:43.586933 19861 sgd_solver.cpp:112] Iteration 5500, lr = 0.001
I0522 10:25:44.852562 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:25:45.751261 19861 solver.cpp:239] Iteration 5520 (9.24078 iter/s, 2.16432s/20 iters), loss = 0.0215968
I0522 10:25:45.765022 19861 solver.cpp:258]     Train net output #0: loss = 0.0215968 (* 1 = 0.0215968 loss)
I0522 10:25:45.765033 19861 sgd_solver.cpp:112] Iteration 5520, lr = 0.001
I0522 10:25:47.943374 19861 solver.cpp:239] Iteration 5540 (9.18138 iter/s, 2.17832s/20 iters), loss = 0.0226777
I0522 10:25:47.943478 19861 solver.cpp:258]     Train net output #0: loss = 0.0226776 (* 1 = 0.0226776 loss)
I0522 10:25:47.943485 19861 sgd_solver.cpp:112] Iteration 5540, lr = 0.001
I0522 10:25:50.137990 19861 solver.cpp:239] Iteration 5560 (9.11412 iter/s, 2.1944s/20 iters), loss = 0.022241
I0522 10:25:50.138250 19861 solver.cpp:258]     Train net output #0: loss = 0.0222409 (* 1 = 0.0222409 loss)
I0522 10:25:50.138273 19861 sgd_solver.cpp:112] Iteration 5560, lr = 0.001
I0522 10:25:52.660564 19861 solver.cpp:239] Iteration 5580 (7.92923 iter/s, 2.52231s/20 iters), loss = 0.0214711
I0522 10:25:52.673987 19861 solver.cpp:258]     Train net output #0: loss = 0.0214711 (* 1 = 0.0214711 loss)
I0522 10:25:52.673995 19861 sgd_solver.cpp:112] Iteration 5580, lr = 0.001
I0522 10:25:54.890422 19861 solver.cpp:239] Iteration 5600 (9.02353 iter/s, 2.21643s/20 iters), loss = 0.012943
I0522 10:25:54.890476 19861 solver.cpp:258]     Train net output #0: loss = 0.0129429 (* 1 = 0.0129429 loss)
I0522 10:25:54.890480 19861 sgd_solver.cpp:112] Iteration 5600, lr = 0.001
I0522 10:25:57.134351 19861 solver.cpp:239] Iteration 5620 (8.91324 iter/s, 2.24385s/20 iters), loss = 0.0144012
I0522 10:25:57.147251 19861 solver.cpp:258]     Train net output #0: loss = 0.0144011 (* 1 = 0.0144011 loss)
I0522 10:25:57.147300 19861 sgd_solver.cpp:112] Iteration 5620, lr = 0.001
I0522 10:25:59.550024 19861 solver.cpp:239] Iteration 5640 (8.32376 iter/s, 2.40276s/20 iters), loss = 0.0217729
I0522 10:25:59.550118 19861 solver.cpp:258]     Train net output #0: loss = 0.0217729 (* 1 = 0.0217729 loss)
I0522 10:25:59.550122 19861 sgd_solver.cpp:112] Iteration 5640, lr = 0.001
I0522 10:26:01.725519 19861 solver.cpp:239] Iteration 5660 (9.1938 iter/s, 2.17538s/20 iters), loss = 0.00847715
I0522 10:26:01.725620 19861 solver.cpp:258]     Train net output #0: loss = 0.00847713 (* 1 = 0.00847713 loss)
I0522 10:26:01.725625 19861 sgd_solver.cpp:112] Iteration 5660, lr = 0.001
I0522 10:26:02.272745 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:26:02.325721 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:26:03.938979 19861 solver.cpp:239] Iteration 5680 (9.03602 iter/s, 2.21336s/20 iters), loss = 0.0434832
I0522 10:26:03.939002 19861 solver.cpp:258]     Train net output #0: loss = 0.0434832 (* 1 = 0.0434832 loss)
I0522 10:26:03.939005 19861 sgd_solver.cpp:112] Iteration 5680, lr = 0.001
I0522 10:26:06.462540 19861 solver.cpp:239] Iteration 5700 (7.92545 iter/s, 2.52352s/20 iters), loss = 0.0159654
I0522 10:26:06.476169 19861 solver.cpp:258]     Train net output #0: loss = 0.0159654 (* 1 = 0.0159654 loss)
I0522 10:26:06.476177 19861 sgd_solver.cpp:112] Iteration 5700, lr = 0.001
I0522 10:26:08.630136 19861 solver.cpp:239] Iteration 5720 (9.28529 iter/s, 2.15394s/20 iters), loss = 0.0207752
I0522 10:26:08.630228 19861 solver.cpp:258]     Train net output #0: loss = 0.0207752 (* 1 = 0.0207752 loss)
I0522 10:26:08.630234 19861 sgd_solver.cpp:112] Iteration 5720, lr = 0.001
I0522 10:26:10.800037 19861 solver.cpp:239] Iteration 5740 (9.21746 iter/s, 2.16979s/20 iters), loss = 0.0157886
I0522 10:26:10.800159 19861 solver.cpp:258]     Train net output #0: loss = 0.0157886 (* 1 = 0.0157886 loss)
I0522 10:26:10.800164 19861 sgd_solver.cpp:112] Iteration 5740, lr = 0.001
I0522 10:26:13.348193 19861 solver.cpp:239] Iteration 5760 (7.84922 iter/s, 2.54802s/20 iters), loss = 0.0021815
I0522 10:26:13.361224 19861 solver.cpp:258]     Train net output #0: loss = 0.00218149 (* 1 = 0.00218149 loss)
I0522 10:26:13.361233 19861 sgd_solver.cpp:112] Iteration 5760, lr = 0.001
I0522 10:26:15.539786 19861 solver.cpp:239] Iteration 5780 (9.18046 iter/s, 2.17854s/20 iters), loss = 0.0184102
I0522 10:26:15.539866 19861 solver.cpp:258]     Train net output #0: loss = 0.0184102 (* 1 = 0.0184102 loss)
I0522 10:26:15.539871 19861 sgd_solver.cpp:112] Iteration 5780, lr = 0.001
I0522 10:26:17.715487 19861 solver.cpp:239] Iteration 5800 (9.19286 iter/s, 2.1756s/20 iters), loss = 0.0298086
I0522 10:26:17.715553 19861 solver.cpp:258]     Train net output #0: loss = 0.0298086 (* 1 = 0.0298086 loss)
I0522 10:26:17.715556 19861 sgd_solver.cpp:112] Iteration 5800, lr = 0.001
I0522 10:26:19.715330 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:26:19.888720 19861 solver.cpp:239] Iteration 5820 (9.20337 iter/s, 2.17312s/20 iters), loss = 0.0131524
I0522 10:26:19.888841 19861 solver.cpp:258]     Train net output #0: loss = 0.0131524 (* 1 = 0.0131524 loss)
I0522 10:26:19.888856 19861 sgd_solver.cpp:112] Iteration 5820, lr = 0.001
I0522 10:26:22.330238 19861 solver.cpp:239] Iteration 5840 (8.19216 iter/s, 2.44136s/20 iters), loss = 0.0174944
I0522 10:26:22.330293 19861 solver.cpp:258]     Train net output #0: loss = 0.0174944 (* 1 = 0.0174944 loss)
I0522 10:26:22.330298 19861 sgd_solver.cpp:112] Iteration 5840, lr = 0.001
I0522 10:26:24.515652 19861 solver.cpp:239] Iteration 5860 (9.15188 iter/s, 2.18534s/20 iters), loss = 0.015839
I0522 10:26:24.515710 19861 solver.cpp:258]     Train net output #0: loss = 0.015839 (* 1 = 0.015839 loss)
I0522 10:26:24.515714 19861 sgd_solver.cpp:112] Iteration 5860, lr = 0.001
I0522 10:26:26.693426 19861 solver.cpp:239] Iteration 5880 (9.18404 iter/s, 2.17769s/20 iters), loss = 0.0101716
I0522 10:26:26.693524 19861 solver.cpp:258]     Train net output #0: loss = 0.0101716 (* 1 = 0.0101716 loss)
I0522 10:26:26.693529 19861 sgd_solver.cpp:112] Iteration 5880, lr = 0.001
I0522 10:26:29.174552 19861 solver.cpp:239] Iteration 5900 (8.06126 iter/s, 2.481s/20 iters), loss = 0.0123072
I0522 10:26:29.174664 19861 solver.cpp:258]     Train net output #0: loss = 0.0123072 (* 1 = 0.0123072 loss)
I0522 10:26:29.174669 19861 sgd_solver.cpp:112] Iteration 5900, lr = 0.001
I0522 10:26:31.423800 19861 solver.cpp:239] Iteration 5920 (8.89234 iter/s, 2.24913s/20 iters), loss = 0.0147368
I0522 10:26:31.436972 19861 solver.cpp:258]     Train net output #0: loss = 0.0147368 (* 1 = 0.0147368 loss)
I0522 10:26:31.436980 19861 sgd_solver.cpp:112] Iteration 5920, lr = 0.001
I0522 10:26:33.749935 19861 solver.cpp:239] Iteration 5940 (8.64695 iter/s, 2.31295s/20 iters), loss = 0.00752398
I0522 10:26:33.749999 19861 solver.cpp:258]     Train net output #0: loss = 0.00752396 (* 1 = 0.00752396 loss)
I0522 10:26:33.750002 19861 sgd_solver.cpp:112] Iteration 5940, lr = 0.001
I0522 10:26:36.218277 19861 solver.cpp:239] Iteration 5960 (8.10294 iter/s, 2.46824s/20 iters), loss = 0.00603409
I0522 10:26:36.218408 19861 solver.cpp:258]     Train net output #0: loss = 0.00603407 (* 1 = 0.00603407 loss)
I0522 10:26:36.218423 19861 sgd_solver.cpp:112] Iteration 5960, lr = 0.001
I0522 10:26:37.555899 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:26:38.511302 19861 solver.cpp:239] Iteration 5980 (8.7226 iter/s, 2.29289s/20 iters), loss = 0.00991657
I0522 10:26:38.511368 19861 solver.cpp:258]     Train net output #0: loss = 0.00991656 (* 1 = 0.00991656 loss)
I0522 10:26:38.511373 19861 sgd_solver.cpp:112] Iteration 5980, lr = 0.001
I0522 10:26:40.581152 19861 solver.cpp:347] Iteration 6000, Testing net (#0)
I0522 10:26:41.692066 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:26:45.955960 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:26:50.127856 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:26:52.135527 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:26:54.204591 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:26:57.156119 19861 solver.cpp:414]     Test net output #0: accuracy = 0.863801
I0522 10:26:57.156189 19861 solver.cpp:414]     Test net output #1: loss = 0.734026 (* 1 = 0.734026 loss)
I0522 10:26:57.309852 19861 solver.cpp:239] Iteration 6000 (1.06391 iter/s, 18.7985s/20 iters), loss = 0.0167611
I0522 10:26:57.311751 19861 solver.cpp:258]     Train net output #0: loss = 0.0167611 (* 1 = 0.0167611 loss)
I0522 10:26:57.311759 19861 sgd_solver.cpp:112] Iteration 6000, lr = 0.001
I0522 10:26:59.702832 19861 solver.cpp:239] Iteration 6020 (8.36443 iter/s, 2.39108s/20 iters), loss = 0.0118676
I0522 10:26:59.702867 19861 solver.cpp:258]     Train net output #0: loss = 0.0118676 (* 1 = 0.0118676 loss)
I0522 10:26:59.702872 19861 sgd_solver.cpp:112] Iteration 6020, lr = 0.001
I0522 10:27:01.842108 19861 solver.cpp:239] Iteration 6040 (9.34913 iter/s, 2.13924s/20 iters), loss = 0.0252761
I0522 10:27:01.842136 19861 solver.cpp:258]     Train net output #0: loss = 0.0252761 (* 1 = 0.0252761 loss)
I0522 10:27:01.842140 19861 sgd_solver.cpp:112] Iteration 6040, lr = 0.001
I0522 10:27:04.006286 19861 solver.cpp:239] Iteration 6060 (9.24164 iter/s, 2.16412s/20 iters), loss = 0.00495023
I0522 10:27:04.006381 19861 solver.cpp:258]     Train net output #0: loss = 0.00495022 (* 1 = 0.00495022 loss)
I0522 10:27:04.006387 19861 sgd_solver.cpp:112] Iteration 6060, lr = 0.001
I0522 10:27:06.387032 19861 solver.cpp:239] Iteration 6080 (8.40113 iter/s, 2.38063s/20 iters), loss = 0.00805504
I0522 10:27:06.387101 19861 solver.cpp:258]     Train net output #0: loss = 0.00805503 (* 1 = 0.00805503 loss)
I0522 10:27:06.387106 19861 sgd_solver.cpp:112] Iteration 6080, lr = 0.001
I0522 10:27:08.545516 19861 solver.cpp:239] Iteration 6100 (9.26612 iter/s, 2.1584s/20 iters), loss = 0.00682588
I0522 10:27:08.555790 19861 solver.cpp:258]     Train net output #0: loss = 0.00682586 (* 1 = 0.00682586 loss)
I0522 10:27:08.555799 19861 sgd_solver.cpp:112] Iteration 6100, lr = 0.001
I0522 10:27:10.722981 19861 solver.cpp:239] Iteration 6120 (9.22862 iter/s, 2.16717s/20 iters), loss = 0.0103572
I0522 10:27:10.723048 19861 solver.cpp:258]     Train net output #0: loss = 0.0103572 (* 1 = 0.0103572 loss)
I0522 10:27:10.723054 19861 sgd_solver.cpp:112] Iteration 6120, lr = 0.001
I0522 10:27:11.200338 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:27:13.086632 19861 solver.cpp:239] Iteration 6140 (8.46176 iter/s, 2.36357s/20 iters), loss = 0.00884423
I0522 10:27:13.095711 19861 solver.cpp:258]     Train net output #0: loss = 0.00884422 (* 1 = 0.00884422 loss)
I0522 10:27:13.095718 19861 sgd_solver.cpp:112] Iteration 6140, lr = 0.001
I0522 10:27:15.215790 19861 solver.cpp:239] Iteration 6160 (9.43369 iter/s, 2.12006s/20 iters), loss = 0.0045938
I0522 10:27:15.215868 19861 solver.cpp:258]     Train net output #0: loss = 0.00459379 (* 1 = 0.00459379 loss)
I0522 10:27:15.215873 19861 sgd_solver.cpp:112] Iteration 6160, lr = 0.001
I0522 10:27:17.374115 19861 solver.cpp:239] Iteration 6180 (9.26685 iter/s, 2.15823s/20 iters), loss = 0.00707215
I0522 10:27:17.387225 19861 solver.cpp:258]     Train net output #0: loss = 0.00707213 (* 1 = 0.00707213 loss)
I0522 10:27:17.387236 19861 sgd_solver.cpp:112] Iteration 6180, lr = 0.001
I0522 10:27:19.501749 19861 solver.cpp:239] Iteration 6200 (9.45843 iter/s, 2.11452s/20 iters), loss = 0.0100145
I0522 10:27:19.501866 19861 solver.cpp:258]     Train net output #0: loss = 0.0100145 (* 1 = 0.0100145 loss)
I0522 10:27:19.501883 19861 sgd_solver.cpp:112] Iteration 6200, lr = 0.001
I0522 10:27:21.947659 19861 solver.cpp:239] Iteration 6220 (8.17735 iter/s, 2.44578s/20 iters), loss = 0.0107029
I0522 10:27:21.947731 19861 solver.cpp:258]     Train net output #0: loss = 0.0107029 (* 1 = 0.0107029 loss)
I0522 10:27:21.947736 19861 sgd_solver.cpp:112] Iteration 6220, lr = 0.001
I0522 10:27:24.101675 19861 solver.cpp:239] Iteration 6240 (9.28538 iter/s, 2.15392s/20 iters), loss = 0.0192512
I0522 10:27:24.101778 19861 solver.cpp:258]     Train net output #0: loss = 0.0192511 (* 1 = 0.0192511 loss)
I0522 10:27:24.101783 19861 sgd_solver.cpp:112] Iteration 6240, lr = 0.001
I0522 10:27:26.256325 19861 solver.cpp:239] Iteration 6260 (9.28273 iter/s, 2.15454s/20 iters), loss = 0.0202408
I0522 10:27:26.256371 19861 solver.cpp:258]     Train net output #0: loss = 0.0202408 (* 1 = 0.0202408 loss)
I0522 10:27:26.256376 19861 sgd_solver.cpp:112] Iteration 6260, lr = 0.001
I0522 10:27:28.381414 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:27:28.634753 19861 solver.cpp:239] Iteration 6280 (8.40911 iter/s, 2.37837s/20 iters), loss = 0.00478467
I0522 10:27:28.634809 19861 solver.cpp:258]     Train net output #0: loss = 0.00478466 (* 1 = 0.00478466 loss)
I0522 10:27:28.634812 19861 sgd_solver.cpp:112] Iteration 6280, lr = 0.001
I0522 10:27:30.799360 19861 solver.cpp:239] Iteration 6300 (9.23989 iter/s, 2.16453s/20 iters), loss = 0.0115297
I0522 10:27:30.808800 19861 solver.cpp:258]     Train net output #0: loss = 0.0115296 (* 1 = 0.0115296 loss)
I0522 10:27:30.808809 19861 sgd_solver.cpp:112] Iteration 6300, lr = 0.001
I0522 10:27:32.837218 19861 solver.cpp:239] Iteration 6320 (9.85998 iter/s, 2.0284s/20 iters), loss = 0.00851922
I0522 10:27:32.846669 19861 solver.cpp:258]     Train net output #0: loss = 0.0085192 (* 1 = 0.0085192 loss)
I0522 10:27:32.846678 19861 sgd_solver.cpp:112] Iteration 6320, lr = 0.001
I0522 10:27:34.882964 19861 solver.cpp:239] Iteration 6340 (9.82181 iter/s, 2.03628s/20 iters), loss = 0.006688
I0522 10:27:34.892470 19861 solver.cpp:258]     Train net output #0: loss = 0.00668799 (* 1 = 0.00668799 loss)
I0522 10:27:34.892478 19861 sgd_solver.cpp:112] Iteration 6340, lr = 0.001
I0522 10:27:36.930809 19861 solver.cpp:239] Iteration 6360 (9.81198 iter/s, 2.03832s/20 iters), loss = 0.0207774
I0522 10:27:36.940248 19861 solver.cpp:258]     Train net output #0: loss = 0.0207774 (* 1 = 0.0207774 loss)
I0522 10:27:36.940255 19861 sgd_solver.cpp:112] Iteration 6360, lr = 0.001
I0522 10:27:40.361150 19861 solver.cpp:239] Iteration 6380 (5.84644 iter/s, 3.42089s/20 iters), loss = 0.011334
I0522 10:27:40.361739 19861 solver.cpp:258]     Train net output #0: loss = 0.0113339 (* 1 = 0.0113339 loss)
I0522 10:27:40.361747 19861 sgd_solver.cpp:112] Iteration 6380, lr = 0.001
I0522 10:27:42.565346 19861 solver.cpp:239] Iteration 6400 (9.08039 iter/s, 2.20255s/20 iters), loss = 0.0094734
I0522 10:27:42.575009 19861 solver.cpp:258]     Train net output #0: loss = 0.00947339 (* 1 = 0.00947339 loss)
I0522 10:27:42.575019 19861 sgd_solver.cpp:112] Iteration 6400, lr = 0.001
I0522 10:27:44.616405 19861 solver.cpp:239] Iteration 6420 (9.7973 iter/s, 2.04138s/20 iters), loss = 0.00543094
I0522 10:27:44.625991 19861 solver.cpp:258]     Train net output #0: loss = 0.00543093 (* 1 = 0.00543093 loss)
I0522 10:27:44.625999 19861 sgd_solver.cpp:112] Iteration 6420, lr = 0.001
I0522 10:27:45.715200 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:27:46.666916 19861 solver.cpp:239] Iteration 6440 (9.79953 iter/s, 2.04092s/20 iters), loss = 0.0137453
I0522 10:27:46.676407 19861 solver.cpp:258]     Train net output #0: loss = 0.0137453 (* 1 = 0.0137453 loss)
I0522 10:27:46.676470 19861 sgd_solver.cpp:112] Iteration 6440, lr = 0.001
I0522 10:27:48.962152 19861 solver.cpp:239] Iteration 6460 (8.74991 iter/s, 2.28574s/20 iters), loss = 0.0112362
I0522 10:27:48.962452 19861 solver.cpp:258]     Train net output #0: loss = 0.0112362 (* 1 = 0.0112362 loss)
I0522 10:27:48.962461 19861 sgd_solver.cpp:112] Iteration 6460, lr = 0.001
I0522 10:27:52.357167 19861 solver.cpp:239] Iteration 6480 (5.89152 iter/s, 3.39471s/20 iters), loss = 0.0146337
I0522 10:27:52.366771 19861 solver.cpp:258]     Train net output #0: loss = 0.0146336 (* 1 = 0.0146336 loss)
I0522 10:27:52.366780 19861 sgd_solver.cpp:112] Iteration 6480, lr = 0.001
I0522 10:27:54.404508 19861 solver.cpp:239] Iteration 6500 (9.81487 iter/s, 2.03772s/20 iters), loss = 0.00530054
I0522 10:27:54.413851 19861 solver.cpp:258]     Train net output #0: loss = 0.00530052 (* 1 = 0.00530052 loss)
I0522 10:27:54.413859 19861 sgd_solver.cpp:112] Iteration 6500, lr = 0.001
I0522 10:27:56.452728 19861 solver.cpp:239] Iteration 6520 (9.80937 iter/s, 2.03887s/20 iters), loss = 0.0182982
I0522 10:27:56.462255 19861 solver.cpp:258]     Train net output #0: loss = 0.0182982 (* 1 = 0.0182982 loss)
I0522 10:27:56.462266 19861 sgd_solver.cpp:112] Iteration 6520, lr = 0.001
I0522 10:27:58.504436 19861 solver.cpp:239] Iteration 6540 (9.79348 iter/s, 2.04218s/20 iters), loss = 0.0101062
I0522 10:27:58.513924 19861 solver.cpp:258]     Train net output #0: loss = 0.0101061 (* 1 = 0.0101061 loss)
I0522 10:27:58.513936 19861 sgd_solver.cpp:112] Iteration 6540, lr = 0.001
I0522 10:28:01.546890 19861 solver.cpp:239] Iteration 6560 (6.59421 iter/s, 3.03297s/20 iters), loss = 0.019514
I0522 10:28:01.556221 19861 solver.cpp:258]     Train net output #0: loss = 0.019514 (* 1 = 0.019514 loss)
I0522 10:28:01.556227 19861 sgd_solver.cpp:112] Iteration 6560, lr = 0.001
I0522 10:28:04.287289 19861 solver.cpp:239] Iteration 6580 (7.32317 iter/s, 2.73106s/20 iters), loss = 0.0106409
I0522 10:28:04.287364 19861 solver.cpp:258]     Train net output #0: loss = 0.0106409 (* 1 = 0.0106409 loss)
I0522 10:28:04.287366 19861 sgd_solver.cpp:112] Iteration 6580, lr = 0.001
I0522 10:28:04.503454 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:28:06.497368 19861 solver.cpp:239] Iteration 6600 (9.04978 iter/s, 2.21s/20 iters), loss = 0.00334832
I0522 10:28:06.497445 19861 solver.cpp:258]     Train net output #0: loss = 0.0033483 (* 1 = 0.0033483 loss)
I0522 10:28:06.497449 19861 sgd_solver.cpp:112] Iteration 6600, lr = 0.001
I0522 10:28:08.714378 19861 solver.cpp:239] Iteration 6620 (9.02154 iter/s, 2.21692s/20 iters), loss = 0.0111166
I0522 10:28:08.714469 19861 solver.cpp:258]     Train net output #0: loss = 0.0111165 (* 1 = 0.0111165 loss)
I0522 10:28:08.714475 19861 sgd_solver.cpp:112] Iteration 6620, lr = 0.001
I0522 10:28:11.201365 19861 solver.cpp:239] Iteration 6640 (8.04223 iter/s, 2.48687s/20 iters), loss = 0.0153364
I0522 10:28:11.216715 19861 solver.cpp:258]     Train net output #0: loss = 0.0153364 (* 1 = 0.0153364 loss)
I0522 10:28:11.216729 19861 sgd_solver.cpp:112] Iteration 6640, lr = 0.001
I0522 10:28:14.572885 19861 solver.cpp:239] Iteration 6660 (5.95916 iter/s, 3.35618s/20 iters), loss = 0.014808
I0522 10:28:14.572934 19861 solver.cpp:258]     Train net output #0: loss = 0.0148079 (* 1 = 0.0148079 loss)
I0522 10:28:14.572938 19861 sgd_solver.cpp:112] Iteration 6660, lr = 0.001
I0522 10:28:16.778167 19861 solver.cpp:239] Iteration 6680 (9.06944 iter/s, 2.20521s/20 iters), loss = 0.0145028
I0522 10:28:16.778317 19861 solver.cpp:258]     Train net output #0: loss = 0.0145027 (* 1 = 0.0145027 loss)
I0522 10:28:16.778326 19861 sgd_solver.cpp:112] Iteration 6680, lr = 0.001
I0522 10:28:18.972674 19861 solver.cpp:239] Iteration 6700 (9.11432 iter/s, 2.19435s/20 iters), loss = 0.0161566
I0522 10:28:18.973145 19861 solver.cpp:258]     Train net output #0: loss = 0.0161566 (* 1 = 0.0161566 loss)
I0522 10:28:18.973152 19861 sgd_solver.cpp:112] Iteration 6700, lr = 0.001
I0522 10:28:21.168123 19861 solver.cpp:239] Iteration 6720 (9.11179 iter/s, 2.19496s/20 iters), loss = 0.0150788
I0522 10:28:21.168206 19861 solver.cpp:258]     Train net output #0: loss = 0.0150788 (* 1 = 0.0150788 loss)
I0522 10:28:21.168212 19861 sgd_solver.cpp:112] Iteration 6720, lr = 0.001
I0522 10:28:24.063002 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:28:24.743762 19861 solver.cpp:239] Iteration 6740 (5.59356 iter/s, 3.57554s/20 iters), loss = 0.0110231
I0522 10:28:24.755834 19861 solver.cpp:258]     Train net output #0: loss = 0.0110231 (* 1 = 0.0110231 loss)
I0522 10:28:24.755843 19861 sgd_solver.cpp:112] Iteration 6740, lr = 0.001
I0522 10:28:26.927383 19861 solver.cpp:239] Iteration 6760 (9.21042 iter/s, 2.17145s/20 iters), loss = 0.00750713
I0522 10:28:26.936893 19861 solver.cpp:258]     Train net output #0: loss = 0.00750711 (* 1 = 0.00750711 loss)
I0522 10:28:26.936903 19861 sgd_solver.cpp:112] Iteration 6760, lr = 0.001
I0522 10:28:28.969298 19861 solver.cpp:239] Iteration 6780 (9.84062 iter/s, 2.03239s/20 iters), loss = 0.0048414
I0522 10:28:28.978689 19861 solver.cpp:258]     Train net output #0: loss = 0.00484138 (* 1 = 0.00484138 loss)
I0522 10:28:28.978699 19861 sgd_solver.cpp:112] Iteration 6780, lr = 0.001
I0522 10:28:31.010605 19861 solver.cpp:239] Iteration 6800 (9.84298 iter/s, 2.0319s/20 iters), loss = 0.00259497
I0522 10:28:31.020153 19861 solver.cpp:258]     Train net output #0: loss = 0.00259494 (* 1 = 0.00259494 loss)
I0522 10:28:31.020161 19861 sgd_solver.cpp:112] Iteration 6800, lr = 0.001
I0522 10:28:33.088985 19861 solver.cpp:239] Iteration 6820 (9.66982 iter/s, 2.06829s/20 iters), loss = 0.0123625
I0522 10:28:33.090282 19861 solver.cpp:258]     Train net output #0: loss = 0.0123625 (* 1 = 0.0123625 loss)
I0522 10:28:33.090654 19861 sgd_solver.cpp:112] Iteration 6820, lr = 0.001
I0522 10:28:36.732264 19861 solver.cpp:239] Iteration 6840 (5.4912 iter/s, 3.64219s/20 iters), loss = 0.0113251
I0522 10:28:36.732318 19861 solver.cpp:258]     Train net output #0: loss = 0.0113251 (* 1 = 0.0113251 loss)
I0522 10:28:36.732323 19861 sgd_solver.cpp:112] Iteration 6840, lr = 0.001
I0522 10:28:38.926539 19861 solver.cpp:239] Iteration 6860 (9.11493 iter/s, 2.1942s/20 iters), loss = 0.0174414
I0522 10:28:38.936084 19861 solver.cpp:258]     Train net output #0: loss = 0.0174414 (* 1 = 0.0174414 loss)
I0522 10:28:38.936092 19861 sgd_solver.cpp:112] Iteration 6860, lr = 0.001
I0522 10:28:40.976049 19861 solver.cpp:239] Iteration 6880 (9.80414 iter/s, 2.03996s/20 iters), loss = 0.00522258
I0522 10:28:40.985512 19861 solver.cpp:258]     Train net output #0: loss = 0.00522256 (* 1 = 0.00522256 loss)
I0522 10:28:40.985524 19861 sgd_solver.cpp:112] Iteration 6880, lr = 0.001
I0522 10:28:42.036496 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:28:43.028264 19861 solver.cpp:239] Iteration 6900 (9.79075 iter/s, 2.04274s/20 iters), loss = 0.04138
I0522 10:28:43.037740 19861 solver.cpp:258]     Train net output #0: loss = 0.04138 (* 1 = 0.04138 loss)
I0522 10:28:43.037752 19861 sgd_solver.cpp:112] Iteration 6900, lr = 0.001
I0522 10:28:46.144183 19861 solver.cpp:239] Iteration 6920 (6.43822 iter/s, 3.10645s/20 iters), loss = 0.0078407
I0522 10:28:46.153414 19861 solver.cpp:258]     Train net output #0: loss = 0.00784068 (* 1 = 0.00784068 loss)
I0522 10:28:46.153424 19861 sgd_solver.cpp:112] Iteration 6920, lr = 0.001
I0522 10:28:48.723392 19861 solver.cpp:239] Iteration 6940 (7.78228 iter/s, 2.56994s/20 iters), loss = 0.00787915
I0522 10:28:48.732933 19861 solver.cpp:258]     Train net output #0: loss = 0.00787913 (* 1 = 0.00787913 loss)
I0522 10:28:48.732944 19861 sgd_solver.cpp:112] Iteration 6940, lr = 0.001
I0522 10:28:50.301239 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:28:50.773608 19861 solver.cpp:239] Iteration 6960 (9.80069 iter/s, 2.04067s/20 iters), loss = 0.00242896
I0522 10:28:50.782999 19861 solver.cpp:258]     Train net output #0: loss = 0.00242894 (* 1 = 0.00242894 loss)
I0522 10:28:50.783008 19861 sgd_solver.cpp:112] Iteration 6960, lr = 0.001
I0522 10:28:52.821897 19861 solver.cpp:239] Iteration 6980 (9.80931 iter/s, 2.03888s/20 iters), loss = 0.0123981
I0522 10:28:52.831342 19861 solver.cpp:258]     Train net output #0: loss = 0.0123981 (* 1 = 0.0123981 loss)
I0522 10:28:52.831352 19861 sgd_solver.cpp:112] Iteration 6980, lr = 0.001
I0522 10:28:54.706653 19861 solver.cpp:347] Iteration 7000, Testing net (#0)
I0522 10:28:56.622421 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:29:02.685322 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:29:07.457826 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:29:11.482101 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:29:13.958604 19861 solver.cpp:414]     Test net output #0: accuracy = 0.861401
I0522 10:29:13.958667 19861 solver.cpp:414]     Test net output #1: loss = 0.787574 (* 1 = 0.787574 loss)
I0522 10:29:14.055270 19861 solver.cpp:239] Iteration 7000 (0.942329 iter/s, 21.224s/20 iters), loss = 0.0164417
I0522 10:29:14.057314 19861 solver.cpp:258]     Train net output #0: loss = 0.0164417 (* 1 = 0.0164417 loss)
I0522 10:29:14.057325 19861 sgd_solver.cpp:112] Iteration 7000, lr = 0.001
I0522 10:29:16.252698 19861 solver.cpp:239] Iteration 7020 (9.1107 iter/s, 2.19522s/20 iters), loss = 0.00913557
I0522 10:29:16.253147 19861 solver.cpp:258]     Train net output #0: loss = 0.00913555 (* 1 = 0.00913555 loss)
I0522 10:29:16.253192 19861 sgd_solver.cpp:112] Iteration 7020, lr = 0.001
I0522 10:29:19.625943 19861 solver.cpp:239] Iteration 7040 (5.92973 iter/s, 3.37284s/20 iters), loss = 0.00359887
I0522 10:29:19.635406 19861 solver.cpp:258]     Train net output #0: loss = 0.00359885 (* 1 = 0.00359885 loss)
I0522 10:29:19.635412 19861 sgd_solver.cpp:112] Iteration 7040, lr = 0.001
I0522 10:29:19.999096 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:29:21.676730 19861 solver.cpp:239] Iteration 7060 (9.79787 iter/s, 2.04126s/20 iters), loss = 0.0159556
I0522 10:29:21.686383 19861 solver.cpp:258]     Train net output #0: loss = 0.0159556 (* 1 = 0.0159556 loss)
I0522 10:29:21.686391 19861 sgd_solver.cpp:112] Iteration 7060, lr = 0.001
I0522 10:29:21.924906 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:29:23.712240 19861 solver.cpp:239] Iteration 7080 (9.87241 iter/s, 2.02585s/20 iters), loss = 0.00620828
I0522 10:29:23.721732 19861 solver.cpp:258]     Train net output #0: loss = 0.00620826 (* 1 = 0.00620826 loss)
I0522 10:29:23.721740 19861 sgd_solver.cpp:112] Iteration 7080, lr = 0.001
I0522 10:29:25.748656 19861 solver.cpp:239] Iteration 7100 (9.86727 iter/s, 2.0269s/20 iters), loss = 0.025277
I0522 10:29:25.758229 19861 solver.cpp:258]     Train net output #0: loss = 0.0252769 (* 1 = 0.0252769 loss)
I0522 10:29:25.758236 19861 sgd_solver.cpp:112] Iteration 7100, lr = 0.001
I0522 10:29:28.562073 19861 solver.cpp:239] Iteration 7120 (7.13307 iter/s, 2.80384s/20 iters), loss = 0.00520966
I0522 10:29:28.571540 19861 solver.cpp:258]     Train net output #0: loss = 0.00520964 (* 1 = 0.00520964 loss)
I0522 10:29:28.571547 19861 sgd_solver.cpp:112] Iteration 7120, lr = 0.001
I0522 10:29:31.421597 19861 solver.cpp:239] Iteration 7140 (7.01753 iter/s, 2.85001s/20 iters), loss = 0.0149689
I0522 10:29:31.421779 19861 solver.cpp:258]     Train net output #0: loss = 0.0149689 (* 1 = 0.0149689 loss)
I0522 10:29:31.421788 19861 sgd_solver.cpp:112] Iteration 7140, lr = 0.001
I0522 10:29:33.468614 19861 solver.cpp:239] Iteration 7160 (9.77125 iter/s, 2.04682s/20 iters), loss = 0.0022062
I0522 10:29:33.478302 19861 solver.cpp:258]     Train net output #0: loss = 0.00220619 (* 1 = 0.00220619 loss)
I0522 10:29:33.478310 19861 sgd_solver.cpp:112] Iteration 7160, lr = 0.001
I0522 10:29:35.510430 19861 solver.cpp:239] Iteration 7180 (9.84197 iter/s, 2.03211s/20 iters), loss = 0.00257489
I0522 10:29:35.520018 19861 solver.cpp:258]     Train net output #0: loss = 0.00257487 (* 1 = 0.00257487 loss)
I0522 10:29:35.520030 19861 sgd_solver.cpp:112] Iteration 7180, lr = 0.001
I0522 10:29:37.210590 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:29:37.556499 19861 solver.cpp:239] Iteration 7200 (9.82091 iter/s, 2.03647s/20 iters), loss = 0.00631548
I0522 10:29:37.566706 19861 solver.cpp:258]     Train net output #0: loss = 0.00631546 (* 1 = 0.00631546 loss)
I0522 10:29:37.566715 19861 sgd_solver.cpp:112] Iteration 7200, lr = 0.001
I0522 10:29:41.037004 19861 solver.cpp:239] Iteration 7220 (5.7632 iter/s, 3.47029s/20 iters), loss = 0.0141647
I0522 10:29:41.046130 19861 solver.cpp:258]     Train net output #0: loss = 0.0141647 (* 1 = 0.0141647 loss)
I0522 10:29:41.046144 19861 sgd_solver.cpp:112] Iteration 7220, lr = 0.001
I0522 10:29:43.238598 19861 solver.cpp:239] Iteration 7240 (9.12218 iter/s, 2.19246s/20 iters), loss = 0.0208052
I0522 10:29:43.248147 19861 solver.cpp:258]     Train net output #0: loss = 0.0208052 (* 1 = 0.0208052 loss)
I0522 10:29:43.248154 19861 sgd_solver.cpp:112] Iteration 7240, lr = 0.001
I0522 10:29:45.293133 19861 solver.cpp:239] Iteration 7260 (9.78008 iter/s, 2.04497s/20 iters), loss = 0.00311728
I0522 10:29:45.302646 19861 solver.cpp:258]     Train net output #0: loss = 0.00311727 (* 1 = 0.00311727 loss)
I0522 10:29:45.302654 19861 sgd_solver.cpp:112] Iteration 7260, lr = 0.001
I0522 10:29:47.343350 19861 solver.cpp:239] Iteration 7280 (9.80061 iter/s, 2.04069s/20 iters), loss = 0.00890224
I0522 10:29:47.352712 19861 solver.cpp:258]     Train net output #0: loss = 0.00890222 (* 1 = 0.00890222 loss)
I0522 10:29:47.352721 19861 sgd_solver.cpp:112] Iteration 7280, lr = 0.001
I0522 10:29:49.401510 19861 solver.cpp:239] Iteration 7300 (9.76185 iter/s, 2.04879s/20 iters), loss = 0.00518337
I0522 10:29:49.401566 19861 solver.cpp:258]     Train net output #0: loss = 0.00518335 (* 1 = 0.00518335 loss)
I0522 10:29:49.401573 19861 sgd_solver.cpp:112] Iteration 7300, lr = 0.001
I0522 10:29:53.032505 19861 solver.cpp:239] Iteration 7320 (5.50821 iter/s, 3.63094s/20 iters), loss = 0.00687025
I0522 10:29:53.032812 19861 solver.cpp:258]     Train net output #0: loss = 0.00687023 (* 1 = 0.00687023 loss)
I0522 10:29:53.032817 19861 sgd_solver.cpp:112] Iteration 7320, lr = 0.001
I0522 10:29:55.240288 19861 solver.cpp:239] Iteration 7340 (9.06023 iter/s, 2.20745s/20 iters), loss = 0.0100487
I0522 10:29:55.240420 19861 solver.cpp:258]     Train net output #0: loss = 0.0100487 (* 1 = 0.0100487 loss)
I0522 10:29:55.240427 19861 sgd_solver.cpp:112] Iteration 7340, lr = 0.001
I0522 10:29:56.204536 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:29:57.385079 19861 solver.cpp:239] Iteration 7360 (9.32553 iter/s, 2.14465s/20 iters), loss = 0.00774752
I0522 10:29:57.394744 19861 solver.cpp:258]     Train net output #0: loss = 0.00774751 (* 1 = 0.00774751 loss)
I0522 10:29:57.394754 19861 sgd_solver.cpp:112] Iteration 7360, lr = 0.001
I0522 10:30:00.384667 19861 solver.cpp:239] Iteration 7380 (6.68912 iter/s, 2.98993s/20 iters), loss = 0.0124543
I0522 10:30:00.393769 19861 solver.cpp:258]     Train net output #0: loss = 0.0124543 (* 1 = 0.0124543 loss)
I0522 10:30:00.393775 19861 sgd_solver.cpp:112] Iteration 7380, lr = 0.001
I0522 10:30:02.441710 19861 solver.cpp:239] Iteration 7400 (9.76592 iter/s, 2.04794s/20 iters), loss = 0.00912093
I0522 10:30:02.450984 19861 solver.cpp:258]     Train net output #0: loss = 0.00912092 (* 1 = 0.00912092 loss)
I0522 10:30:02.450992 19861 sgd_solver.cpp:112] Iteration 7400, lr = 0.001
I0522 10:30:04.492255 19861 solver.cpp:239] Iteration 7420 (9.79783 iter/s, 2.04127s/20 iters), loss = 0.00461188
I0522 10:30:04.501513 19861 solver.cpp:258]     Train net output #0: loss = 0.00461186 (* 1 = 0.00461186 loss)
I0522 10:30:04.501519 19861 sgd_solver.cpp:112] Iteration 7420, lr = 0.001
I0522 10:30:06.542239 19861 solver.cpp:239] Iteration 7440 (9.80045 iter/s, 2.04072s/20 iters), loss = 0.00992425
I0522 10:30:06.551333 19861 solver.cpp:258]     Train net output #0: loss = 0.00992423 (* 1 = 0.00992423 loss)
I0522 10:30:06.551340 19861 sgd_solver.cpp:112] Iteration 7440, lr = 0.001
I0522 10:30:08.588572 19861 solver.cpp:239] Iteration 7460 (9.81724 iter/s, 2.03723s/20 iters), loss = 0.00597897
I0522 10:30:08.597666 19861 solver.cpp:258]     Train net output #0: loss = 0.00597895 (* 1 = 0.00597895 loss)
I0522 10:30:08.597673 19861 sgd_solver.cpp:112] Iteration 7460, lr = 0.001
I0522 10:30:10.635099 19861 solver.cpp:239] Iteration 7480 (9.81629 iter/s, 2.03743s/20 iters), loss = 0.020585
I0522 10:30:10.644173 19861 solver.cpp:258]     Train net output #0: loss = 0.020585 (* 1 = 0.020585 loss)
I0522 10:30:10.644181 19861 sgd_solver.cpp:112] Iteration 7480, lr = 0.001
I0522 10:30:12.682140 19861 solver.cpp:239] Iteration 7500 (9.81373 iter/s, 2.03796s/20 iters), loss = 0.010374
I0522 10:30:12.691267 19861 solver.cpp:258]     Train net output #0: loss = 0.010374 (* 1 = 0.010374 loss)
I0522 10:30:12.691275 19861 sgd_solver.cpp:112] Iteration 7500, lr = 0.001
I0522 10:30:12.964038 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:30:14.729943 19861 solver.cpp:239] Iteration 7520 (9.8103 iter/s, 2.03867s/20 iters), loss = 0.0127291
I0522 10:30:14.739089 19861 solver.cpp:258]     Train net output #0: loss = 0.0127291 (* 1 = 0.0127291 loss)
I0522 10:30:14.739094 19861 sgd_solver.cpp:112] Iteration 7520, lr = 0.001
I0522 10:30:16.785131 19861 solver.cpp:239] Iteration 7540 (9.7751 iter/s, 2.04601s/20 iters), loss = 0.010794
I0522 10:30:16.795037 19861 solver.cpp:258]     Train net output #0: loss = 0.010794 (* 1 = 0.010794 loss)
I0522 10:30:16.795051 19861 sgd_solver.cpp:112] Iteration 7540, lr = 0.001
I0522 10:30:18.831264 19861 solver.cpp:239] Iteration 7560 (9.82206 iter/s, 2.03623s/20 iters), loss = 0.0154471
I0522 10:30:18.840564 19861 solver.cpp:258]     Train net output #0: loss = 0.0154471 (* 1 = 0.0154471 loss)
I0522 10:30:18.840572 19861 sgd_solver.cpp:112] Iteration 7560, lr = 0.001
I0522 10:30:20.881448 19861 solver.cpp:239] Iteration 7580 (9.79969 iter/s, 2.04088s/20 iters), loss = 0.00204377
I0522 10:30:20.890733 19861 solver.cpp:258]     Train net output #0: loss = 0.00204376 (* 1 = 0.00204376 loss)
I0522 10:30:20.890766 19861 sgd_solver.cpp:112] Iteration 7580, lr = 0.001
I0522 10:30:22.950369 19861 solver.cpp:239] Iteration 7600 (9.71043 iter/s, 2.05964s/20 iters), loss = 0.0111558
I0522 10:30:22.959787 19861 solver.cpp:258]     Train net output #0: loss = 0.0111558 (* 1 = 0.0111558 loss)
I0522 10:30:22.959794 19861 sgd_solver.cpp:112] Iteration 7600, lr = 0.001
I0522 10:30:25.023701 19861 solver.cpp:239] Iteration 7620 (9.69033 iter/s, 2.06391s/20 iters), loss = 0.0031514
I0522 10:30:25.033084 19861 solver.cpp:258]     Train net output #0: loss = 0.00315139 (* 1 = 0.00315139 loss)
I0522 10:30:25.033090 19861 sgd_solver.cpp:112] Iteration 7620, lr = 0.001
I0522 10:30:27.096071 19861 solver.cpp:239] Iteration 7640 (9.69465 iter/s, 2.06299s/20 iters), loss = 0.00752832
I0522 10:30:27.105412 19861 solver.cpp:258]     Train net output #0: loss = 0.0075283 (* 1 = 0.0075283 loss)
I0522 10:30:27.105418 19861 sgd_solver.cpp:112] Iteration 7640, lr = 0.001
I0522 10:30:28.776477 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:30:29.177769 19861 solver.cpp:239] Iteration 7660 (9.6509 iter/s, 2.07235s/20 iters), loss = 0.0237258
I0522 10:30:29.187331 19861 solver.cpp:258]     Train net output #0: loss = 0.0237258 (* 1 = 0.0237258 loss)
I0522 10:30:29.187338 19861 sgd_solver.cpp:112] Iteration 7660, lr = 0.001
I0522 10:30:31.240960 19861 solver.cpp:239] Iteration 7680 (9.73892 iter/s, 2.05362s/20 iters), loss = 0.0104297
I0522 10:30:31.250718 19861 solver.cpp:258]     Train net output #0: loss = 0.0104296 (* 1 = 0.0104296 loss)
I0522 10:30:31.250725 19861 sgd_solver.cpp:112] Iteration 7680, lr = 0.001
I0522 10:30:33.551501 19861 solver.cpp:239] Iteration 7700 (8.69272 iter/s, 2.30078s/20 iters), loss = 0.00384293
I0522 10:30:33.561766 19861 solver.cpp:258]     Train net output #0: loss = 0.00384291 (* 1 = 0.00384291 loss)
I0522 10:30:33.561774 19861 sgd_solver.cpp:112] Iteration 7700, lr = 0.001
I0522 10:30:35.816608 19861 solver.cpp:239] Iteration 7720 (8.8699 iter/s, 2.25482s/20 iters), loss = 0.00254071
I0522 10:30:35.816725 19861 solver.cpp:258]     Train net output #0: loss = 0.0025407 (* 1 = 0.0025407 loss)
I0522 10:30:35.816738 19861 sgd_solver.cpp:112] Iteration 7720, lr = 0.001
I0522 10:30:38.024179 19861 solver.cpp:239] Iteration 7740 (9.0602 iter/s, 2.20746s/20 iters), loss = 0.00382588
I0522 10:30:38.024219 19861 solver.cpp:258]     Train net output #0: loss = 0.00382587 (* 1 = 0.00382587 loss)
I0522 10:30:38.024224 19861 sgd_solver.cpp:112] Iteration 7740, lr = 0.001
I0522 10:30:40.229111 19861 solver.cpp:239] Iteration 7760 (9.07072 iter/s, 2.2049s/20 iters), loss = 0.00428462
I0522 10:30:40.239253 19861 solver.cpp:258]     Train net output #0: loss = 0.00428461 (* 1 = 0.00428461 loss)
I0522 10:30:40.239261 19861 sgd_solver.cpp:112] Iteration 7760, lr = 0.001
I0522 10:30:42.292451 19861 solver.cpp:239] Iteration 7780 (9.74103 iter/s, 2.05317s/20 iters), loss = 0.0158881
I0522 10:30:42.292551 19861 solver.cpp:258]     Train net output #0: loss = 0.0158881 (* 1 = 0.0158881 loss)
I0522 10:30:42.292555 19861 sgd_solver.cpp:112] Iteration 7780, lr = 0.001
I0522 10:30:44.358105 19861 solver.cpp:239] Iteration 7800 (9.68266 iter/s, 2.06555s/20 iters), loss = 0.0153613
I0522 10:30:44.367552 19861 solver.cpp:258]     Train net output #0: loss = 0.0153613 (* 1 = 0.0153613 loss)
I0522 10:30:44.367559 19861 sgd_solver.cpp:112] Iteration 7800, lr = 0.001
I0522 10:30:45.622570 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:30:46.741449 19861 solver.cpp:239] Iteration 7820 (8.425 iter/s, 2.37389s/20 iters), loss = 0.014984
I0522 10:30:46.750524 19861 solver.cpp:258]     Train net output #0: loss = 0.014984 (* 1 = 0.014984 loss)
I0522 10:30:46.750532 19861 sgd_solver.cpp:112] Iteration 7820, lr = 0.001
I0522 10:30:48.821171 19861 solver.cpp:239] Iteration 7840 (9.6588 iter/s, 2.07065s/20 iters), loss = 0.0121065
I0522 10:30:48.821207 19861 solver.cpp:258]     Train net output #0: loss = 0.0121065 (* 1 = 0.0121065 loss)
I0522 10:30:48.821210 19861 sgd_solver.cpp:112] Iteration 7840, lr = 0.001
I0522 10:30:50.896234 19861 solver.cpp:239] Iteration 7860 (9.63851 iter/s, 2.07501s/20 iters), loss = 0.0097671
I0522 10:30:50.896301 19861 solver.cpp:258]     Train net output #0: loss = 0.00976708 (* 1 = 0.00976708 loss)
I0522 10:30:50.896306 19861 sgd_solver.cpp:112] Iteration 7860, lr = 0.001
I0522 10:30:53.004948 19861 solver.cpp:239] Iteration 7880 (9.48479 iter/s, 2.10864s/20 iters), loss = 0.00567346
I0522 10:30:53.015108 19861 solver.cpp:258]     Train net output #0: loss = 0.00567345 (* 1 = 0.00567345 loss)
I0522 10:30:53.015146 19861 sgd_solver.cpp:112] Iteration 7880, lr = 0.001
I0522 10:30:55.414320 19861 solver.cpp:239] Iteration 7900 (8.33612 iter/s, 2.3992s/20 iters), loss = 0.00808634
I0522 10:30:55.427397 19861 solver.cpp:258]     Train net output #0: loss = 0.00808632 (* 1 = 0.00808632 loss)
I0522 10:30:55.427404 19861 sgd_solver.cpp:112] Iteration 7900, lr = 0.001
I0522 10:30:57.514961 19861 solver.cpp:239] Iteration 7920 (9.58064 iter/s, 2.08754s/20 iters), loss = 0.00520858
I0522 10:30:57.515051 19861 solver.cpp:258]     Train net output #0: loss = 0.00520856 (* 1 = 0.00520856 loss)
I0522 10:30:57.515056 19861 sgd_solver.cpp:112] Iteration 7920, lr = 0.001
I0522 10:30:59.620470 19861 solver.cpp:239] Iteration 7940 (9.49933 iter/s, 2.10541s/20 iters), loss = 0.0103891
I0522 10:30:59.620527 19861 solver.cpp:258]     Train net output #0: loss = 0.0103891 (* 1 = 0.0103891 loss)
I0522 10:30:59.620532 19861 sgd_solver.cpp:112] Iteration 7940, lr = 0.001
I0522 10:31:01.747362 19861 solver.cpp:239] Iteration 7960 (9.40372 iter/s, 2.12682s/20 iters), loss = 0.0044482
I0522 10:31:01.747432 19861 solver.cpp:258]     Train net output #0: loss = 0.00444817 (* 1 = 0.00444817 loss)
I0522 10:31:01.747436 19861 sgd_solver.cpp:112] Iteration 7960, lr = 0.001
I0522 10:31:02.007236 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:31:04.223248 19861 solver.cpp:239] Iteration 7980 (8.07819 iter/s, 2.4758s/20 iters), loss = 0.00360862
I0522 10:31:04.236367 19861 solver.cpp:258]     Train net output #0: loss = 0.0036086 (* 1 = 0.0036086 loss)
I0522 10:31:04.236374 19861 sgd_solver.cpp:112] Iteration 7980, lr = 0.001
I0522 10:31:06.183974 19861 solver.cpp:347] Iteration 8000, Testing net (#0)
I0522 10:31:08.143381 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:31:10.843634 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:31:12.368010 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:31:16.320688 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:31:20.474445 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:31:22.987545 19861 solver.cpp:414]     Test net output #0: accuracy = 0.866322
I0522 10:31:22.987586 19861 solver.cpp:414]     Test net output #1: loss = 0.769525 (* 1 = 0.769525 loss)
I0522 10:31:23.083292 19861 solver.cpp:239] Iteration 8000 (1.06118 iter/s, 18.847s/20 iters), loss = 0.00378254
I0522 10:31:23.086182 19861 solver.cpp:258]     Train net output #0: loss = 0.00378252 (* 1 = 0.00378252 loss)
I0522 10:31:23.086196 19861 sgd_solver.cpp:112] Iteration 8000, lr = 0.001
I0522 10:31:25.281721 19861 solver.cpp:239] Iteration 8020 (9.10953 iter/s, 2.1955s/20 iters), loss = 0.00497068
I0522 10:31:25.281839 19861 solver.cpp:258]     Train net output #0: loss = 0.00497066 (* 1 = 0.00497066 loss)
I0522 10:31:25.281844 19861 sgd_solver.cpp:112] Iteration 8020, lr = 0.001
I0522 10:31:27.665688 19861 solver.cpp:239] Iteration 8040 (8.38983 iter/s, 2.38384s/20 iters), loss = 0.00374117
I0522 10:31:27.676218 19861 solver.cpp:258]     Train net output #0: loss = 0.00374114 (* 1 = 0.00374114 loss)
I0522 10:31:27.676225 19861 sgd_solver.cpp:112] Iteration 8040, lr = 0.001
I0522 10:31:29.788899 19861 solver.cpp:239] Iteration 8060 (9.46669 iter/s, 2.11267s/20 iters), loss = 0.00431527
I0522 10:31:29.802471 19861 solver.cpp:258]     Train net output #0: loss = 0.00431524 (* 1 = 0.00431524 loss)
I0522 10:31:29.802479 19861 sgd_solver.cpp:112] Iteration 8060, lr = 0.001
I0522 10:31:31.914425 19861 solver.cpp:239] Iteration 8080 (9.46993 iter/s, 2.11195s/20 iters), loss = 0.00844084
I0522 10:31:31.914487 19861 solver.cpp:258]     Train net output #0: loss = 0.00844081 (* 1 = 0.00844081 loss)
I0522 10:31:31.914491 19861 sgd_solver.cpp:112] Iteration 8080, lr = 0.001
I0522 10:31:34.230561 19861 solver.cpp:239] Iteration 8100 (8.63538 iter/s, 2.31605s/20 iters), loss = 0.00976849
I0522 10:31:34.243667 19861 solver.cpp:258]     Train net output #0: loss = 0.00976847 (* 1 = 0.00976847 loss)
I0522 10:31:34.243676 19861 sgd_solver.cpp:112] Iteration 8100, lr = 0.001
I0522 10:31:35.884575 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:31:36.343757 19861 solver.cpp:239] Iteration 8120 (9.52342 iter/s, 2.10009s/20 iters), loss = 0.0266433
I0522 10:31:36.353878 19861 solver.cpp:258]     Train net output #0: loss = 0.0266432 (* 1 = 0.0266432 loss)
I0522 10:31:36.353886 19861 sgd_solver.cpp:112] Iteration 8120, lr = 0.001
I0522 10:31:38.485069 19861 solver.cpp:239] Iteration 8140 (9.38442 iter/s, 2.13119s/20 iters), loss = 0.00407996
I0522 10:31:38.485100 19861 solver.cpp:258]     Train net output #0: loss = 0.00407993 (* 1 = 0.00407993 loss)
I0522 10:31:38.485105 19861 sgd_solver.cpp:112] Iteration 8140, lr = 0.001
I0522 10:31:40.867074 19861 solver.cpp:239] Iteration 8160 (8.39648 iter/s, 2.38195s/20 iters), loss = 0.00734494
I0522 10:31:40.867174 19861 solver.cpp:258]     Train net output #0: loss = 0.00734491 (* 1 = 0.00734491 loss)
I0522 10:31:40.867178 19861 sgd_solver.cpp:112] Iteration 8160, lr = 0.001
I0522 10:31:43.002053 19861 solver.cpp:239] Iteration 8180 (9.36826 iter/s, 2.13487s/20 iters), loss = 0.0158413
I0522 10:31:43.002104 19861 solver.cpp:258]     Train net output #0: loss = 0.0158413 (* 1 = 0.0158413 loss)
I0522 10:31:43.002107 19861 sgd_solver.cpp:112] Iteration 8180, lr = 0.001
I0522 10:31:45.110708 19861 solver.cpp:239] Iteration 8200 (9.48513 iter/s, 2.10856s/20 iters), loss = 0.0206981
I0522 10:31:45.110852 19861 solver.cpp:258]     Train net output #0: loss = 0.020698 (* 1 = 0.020698 loss)
I0522 10:31:45.110863 19861 sgd_solver.cpp:112] Iteration 8200, lr = 0.001
I0522 10:31:47.199578 19861 solver.cpp:239] Iteration 8220 (9.57538 iter/s, 2.08869s/20 iters), loss = 0.00736708
I0522 10:31:47.199708 19861 solver.cpp:258]     Train net output #0: loss = 0.00736705 (* 1 = 0.00736705 loss)
I0522 10:31:47.199720 19861 sgd_solver.cpp:112] Iteration 8220, lr = 0.001
I0522 10:31:49.505055 19861 solver.cpp:239] Iteration 8240 (8.67549 iter/s, 2.30534s/20 iters), loss = 0.00207411
I0522 10:31:49.514225 19861 solver.cpp:258]     Train net output #0: loss = 0.00207408 (* 1 = 0.00207408 loss)
I0522 10:31:49.514240 19861 sgd_solver.cpp:112] Iteration 8240, lr = 0.001
I0522 10:31:51.653146 19861 solver.cpp:239] Iteration 8260 (9.35058 iter/s, 2.1389s/20 iters), loss = 0.00594543
I0522 10:31:51.653239 19861 solver.cpp:258]     Train net output #0: loss = 0.0059454 (* 1 = 0.0059454 loss)
I0522 10:31:51.653244 19861 sgd_solver.cpp:112] Iteration 8260, lr = 0.001
I0522 10:31:52.577250 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:31:53.305183 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:31:53.789739 19861 solver.cpp:239] Iteration 8280 (9.36114 iter/s, 2.13649s/20 iters), loss = 0.0107051
I0522 10:31:53.789795 19861 solver.cpp:258]     Train net output #0: loss = 0.0107051 (* 1 = 0.0107051 loss)
I0522 10:31:53.789799 19861 sgd_solver.cpp:112] Iteration 8280, lr = 0.001
I0522 10:31:56.124372 19861 solver.cpp:239] Iteration 8300 (8.56707 iter/s, 2.33452s/20 iters), loss = 0.00252307
I0522 10:31:56.134707 19861 solver.cpp:258]     Train net output #0: loss = 0.00252304 (* 1 = 0.00252304 loss)
I0522 10:31:56.134722 19861 sgd_solver.cpp:112] Iteration 8300, lr = 0.001
I0522 10:31:58.273476 19861 solver.cpp:239] Iteration 8320 (9.35123 iter/s, 2.13876s/20 iters), loss = 0.00370194
I0522 10:31:58.273891 19861 solver.cpp:258]     Train net output #0: loss = 0.00370191 (* 1 = 0.00370191 loss)
I0522 10:31:58.273895 19861 sgd_solver.cpp:112] Iteration 8320, lr = 0.001
I0522 10:32:00.447154 19861 solver.cpp:239] Iteration 8340 (9.20279 iter/s, 2.17325s/20 iters), loss = 0.0063142
I0522 10:32:00.447211 19861 solver.cpp:258]     Train net output #0: loss = 0.00631417 (* 1 = 0.00631417 loss)
I0522 10:32:00.447216 19861 sgd_solver.cpp:112] Iteration 8340, lr = 0.001
I0522 10:32:02.919100 19861 solver.cpp:239] Iteration 8360 (8.09103 iter/s, 2.47187s/20 iters), loss = 0.0072816
I0522 10:32:02.932183 19861 solver.cpp:258]     Train net output #0: loss = 0.00728157 (* 1 = 0.00728157 loss)
I0522 10:32:02.932189 19861 sgd_solver.cpp:112] Iteration 8360, lr = 0.001
I0522 10:32:05.064079 19861 solver.cpp:239] Iteration 8380 (9.3813 iter/s, 2.1319s/20 iters), loss = 0.00888606
I0522 10:32:05.064110 19861 solver.cpp:258]     Train net output #0: loss = 0.00888602 (* 1 = 0.00888602 loss)
I0522 10:32:05.064113 19861 sgd_solver.cpp:112] Iteration 8380, lr = 0.001
I0522 10:32:07.193850 19861 solver.cpp:239] Iteration 8400 (9.39083 iter/s, 2.12974s/20 iters), loss = 0.0123002
I0522 10:32:07.193881 19861 solver.cpp:258]     Train net output #0: loss = 0.0123001 (* 1 = 0.0123001 loss)
I0522 10:32:07.193884 19861 sgd_solver.cpp:112] Iteration 8400, lr = 0.001
I0522 10:32:09.354720 19861 solver.cpp:239] Iteration 8420 (9.25568 iter/s, 2.16084s/20 iters), loss = 0.00328491
I0522 10:32:09.354758 19861 solver.cpp:258]     Train net output #0: loss = 0.00328488 (* 1 = 0.00328488 loss)
I0522 10:32:09.354760 19861 sgd_solver.cpp:112] Iteration 8420, lr = 0.001
I0522 10:32:09.551896 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:32:11.832176 19861 solver.cpp:239] Iteration 8440 (8.07301 iter/s, 2.47739s/20 iters), loss = 0.0016305
I0522 10:32:11.832252 19861 solver.cpp:258]     Train net output #0: loss = 0.00163047 (* 1 = 0.00163047 loss)
I0522 10:32:11.832260 19861 sgd_solver.cpp:112] Iteration 8440, lr = 0.001
I0522 10:32:13.996284 19861 solver.cpp:239] Iteration 8460 (9.24207 iter/s, 2.16402s/20 iters), loss = 0.002004
I0522 10:32:14.009953 19861 solver.cpp:258]     Train net output #0: loss = 0.00200397 (* 1 = 0.00200397 loss)
I0522 10:32:14.009963 19861 sgd_solver.cpp:112] Iteration 8460, lr = 0.001
I0522 10:32:16.162369 19861 solver.cpp:239] Iteration 8480 (9.29189 iter/s, 2.15241s/20 iters), loss = 0.00534209
I0522 10:32:16.162406 19861 solver.cpp:258]     Train net output #0: loss = 0.00534206 (* 1 = 0.00534206 loss)
I0522 10:32:16.162410 19861 sgd_solver.cpp:112] Iteration 8480, lr = 0.001
I0522 10:32:18.457453 19861 solver.cpp:239] Iteration 8500 (8.71448 iter/s, 2.29503s/20 iters), loss = 0.00620444
I0522 10:32:18.457520 19861 solver.cpp:258]     Train net output #0: loss = 0.0062044 (* 1 = 0.0062044 loss)
I0522 10:32:18.457525 19861 sgd_solver.cpp:112] Iteration 8500, lr = 0.001
I0522 10:32:20.605983 19861 solver.cpp:239] Iteration 8520 (9.30897 iter/s, 2.14846s/20 iters), loss = 0.0279423
I0522 10:32:20.619534 19861 solver.cpp:258]     Train net output #0: loss = 0.0279422 (* 1 = 0.0279422 loss)
I0522 10:32:20.619541 19861 sgd_solver.cpp:112] Iteration 8520, lr = 0.001
I0522 10:32:22.745810 19861 solver.cpp:239] Iteration 8540 (9.4061 iter/s, 2.12628s/20 iters), loss = 0.0239926
I0522 10:32:22.754890 19861 solver.cpp:258]     Train net output #0: loss = 0.0239925 (* 1 = 0.0239925 loss)
I0522 10:32:22.754897 19861 sgd_solver.cpp:112] Iteration 8540, lr = 0.001
I0522 10:32:24.875703 19861 solver.cpp:239] Iteration 8560 (9.43054 iter/s, 2.12077s/20 iters), loss = 0.00539033
I0522 10:32:24.875849 19861 solver.cpp:258]     Train net output #0: loss = 0.0053903 (* 1 = 0.0053903 loss)
I0522 10:32:24.875865 19861 sgd_solver.cpp:112] Iteration 8560, lr = 0.001
I0522 10:32:26.766027 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:32:27.298275 19861 solver.cpp:239] Iteration 8580 (8.25631 iter/s, 2.42239s/20 iters), loss = 0.00312628
I0522 10:32:27.298420 19861 solver.cpp:258]     Train net output #0: loss = 0.00312624 (* 1 = 0.00312624 loss)
I0522 10:32:27.298568 19861 sgd_solver.cpp:112] Iteration 8580, lr = 0.001
I0522 10:32:29.426340 19861 solver.cpp:239] Iteration 8600 (9.39894 iter/s, 2.1279s/20 iters), loss = 0.00452175
I0522 10:32:29.438520 19861 solver.cpp:258]     Train net output #0: loss = 0.00452172 (* 1 = 0.00452172 loss)
I0522 10:32:29.438537 19861 sgd_solver.cpp:112] Iteration 8600, lr = 0.001
I0522 10:32:31.571952 19861 solver.cpp:239] Iteration 8620 (9.3746 iter/s, 2.13342s/20 iters), loss = 0.0031252
I0522 10:32:31.572032 19861 solver.cpp:258]     Train net output #0: loss = 0.00312517 (* 1 = 0.00312517 loss)
I0522 10:32:31.572038 19861 sgd_solver.cpp:112] Iteration 8620, lr = 0.001
I0522 10:32:33.994854 19861 solver.cpp:239] Iteration 8640 (8.2549 iter/s, 2.4228s/20 iters), loss = 0.0035243
I0522 10:32:33.994946 19861 solver.cpp:258]     Train net output #0: loss = 0.00352426 (* 1 = 0.00352426 loss)
I0522 10:32:33.994951 19861 sgd_solver.cpp:112] Iteration 8640, lr = 0.001
I0522 10:32:36.187000 19861 solver.cpp:239] Iteration 8660 (9.12386 iter/s, 2.19205s/20 iters), loss = 0.00912678
I0522 10:32:36.187038 19861 solver.cpp:258]     Train net output #0: loss = 0.00912674 (* 1 = 0.00912674 loss)
I0522 10:32:36.187043 19861 sgd_solver.cpp:112] Iteration 8660, lr = 0.001
I0522 10:32:38.364317 19861 solver.cpp:239] Iteration 8680 (9.18583 iter/s, 2.17727s/20 iters), loss = 0.0133599
I0522 10:32:38.364377 19861 solver.cpp:258]     Train net output #0: loss = 0.0133598 (* 1 = 0.0133598 loss)
I0522 10:32:38.364382 19861 sgd_solver.cpp:112] Iteration 8680, lr = 0.001
I0522 10:32:40.746233 19861 solver.cpp:239] Iteration 8700 (8.39685 iter/s, 2.38184s/20 iters), loss = 0.00584988
I0522 10:32:40.746292 19861 solver.cpp:258]     Train net output #0: loss = 0.00584983 (* 1 = 0.00584983 loss)
I0522 10:32:40.746296 19861 sgd_solver.cpp:112] Iteration 8700, lr = 0.001
I0522 10:32:42.925426 19861 solver.cpp:239] Iteration 8720 (9.17807 iter/s, 2.17911s/20 iters), loss = 0.00725909
I0522 10:32:42.925526 19861 solver.cpp:258]     Train net output #0: loss = 0.00725905 (* 1 = 0.00725905 loss)
I0522 10:32:42.925531 19861 sgd_solver.cpp:112] Iteration 8720, lr = 0.001
I0522 10:32:43.820500 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:32:45.106844 19861 solver.cpp:239] Iteration 8740 (9.16885 iter/s, 2.1813s/20 iters), loss = 0.0248654
I0522 10:32:45.106940 19861 solver.cpp:258]     Train net output #0: loss = 0.0248654 (* 1 = 0.0248654 loss)
I0522 10:32:45.106951 19861 sgd_solver.cpp:112] Iteration 8740, lr = 0.001
I0522 10:32:47.527917 19861 solver.cpp:239] Iteration 8760 (8.26129 iter/s, 2.42093s/20 iters), loss = 0.002026
I0522 10:32:47.528060 19861 solver.cpp:258]     Train net output #0: loss = 0.00202596 (* 1 = 0.00202596 loss)
I0522 10:32:47.528075 19861 sgd_solver.cpp:112] Iteration 8760, lr = 0.001
I0522 10:32:49.620353 19861 solver.cpp:239] Iteration 8780 (9.55905 iter/s, 2.09226s/20 iters), loss = 0.00251488
I0522 10:32:49.630429 19861 solver.cpp:258]     Train net output #0: loss = 0.00251484 (* 1 = 0.00251484 loss)
I0522 10:32:49.630442 19861 sgd_solver.cpp:112] Iteration 8780, lr = 0.001
I0522 10:32:51.748446 19861 solver.cpp:239] Iteration 8800 (9.44279 iter/s, 2.11802s/20 iters), loss = 0.00781103
I0522 10:32:51.758081 19861 solver.cpp:258]     Train net output #0: loss = 0.00781099 (* 1 = 0.00781099 loss)
I0522 10:32:51.758087 19861 sgd_solver.cpp:112] Iteration 8800, lr = 0.001
I0522 10:32:53.928936 19861 solver.cpp:239] Iteration 8820 (9.21303 iter/s, 2.17084s/20 iters), loss = 0.00471498
I0522 10:32:53.929028 19861 solver.cpp:258]     Train net output #0: loss = 0.00471493 (* 1 = 0.00471493 loss)
I0522 10:32:53.929033 19861 sgd_solver.cpp:112] Iteration 8820, lr = 0.001
I0522 10:32:56.393942 19861 solver.cpp:239] Iteration 8840 (8.1139 iter/s, 2.4649s/20 iters), loss = 0.000568329
I0522 10:32:56.407207 19861 solver.cpp:258]     Train net output #0: loss = 0.000568285 (* 1 = 0.000568285 loss)
I0522 10:32:56.407215 19861 sgd_solver.cpp:112] Iteration 8840, lr = 0.001
I0522 10:32:58.529860 19861 solver.cpp:239] Iteration 8860 (9.42228 iter/s, 2.12263s/20 iters), loss = 0.00192413
I0522 10:32:58.529951 19861 solver.cpp:258]     Train net output #0: loss = 0.00192408 (* 1 = 0.00192408 loss)
I0522 10:32:58.529963 19861 sgd_solver.cpp:112] Iteration 8860, lr = 0.001
I0522 10:33:00.670002 19861 solver.cpp:239] Iteration 8880 (9.34562 iter/s, 2.14004s/20 iters), loss = 0.00291215
I0522 10:33:00.680512 19861 solver.cpp:258]     Train net output #0: loss = 0.00291211 (* 1 = 0.00291211 loss)
I0522 10:33:00.680521 19861 sgd_solver.cpp:112] Iteration 8880, lr = 0.001
I0522 10:33:00.842022 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:33:03.041708 19861 solver.cpp:239] Iteration 8900 (8.47036 iter/s, 2.36118s/20 iters), loss = 0.00115643
I0522 10:33:03.041810 19861 solver.cpp:258]     Train net output #0: loss = 0.00115639 (* 1 = 0.00115639 loss)
I0522 10:33:03.041815 19861 sgd_solver.cpp:112] Iteration 8900, lr = 0.001
I0522 10:33:05.232733 19861 solver.cpp:239] Iteration 8920 (9.12863 iter/s, 2.19091s/20 iters), loss = 0.00277961
I0522 10:33:05.232790 19861 solver.cpp:258]     Train net output #0: loss = 0.00277956 (* 1 = 0.00277956 loss)
I0522 10:33:05.232795 19861 sgd_solver.cpp:112] Iteration 8920, lr = 0.001
I0522 10:33:07.449610 19861 solver.cpp:239] Iteration 8940 (9.02198 iter/s, 2.21681s/20 iters), loss = 0.00493808
I0522 10:33:07.449668 19861 solver.cpp:258]     Train net output #0: loss = 0.00493803 (* 1 = 0.00493803 loss)
I0522 10:33:07.449672 19861 sgd_solver.cpp:112] Iteration 8940, lr = 0.001
I0522 10:33:09.877568 19861 solver.cpp:239] Iteration 8960 (8.23759 iter/s, 2.42789s/20 iters), loss = 0.00919688
I0522 10:33:09.877619 19861 solver.cpp:258]     Train net output #0: loss = 0.00919684 (* 1 = 0.00919684 loss)
I0522 10:33:09.877622 19861 sgd_solver.cpp:112] Iteration 8960, lr = 0.001
I0522 10:33:12.114131 19861 solver.cpp:239] Iteration 8980 (8.9425 iter/s, 2.23651s/20 iters), loss = 0.00321058
I0522 10:33:12.114162 19861 solver.cpp:258]     Train net output #0: loss = 0.00321054 (* 1 = 0.00321054 loss)
I0522 10:33:12.114166 19861 sgd_solver.cpp:112] Iteration 8980, lr = 0.001
I0522 10:33:14.138407 19861 solver.cpp:347] Iteration 9000, Testing net (#0)
I0522 10:33:15.758630 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:33:19.386698 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:33:20.005990 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:33:24.133013 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:33:28.298370 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:33:30.646597 19861 solver.cpp:414]     Test net output #0: accuracy = 0.869602
I0522 10:33:30.646657 19861 solver.cpp:414]     Test net output #1: loss = 0.766344 (* 1 = 0.766344 loss)
I0522 10:33:30.745389 19861 solver.cpp:239] Iteration 9000 (1.07346 iter/s, 18.6313s/20 iters), loss = 0.00428252
I0522 10:33:30.748229 19861 solver.cpp:258]     Train net output #0: loss = 0.00428248 (* 1 = 0.00428248 loss)
I0522 10:33:30.748240 19861 sgd_solver.cpp:112] Iteration 9000, lr = 0.001
I0522 10:33:33.142748 19861 solver.cpp:239] Iteration 9020 (8.35246 iter/s, 2.3945s/20 iters), loss = 0.00272328
I0522 10:33:33.142830 19861 solver.cpp:258]     Train net output #0: loss = 0.00272323 (* 1 = 0.00272323 loss)
I0522 10:33:33.142835 19861 sgd_solver.cpp:112] Iteration 9020, lr = 0.001
I0522 10:33:34.730715 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:33:35.310374 19861 solver.cpp:239] Iteration 9040 (9.22708 iter/s, 2.16753s/20 iters), loss = 0.00299594
I0522 10:33:35.310431 19861 solver.cpp:258]     Train net output #0: loss = 0.00299589 (* 1 = 0.00299589 loss)
I0522 10:33:35.310434 19861 sgd_solver.cpp:112] Iteration 9040, lr = 0.001
I0522 10:33:37.524590 19861 solver.cpp:239] Iteration 9060 (9.03276 iter/s, 2.21416s/20 iters), loss = 0.00650175
I0522 10:33:37.524616 19861 solver.cpp:258]     Train net output #0: loss = 0.00650171 (* 1 = 0.00650171 loss)
I0522 10:33:37.524619 19861 sgd_solver.cpp:112] Iteration 9060, lr = 0.001
I0522 10:33:39.940825 19861 solver.cpp:239] Iteration 9080 (8.27747 iter/s, 2.4162s/20 iters), loss = 0.00574293
I0522 10:33:39.940882 19861 solver.cpp:258]     Train net output #0: loss = 0.00574289 (* 1 = 0.00574289 loss)
I0522 10:33:39.940887 19861 sgd_solver.cpp:112] Iteration 9080, lr = 0.001
I0522 10:33:42.082805 19861 solver.cpp:239] Iteration 9100 (9.33741 iter/s, 2.14192s/20 iters), loss = 0.00450331
I0522 10:33:42.082839 19861 solver.cpp:258]     Train net output #0: loss = 0.00450327 (* 1 = 0.00450327 loss)
I0522 10:33:42.082844 19861 sgd_solver.cpp:112] Iteration 9100, lr = 0.001
I0522 10:33:44.264160 19861 solver.cpp:239] Iteration 9120 (9.16874 iter/s, 2.18132s/20 iters), loss = 0.00662288
I0522 10:33:44.273584 19861 solver.cpp:258]     Train net output #0: loss = 0.00662283 (* 1 = 0.00662283 loss)
I0522 10:33:44.273591 19861 sgd_solver.cpp:112] Iteration 9120, lr = 0.001
I0522 10:33:46.427969 19861 solver.cpp:239] Iteration 9140 (9.28344 iter/s, 2.15437s/20 iters), loss = 0.00840731
I0522 10:33:46.428030 19861 solver.cpp:258]     Train net output #0: loss = 0.00840727 (* 1 = 0.00840727 loss)
I0522 10:33:46.428036 19861 sgd_solver.cpp:112] Iteration 9140, lr = 0.001
I0522 10:33:48.906684 19861 solver.cpp:239] Iteration 9160 (8.06897 iter/s, 2.47863s/20 iters), loss = 0.00489674
I0522 10:33:48.921088 19861 solver.cpp:258]     Train net output #0: loss = 0.0048967 (* 1 = 0.0048967 loss)
I0522 10:33:48.921106 19861 sgd_solver.cpp:112] Iteration 9160, lr = 0.001
I0522 10:33:51.025102 19861 solver.cpp:239] Iteration 9180 (9.50565 iter/s, 2.10401s/20 iters), loss = 0.00361837
I0522 10:33:51.025167 19861 solver.cpp:258]     Train net output #0: loss = 0.00361833 (* 1 = 0.00361833 loss)
I0522 10:33:51.025172 19861 sgd_solver.cpp:112] Iteration 9180, lr = 0.001
I0522 10:33:51.899122 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:33:53.268537 19861 solver.cpp:239] Iteration 9200 (8.91518 iter/s, 2.24336s/20 iters), loss = 0.013775
I0522 10:33:53.279536 19861 solver.cpp:258]     Train net output #0: loss = 0.013775 (* 1 = 0.013775 loss)
I0522 10:33:53.279544 19861 sgd_solver.cpp:112] Iteration 9200, lr = 0.001
I0522 10:33:55.649964 19861 solver.cpp:239] Iteration 9220 (8.43731 iter/s, 2.37042s/20 iters), loss = 0.00329502
I0522 10:33:55.650023 19861 solver.cpp:258]     Train net output #0: loss = 0.00329498 (* 1 = 0.00329498 loss)
I0522 10:33:55.650027 19861 sgd_solver.cpp:112] Iteration 9220, lr = 0.001
I0522 10:33:57.772881 19861 solver.cpp:239] Iteration 9240 (9.4213 iter/s, 2.12285s/20 iters), loss = 0.00553939
I0522 10:33:57.772925 19861 solver.cpp:258]     Train net output #0: loss = 0.00553934 (* 1 = 0.00553934 loss)
I0522 10:33:57.772929 19861 sgd_solver.cpp:112] Iteration 9240, lr = 0.001
I0522 10:33:59.928292 19861 solver.cpp:239] Iteration 9260 (9.27919 iter/s, 2.15536s/20 iters), loss = 0.00344568
I0522 10:33:59.928341 19861 solver.cpp:258]     Train net output #0: loss = 0.00344563 (* 1 = 0.00344563 loss)
I0522 10:33:59.928416 19861 sgd_solver.cpp:112] Iteration 9260, lr = 0.001
I0522 10:34:02.198679 19861 solver.cpp:239] Iteration 9280 (8.80931 iter/s, 2.27032s/20 iters), loss = 0.00099822
I0522 10:34:02.211304 19861 solver.cpp:258]     Train net output #0: loss = 0.000998174 (* 1 = 0.000998174 loss)
I0522 10:34:02.211313 19861 sgd_solver.cpp:112] Iteration 9280, lr = 0.001
I0522 10:34:04.484933 19861 solver.cpp:239] Iteration 9300 (8.7965 iter/s, 2.27363s/20 iters), loss = 0.00171692
I0522 10:34:04.497893 19861 solver.cpp:258]     Train net output #0: loss = 0.00171688 (* 1 = 0.00171688 loss)
I0522 10:34:04.497901 19861 sgd_solver.cpp:112] Iteration 9300, lr = 0.001
I0522 10:34:06.600426 19861 solver.cpp:239] Iteration 9320 (9.51236 iter/s, 2.10253s/20 iters), loss = 0.00985654
I0522 10:34:06.600461 19861 solver.cpp:258]     Train net output #0: loss = 0.00985649 (* 1 = 0.00985649 loss)
I0522 10:34:06.600466 19861 sgd_solver.cpp:112] Iteration 9320, lr = 0.001
I0522 10:34:07.709993 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:34:08.732928 19861 solver.cpp:239] Iteration 9340 (9.37884 iter/s, 2.13246s/20 iters), loss = 0.00322986
I0522 10:34:08.732955 19861 solver.cpp:258]     Train net output #0: loss = 0.00322982 (* 1 = 0.00322982 loss)
I0522 10:34:08.732961 19861 sgd_solver.cpp:112] Iteration 9340, lr = 0.001
I0522 10:34:08.805032 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:34:11.103355 19861 solver.cpp:239] Iteration 9360 (8.43748 iter/s, 2.37037s/20 iters), loss = 0.00771048
I0522 10:34:11.103438 19861 solver.cpp:258]     Train net output #0: loss = 0.00771044 (* 1 = 0.00771044 loss)
I0522 10:34:11.103443 19861 sgd_solver.cpp:112] Iteration 9360, lr = 0.001
I0522 10:34:13.258848 19861 solver.cpp:239] Iteration 9380 (9.27898 iter/s, 2.15541s/20 iters), loss = 0.00347694
I0522 10:34:13.258879 19861 solver.cpp:258]     Train net output #0: loss = 0.0034769 (* 1 = 0.0034769 loss)
I0522 10:34:13.258882 19861 sgd_solver.cpp:112] Iteration 9380, lr = 0.001
I0522 10:34:15.438256 19861 solver.cpp:239] Iteration 9400 (9.17699 iter/s, 2.17936s/20 iters), loss = 0.00505135
I0522 10:34:15.438304 19861 solver.cpp:258]     Train net output #0: loss = 0.0050513 (* 1 = 0.0050513 loss)
I0522 10:34:15.438308 19861 sgd_solver.cpp:112] Iteration 9400, lr = 0.001
I0522 10:34:17.852484 19861 solver.cpp:239] Iteration 9420 (8.2844 iter/s, 2.41418s/20 iters), loss = 0.00213909
I0522 10:34:17.852525 19861 solver.cpp:258]     Train net output #0: loss = 0.00213905 (* 1 = 0.00213905 loss)
I0522 10:34:17.852530 19861 sgd_solver.cpp:112] Iteration 9420, lr = 0.001
I0522 10:34:20.066720 19861 solver.cpp:239] Iteration 9440 (9.03266 iter/s, 2.21419s/20 iters), loss = 0.00233113
I0522 10:34:20.066778 19861 solver.cpp:258]     Train net output #0: loss = 0.00233108 (* 1 = 0.00233108 loss)
I0522 10:34:20.066782 19861 sgd_solver.cpp:112] Iteration 9440, lr = 0.001
I0522 10:34:22.284085 19861 solver.cpp:239] Iteration 9460 (9.01998 iter/s, 2.2173s/20 iters), loss = 0.00377242
I0522 10:34:22.284145 19861 solver.cpp:258]     Train net output #0: loss = 0.00377237 (* 1 = 0.00377237 loss)
I0522 10:34:22.284148 19861 sgd_solver.cpp:112] Iteration 9460, lr = 0.001
I0522 10:34:24.476790 19861 solver.cpp:239] Iteration 9480 (9.12156 iter/s, 2.19261s/20 iters), loss = 0.00735743
I0522 10:34:24.476886 19861 solver.cpp:258]     Train net output #0: loss = 0.00735738 (* 1 = 0.00735738 loss)
I0522 10:34:24.476893 19861 sgd_solver.cpp:112] Iteration 9480, lr = 0.001
I0522 10:34:26.269366 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:34:26.975814 19861 solver.cpp:239] Iteration 9500 (8.00346 iter/s, 2.49892s/20 iters), loss = 0.00562917
I0522 10:34:26.975899 19861 solver.cpp:258]     Train net output #0: loss = 0.00562912 (* 1 = 0.00562912 loss)
I0522 10:34:26.975906 19861 sgd_solver.cpp:112] Iteration 9500, lr = 0.001
I0522 10:34:29.019357 19861 solver.cpp:239] Iteration 9520 (9.78743 iter/s, 2.04344s/20 iters), loss = 0.0018712
I0522 10:34:29.028964 19861 solver.cpp:258]     Train net output #0: loss = 0.00187116 (* 1 = 0.00187116 loss)
I0522 10:34:29.028972 19861 sgd_solver.cpp:112] Iteration 9520, lr = 0.001
I0522 10:34:31.060933 19861 solver.cpp:239] Iteration 9540 (9.84276 iter/s, 2.03195s/20 iters), loss = 0.00743757
I0522 10:34:31.070353 19861 solver.cpp:258]     Train net output #0: loss = 0.00743752 (* 1 = 0.00743752 loss)
I0522 10:34:31.070360 19861 sgd_solver.cpp:112] Iteration 9540, lr = 0.001
I0522 10:34:33.132494 19861 solver.cpp:239] Iteration 9560 (9.6987 iter/s, 2.06213s/20 iters), loss = 0.00573578
I0522 10:34:33.142014 19861 solver.cpp:258]     Train net output #0: loss = 0.00573574 (* 1 = 0.00573574 loss)
I0522 10:34:33.142022 19861 sgd_solver.cpp:112] Iteration 9560, lr = 0.001
I0522 10:34:36.078675 19861 solver.cpp:239] Iteration 9580 (6.81045 iter/s, 2.93666s/20 iters), loss = 0.00230339
I0522 10:34:36.088296 19861 solver.cpp:258]     Train net output #0: loss = 0.00230335 (* 1 = 0.00230335 loss)
I0522 10:34:36.088302 19861 sgd_solver.cpp:112] Iteration 9580, lr = 0.001
I0522 10:34:38.823683 19861 solver.cpp:239] Iteration 9600 (7.31168 iter/s, 2.73535s/20 iters), loss = 0.00436657
I0522 10:34:38.833129 19861 solver.cpp:258]     Train net output #0: loss = 0.00436653 (* 1 = 0.00436653 loss)
I0522 10:34:38.833137 19861 sgd_solver.cpp:112] Iteration 9600, lr = 0.001
I0522 10:34:40.871196 19861 solver.cpp:239] Iteration 9620 (9.81328 iter/s, 2.03805s/20 iters), loss = 0.00132411
I0522 10:34:40.880704 19861 solver.cpp:258]     Train net output #0: loss = 0.00132406 (* 1 = 0.00132406 loss)
I0522 10:34:40.880712 19861 sgd_solver.cpp:112] Iteration 9620, lr = 0.001
I0522 10:34:42.929656 19861 solver.cpp:239] Iteration 9640 (9.76114 iter/s, 2.04894s/20 iters), loss = 0.00368253
I0522 10:34:42.939251 19861 solver.cpp:258]     Train net output #0: loss = 0.00368248 (* 1 = 0.00368248 loss)
I0522 10:34:42.939265 19861 sgd_solver.cpp:112] Iteration 9640, lr = 0.001
I0522 10:34:43.668957 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:34:44.980306 19861 solver.cpp:239] Iteration 9660 (9.79889 iter/s, 2.04105s/20 iters), loss = 0.00659988
I0522 10:34:44.989820 19861 solver.cpp:258]     Train net output #0: loss = 0.00659984 (* 1 = 0.00659984 loss)
I0522 10:34:44.989830 19861 sgd_solver.cpp:112] Iteration 9660, lr = 0.001
I0522 10:34:48.564642 19861 solver.cpp:239] Iteration 9680 (5.59469 iter/s, 3.57482s/20 iters), loss = 0.00540324
I0522 10:34:48.579296 19861 solver.cpp:258]     Train net output #0: loss = 0.00540319 (* 1 = 0.00540319 loss)
I0522 10:34:48.579303 19861 sgd_solver.cpp:112] Iteration 9680, lr = 0.001
I0522 10:34:50.649803 19861 solver.cpp:239] Iteration 9700 (9.6595 iter/s, 2.0705s/20 iters), loss = 0.0051001
I0522 10:34:50.659454 19861 solver.cpp:258]     Train net output #0: loss = 0.00510006 (* 1 = 0.00510006 loss)
I0522 10:34:50.659464 19861 sgd_solver.cpp:112] Iteration 9700, lr = 0.001
I0522 10:34:52.707149 19861 solver.cpp:239] Iteration 9720 (9.76716 iter/s, 2.04768s/20 iters), loss = 0.00543333
I0522 10:34:52.716684 19861 solver.cpp:258]     Train net output #0: loss = 0.00543328 (* 1 = 0.00543328 loss)
I0522 10:34:52.716696 19861 sgd_solver.cpp:112] Iteration 9720, lr = 0.001
I0522 10:34:54.759052 19861 solver.cpp:239] Iteration 9740 (9.79258 iter/s, 2.04236s/20 iters), loss = 0.00121709
I0522 10:34:54.768488 19861 solver.cpp:258]     Train net output #0: loss = 0.00121704 (* 1 = 0.00121704 loss)
I0522 10:34:54.768499 19861 sgd_solver.cpp:112] Iteration 9740, lr = 0.001
I0522 10:34:57.853670 19861 solver.cpp:239] Iteration 9760 (6.4826 iter/s, 3.08518s/20 iters), loss = 0.00513223
I0522 10:34:57.862987 19861 solver.cpp:258]     Train net output #0: loss = 0.00513218 (* 1 = 0.00513218 loss)
I0522 10:34:57.862996 19861 sgd_solver.cpp:112] Iteration 9760, lr = 0.001
I0522 10:35:00.544872 19861 solver.cpp:239] Iteration 9780 (7.45761 iter/s, 2.68183s/20 iters), loss = 0.00196043
I0522 10:35:00.544977 19861 solver.cpp:258]     Train net output #0: loss = 0.00196038 (* 1 = 0.00196038 loss)
I0522 10:35:00.544983 19861 sgd_solver.cpp:112] Iteration 9780, lr = 0.001
I0522 10:35:02.608808 19861 solver.cpp:239] Iteration 9800 (9.69077 iter/s, 2.06382s/20 iters), loss = 0.0204017
I0522 10:35:02.618326 19861 solver.cpp:258]     Train net output #0: loss = 0.0204017 (* 1 = 0.0204017 loss)
I0522 10:35:02.618335 19861 sgd_solver.cpp:112] Iteration 9800, lr = 0.001
I0522 10:35:02.636332 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:35:04.651294 19861 solver.cpp:239] Iteration 9820 (9.8379 iter/s, 2.03295s/20 iters), loss = 0.00222606
I0522 10:35:04.660859 19861 solver.cpp:258]     Train net output #0: loss = 0.00222601 (* 1 = 0.00222601 loss)
I0522 10:35:04.660866 19861 sgd_solver.cpp:112] Iteration 9820, lr = 0.001
I0522 10:35:06.693172 19861 solver.cpp:239] Iteration 9840 (9.841 iter/s, 2.03231s/20 iters), loss = 0.00276377
I0522 10:35:06.702847 19861 solver.cpp:258]     Train net output #0: loss = 0.00276372 (* 1 = 0.00276372 loss)
I0522 10:35:06.702855 19861 sgd_solver.cpp:112] Iteration 9840, lr = 0.001
I0522 10:35:10.322335 19861 solver.cpp:239] Iteration 9860 (5.52563 iter/s, 3.61949s/20 iters), loss = 0.00219896
I0522 10:35:10.322378 19861 solver.cpp:258]     Train net output #0: loss = 0.00219891 (* 1 = 0.00219891 loss)
I0522 10:35:10.322382 19861 sgd_solver.cpp:112] Iteration 9860, lr = 0.001
I0522 10:35:12.458627 19861 solver.cpp:239] Iteration 9880 (9.36228 iter/s, 2.13623s/20 iters), loss = 0.0101021
I0522 10:35:12.468220 19861 solver.cpp:258]     Train net output #0: loss = 0.010102 (* 1 = 0.010102 loss)
I0522 10:35:12.468230 19861 sgd_solver.cpp:112] Iteration 9880, lr = 0.001
I0522 10:35:14.519049 19861 solver.cpp:239] Iteration 9900 (9.75224 iter/s, 2.05081s/20 iters), loss = 0.0117248
I0522 10:35:14.528445 19861 solver.cpp:258]     Train net output #0: loss = 0.0117247 (* 1 = 0.0117247 loss)
I0522 10:35:14.528452 19861 sgd_solver.cpp:112] Iteration 9900, lr = 0.001
I0522 10:35:16.573285 19861 solver.cpp:239] Iteration 9920 (9.78079 iter/s, 2.04483s/20 iters), loss = 0.0032667
I0522 10:35:16.573361 19861 solver.cpp:258]     Train net output #0: loss = 0.00326665 (* 1 = 0.00326665 loss)
I0522 10:35:16.573370 19861 sgd_solver.cpp:112] Iteration 9920, lr = 0.001
I0522 10:35:18.670022 19861 solver.cpp:239] Iteration 9940 (9.53977 iter/s, 2.09649s/20 iters), loss = 0.00258749
I0522 10:35:18.670475 19861 solver.cpp:258]     Train net output #0: loss = 0.00258744 (* 1 = 0.00258744 loss)
I0522 10:35:18.670519 19861 sgd_solver.cpp:112] Iteration 9940, lr = 0.001
I0522 10:35:21.563684 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:35:22.231145 19861 solver.cpp:239] Iteration 9960 (5.61683 iter/s, 3.56072s/20 iters), loss = 0.00445631
I0522 10:35:22.240754 19861 solver.cpp:258]     Train net output #0: loss = 0.00445626 (* 1 = 0.00445626 loss)
I0522 10:35:22.240763 19861 sgd_solver.cpp:112] Iteration 9960, lr = 0.001
I0522 10:35:24.283830 19861 solver.cpp:239] Iteration 9980 (9.78919 iter/s, 2.04307s/20 iters), loss = 0.0272203
I0522 10:35:24.293279 19861 solver.cpp:258]     Train net output #0: loss = 0.0272203 (* 1 = 0.0272203 loss)
I0522 10:35:24.293287 19861 sgd_solver.cpp:112] Iteration 9980, lr = 0.001
I0522 10:35:26.174355 19861 solver.cpp:464] Snapshotting to binary proto file ./data/trained_models/caffenet/solver_iter_10000.caffemodel
I0522 10:35:27.168748 19861 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./data/trained_models/caffenet/solver_iter_10000.solverstate
I0522 10:35:27.450284 19861 solver.cpp:347] Iteration 10000, Testing net (#0)
I0522 10:35:29.068670 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:35:34.301856 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:35:36.414245 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:35:37.959249 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:35:42.977133 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:35:44.973628 19861 solver.cpp:414]     Test net output #0: accuracy = 0.867222
I0522 10:35:44.973695 19861 solver.cpp:414]     Test net output #1: loss = 0.77641 (* 1 = 0.77641 loss)
I0522 10:35:45.070905 19861 solver.cpp:239] Iteration 10000 (0.96257 iter/s, 20.7777s/20 iters), loss = 0.00103613
I0522 10:35:45.072751 19861 solver.cpp:258]     Train net output #0: loss = 0.00103608 (* 1 = 0.00103608 loss)
I0522 10:35:45.072759 19861 sgd_solver.cpp:112] Iteration 10000, lr = 0.001
I0522 10:35:47.278753 19861 solver.cpp:239] Iteration 10020 (9.06625 iter/s, 2.20598s/20 iters), loss = 0.00736085
I0522 10:35:47.278848 19861 solver.cpp:258]     Train net output #0: loss = 0.0073608 (* 1 = 0.0073608 loss)
I0522 10:35:47.278852 19861 sgd_solver.cpp:112] Iteration 10020, lr = 0.001
I0522 10:35:49.315531 19861 solver.cpp:239] Iteration 10040 (9.81996 iter/s, 2.03667s/20 iters), loss = 0.00889755
I0522 10:35:49.325093 19861 solver.cpp:258]     Train net output #0: loss = 0.00889751 (* 1 = 0.00889751 loss)
I0522 10:35:49.325100 19861 sgd_solver.cpp:112] Iteration 10040, lr = 0.001
I0522 10:35:51.561882 19861 solver.cpp:239] Iteration 10060 (8.94144 iter/s, 2.23678s/20 iters), loss = 0.0074388
I0522 10:35:51.561951 19861 solver.cpp:258]     Train net output #0: loss = 0.00743875 (* 1 = 0.00743875 loss)
I0522 10:35:51.561962 19861 sgd_solver.cpp:112] Iteration 10060, lr = 0.001
I0522 10:35:55.004426 19861 solver.cpp:239] Iteration 10080 (5.80978 iter/s, 3.44247s/20 iters), loss = 0.00570752
I0522 10:35:55.004477 19861 solver.cpp:258]     Train net output #0: loss = 0.00570747 (* 1 = 0.00570747 loss)
I0522 10:35:55.004482 19861 sgd_solver.cpp:112] Iteration 10080, lr = 0.001
I0522 10:35:57.050230 19861 solver.cpp:239] Iteration 10100 (9.77643 iter/s, 2.04574s/20 iters), loss = 0.00369293
I0522 10:35:57.059823 19861 solver.cpp:258]     Train net output #0: loss = 0.00369288 (* 1 = 0.00369288 loss)
I0522 10:35:57.059831 19861 sgd_solver.cpp:112] Iteration 10100, lr = 0.001
I0522 10:35:57.727720 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:35:59.085988 19861 solver.cpp:239] Iteration 10120 (9.87095 iter/s, 2.02615s/20 iters), loss = 0.00868419
I0522 10:35:59.095502 19861 solver.cpp:258]     Train net output #0: loss = 0.00868414 (* 1 = 0.00868414 loss)
I0522 10:35:59.095512 19861 sgd_solver.cpp:112] Iteration 10120, lr = 0.001
I0522 10:36:01.129487 19861 solver.cpp:239] Iteration 10140 (9.833 iter/s, 2.03397s/20 iters), loss = 0.0250187
I0522 10:36:01.139077 19861 solver.cpp:258]     Train net output #0: loss = 0.0250186 (* 1 = 0.0250186 loss)
I0522 10:36:01.139086 19861 sgd_solver.cpp:112] Iteration 10140, lr = 0.001
I0522 10:36:04.715454 19861 solver.cpp:239] Iteration 10160 (5.59225 iter/s, 3.57638s/20 iters), loss = 0.00723448
I0522 10:36:04.715540 19861 solver.cpp:258]     Train net output #0: loss = 0.00723443 (* 1 = 0.00723443 loss)
I0522 10:36:04.715544 19861 sgd_solver.cpp:112] Iteration 10160, lr = 0.001
I0522 10:36:06.760236 19861 solver.cpp:239] Iteration 10180 (9.78158 iter/s, 2.04466s/20 iters), loss = 0.0241611
I0522 10:36:06.769716 19861 solver.cpp:258]     Train net output #0: loss = 0.0241611 (* 1 = 0.0241611 loss)
I0522 10:36:06.769724 19861 sgd_solver.cpp:112] Iteration 10180, lr = 0.001
I0522 10:36:08.798887 19861 solver.cpp:239] Iteration 10200 (9.85627 iter/s, 2.02917s/20 iters), loss = 0.0147077
I0522 10:36:08.808403 19861 solver.cpp:258]     Train net output #0: loss = 0.0147076 (* 1 = 0.0147076 loss)
I0522 10:36:08.808413 19861 sgd_solver.cpp:112] Iteration 10200, lr = 0.001
I0522 10:36:10.837445 19861 solver.cpp:239] Iteration 10220 (9.85693 iter/s, 2.02903s/20 iters), loss = 0.00302787
I0522 10:36:10.846889 19861 solver.cpp:258]     Train net output #0: loss = 0.00302782 (* 1 = 0.00302782 loss)
I0522 10:36:10.846899 19861 sgd_solver.cpp:112] Iteration 10220, lr = 0.001
I0522 10:36:12.883430 19861 solver.cpp:239] Iteration 10240 (9.82066 iter/s, 2.03652s/20 iters), loss = 0.00164876
I0522 10:36:12.894651 19861 solver.cpp:258]     Train net output #0: loss = 0.00164871 (* 1 = 0.00164871 loss)
I0522 10:36:12.894662 19861 sgd_solver.cpp:112] Iteration 10240, lr = 0.001
I0522 10:36:16.435422 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:36:16.454825 19861 solver.cpp:239] Iteration 10260 (5.61772 iter/s, 3.56016s/20 iters), loss = 0.0144937
I0522 10:36:16.454908 19861 solver.cpp:258]     Train net output #0: loss = 0.0144937 (* 1 = 0.0144937 loss)
I0522 10:36:16.454915 19861 sgd_solver.cpp:112] Iteration 10260, lr = 0.001
I0522 10:36:18.510442 19861 solver.cpp:239] Iteration 10280 (9.73002 iter/s, 2.0555s/20 iters), loss = 0.00833101
I0522 10:36:18.519855 19861 solver.cpp:258]     Train net output #0: loss = 0.00833096 (* 1 = 0.00833096 loss)
I0522 10:36:18.519865 19861 sgd_solver.cpp:112] Iteration 10280, lr = 0.001
I0522 10:36:20.561559 19861 solver.cpp:239] Iteration 10300 (9.79582 iter/s, 2.04169s/20 iters), loss = 0.00221095
I0522 10:36:20.570945 19861 solver.cpp:258]     Train net output #0: loss = 0.0022109 (* 1 = 0.0022109 loss)
I0522 10:36:20.570953 19861 sgd_solver.cpp:112] Iteration 10300, lr = 0.001
I0522 10:36:22.611840 19861 solver.cpp:239] Iteration 10320 (9.79973 iter/s, 2.04087s/20 iters), loss = 0.00263211
I0522 10:36:22.621244 19861 solver.cpp:258]     Train net output #0: loss = 0.00263207 (* 1 = 0.00263207 loss)
I0522 10:36:22.621260 19861 sgd_solver.cpp:112] Iteration 10320, lr = 0.001
I0522 10:36:24.667558 19861 solver.cpp:239] Iteration 10340 (9.7747 iter/s, 2.0461s/20 iters), loss = 0.0112573
I0522 10:36:24.668012 19861 solver.cpp:258]     Train net output #0: loss = 0.0112572 (* 1 = 0.0112572 loss)
I0522 10:36:24.668053 19861 sgd_solver.cpp:112] Iteration 10340, lr = 0.001
I0522 10:36:28.292691 19861 solver.cpp:239] Iteration 10360 (5.51758 iter/s, 3.62478s/20 iters), loss = 0.0142844
I0522 10:36:28.292735 19861 solver.cpp:258]     Train net output #0: loss = 0.0142844 (* 1 = 0.0142844 loss)
I0522 10:36:28.292739 19861 sgd_solver.cpp:112] Iteration 10360, lr = 0.001
I0522 10:36:30.434733 19861 solver.cpp:239] Iteration 10380 (9.33712 iter/s, 2.14199s/20 iters), loss = 0.0140773
I0522 10:36:30.444270 19861 solver.cpp:258]     Train net output #0: loss = 0.0140772 (* 1 = 0.0140772 loss)
I0522 10:36:30.444280 19861 sgd_solver.cpp:112] Iteration 10380, lr = 0.001
I0522 10:36:32.484688 19861 solver.cpp:239] Iteration 10400 (9.80199 iter/s, 2.0404s/20 iters), loss = 0.00325632
I0522 10:36:32.494240 19861 solver.cpp:258]     Train net output #0: loss = 0.00325627 (* 1 = 0.00325627 loss)
I0522 10:36:32.494247 19861 sgd_solver.cpp:112] Iteration 10400, lr = 0.001
I0522 10:36:33.783721 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:36:34.534303 19861 solver.cpp:239] Iteration 10420 (9.80369 iter/s, 2.04005s/20 iters), loss = 0.00564799
I0522 10:36:34.543659 19861 solver.cpp:258]     Train net output #0: loss = 0.00564794 (* 1 = 0.00564794 loss)
I0522 10:36:34.543668 19861 sgd_solver.cpp:112] Iteration 10420, lr = 0.001
I0522 10:36:36.979111 19861 solver.cpp:239] Iteration 10440 (8.2121 iter/s, 2.43543s/20 iters), loss = 0.00109451
I0522 10:36:36.993317 19861 solver.cpp:258]     Train net output #0: loss = 0.00109446 (* 1 = 0.00109446 loss)
I0522 10:36:36.993335 19861 sgd_solver.cpp:112] Iteration 10440, lr = 0.001
I0522 10:36:40.140470 19861 solver.cpp:239] Iteration 10460 (6.35497 iter/s, 3.14715s/20 iters), loss = 0.0114854
I0522 10:36:40.150179 19861 solver.cpp:258]     Train net output #0: loss = 0.0114853 (* 1 = 0.0114853 loss)
I0522 10:36:40.150187 19861 sgd_solver.cpp:112] Iteration 10460, lr = 0.001
I0522 10:36:42.195677 19861 solver.cpp:239] Iteration 10480 (9.77766 iter/s, 2.04548s/20 iters), loss = 0.0190834
I0522 10:36:42.205055 19861 solver.cpp:258]     Train net output #0: loss = 0.0190834 (* 1 = 0.0190834 loss)
I0522 10:36:42.205063 19861 sgd_solver.cpp:112] Iteration 10480, lr = 0.001
I0522 10:36:44.259224 19861 solver.cpp:239] Iteration 10500 (9.73644 iter/s, 2.05414s/20 iters), loss = 0.00292682
I0522 10:36:44.268615 19861 solver.cpp:258]     Train net output #0: loss = 0.00292677 (* 1 = 0.00292677 loss)
I0522 10:36:44.268622 19861 sgd_solver.cpp:112] Iteration 10500, lr = 0.001
I0522 10:36:46.309223 19861 solver.cpp:239] Iteration 10520 (9.80108 iter/s, 2.04059s/20 iters), loss = 0.015916
I0522 10:36:46.318686 19861 solver.cpp:258]     Train net output #0: loss = 0.015916 (* 1 = 0.015916 loss)
I0522 10:36:46.318693 19861 sgd_solver.cpp:112] Iteration 10520, lr = 0.001
I0522 10:36:49.537493 19861 solver.cpp:239] Iteration 10540 (6.21348 iter/s, 3.21881s/20 iters), loss = 0.00443421
I0522 10:36:49.547001 19861 solver.cpp:258]     Train net output #0: loss = 0.00443416 (* 1 = 0.00443416 loss)
I0522 10:36:49.547008 19861 sgd_solver.cpp:112] Iteration 10540, lr = 0.001
I0522 10:36:52.074668 19861 solver.cpp:239] Iteration 10560 (7.91248 iter/s, 2.52765s/20 iters), loss = 0.00104789
I0522 10:36:52.074748 19861 solver.cpp:258]     Train net output #0: loss = 0.00104783 (* 1 = 0.00104783 loss)
I0522 10:36:52.074759 19861 sgd_solver.cpp:112] Iteration 10560, lr = 0.001
I0522 10:36:52.680007 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:36:54.158030 19861 solver.cpp:239] Iteration 10580 (9.60031 iter/s, 2.08327s/20 iters), loss = 0.00360829
I0522 10:36:54.167487 19861 solver.cpp:258]     Train net output #0: loss = 0.00360824 (* 1 = 0.00360824 loss)
I0522 10:36:54.167495 19861 sgd_solver.cpp:112] Iteration 10580, lr = 0.001
I0522 10:36:56.570844 19861 solver.cpp:239] Iteration 10600 (8.32179 iter/s, 2.40333s/20 iters), loss = 0.0135982
I0522 10:36:56.580771 19861 solver.cpp:258]     Train net output #0: loss = 0.0135982 (* 1 = 0.0135982 loss)
I0522 10:36:56.580787 19861 sgd_solver.cpp:112] Iteration 10600, lr = 0.001
I0522 10:36:59.308398 19861 solver.cpp:239] Iteration 10620 (7.33234 iter/s, 2.72764s/20 iters), loss = 0.0119106
I0522 10:36:59.308416 19861 solver.cpp:258]     Train net output #0: loss = 0.0119106 (* 1 = 0.0119106 loss)
I0522 10:36:59.308419 19861 sgd_solver.cpp:112] Iteration 10620, lr = 0.001
I0522 10:37:01.509865 19861 solver.cpp:239] Iteration 10640 (9.08493 iter/s, 2.20145s/20 iters), loss = 0.00352391
I0522 10:37:01.509888 19861 solver.cpp:258]     Train net output #0: loss = 0.00352385 (* 1 = 0.00352385 loss)
I0522 10:37:01.509891 19861 sgd_solver.cpp:112] Iteration 10640, lr = 0.001
I0522 10:37:03.711522 19861 solver.cpp:239] Iteration 10660 (9.08418 iter/s, 2.20163s/20 iters), loss = 0.00177682
I0522 10:37:03.711541 19861 solver.cpp:258]     Train net output #0: loss = 0.00177677 (* 1 = 0.00177677 loss)
I0522 10:37:03.711545 19861 sgd_solver.cpp:112] Iteration 10660, lr = 0.001
I0522 10:37:05.818122 19861 solver.cpp:239] Iteration 10680 (9.4941 iter/s, 2.10657s/20 iters), loss = 0.00441651
I0522 10:37:05.827208 19861 solver.cpp:258]     Train net output #0: loss = 0.00441645 (* 1 = 0.00441645 loss)
I0522 10:37:05.827215 19861 sgd_solver.cpp:112] Iteration 10680, lr = 0.001
I0522 10:37:07.873395 19861 solver.cpp:239] Iteration 10700 (9.77429 iter/s, 2.04618s/20 iters), loss = 0.00360263
I0522 10:37:07.883381 19861 solver.cpp:258]     Train net output #0: loss = 0.00360257 (* 1 = 0.00360257 loss)
I0522 10:37:07.883389 19861 sgd_solver.cpp:112] Iteration 10700, lr = 0.001
I0522 10:37:09.557590 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:37:09.857995 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:37:09.920995 19861 solver.cpp:239] Iteration 10720 (9.81535 iter/s, 2.03762s/20 iters), loss = 0.00414421
I0522 10:37:09.930244 19861 solver.cpp:258]     Train net output #0: loss = 0.00414415 (* 1 = 0.00414415 loss)
I0522 10:37:09.930251 19861 sgd_solver.cpp:112] Iteration 10720, lr = 0.001
I0522 10:37:11.970197 19861 solver.cpp:239] Iteration 10740 (9.80415 iter/s, 2.03995s/20 iters), loss = 0.00406912
I0522 10:37:11.979424 19861 solver.cpp:258]     Train net output #0: loss = 0.00406906 (* 1 = 0.00406906 loss)
I0522 10:37:11.979430 19861 sgd_solver.cpp:112] Iteration 10740, lr = 0.001
I0522 10:37:14.020959 19861 solver.cpp:239] Iteration 10760 (9.79657 iter/s, 2.04153s/20 iters), loss = 0.00168995
I0522 10:37:14.030174 19861 solver.cpp:258]     Train net output #0: loss = 0.00168989 (* 1 = 0.00168989 loss)
I0522 10:37:14.030181 19861 sgd_solver.cpp:112] Iteration 10760, lr = 0.001
I0522 10:37:16.068794 19861 solver.cpp:239] Iteration 10780 (9.81057 iter/s, 2.03862s/20 iters), loss = 0.00340171
I0522 10:37:16.077932 19861 solver.cpp:258]     Train net output #0: loss = 0.00340165 (* 1 = 0.00340165 loss)
I0522 10:37:16.077940 19861 sgd_solver.cpp:112] Iteration 10780, lr = 0.001
I0522 10:37:18.119123 19861 solver.cpp:239] Iteration 10800 (9.79828 iter/s, 2.04117s/20 iters), loss = 0.00185815
I0522 10:37:18.119201 19861 solver.cpp:258]     Train net output #0: loss = 0.00185809 (* 1 = 0.00185809 loss)
I0522 10:37:18.119205 19861 sgd_solver.cpp:112] Iteration 10800, lr = 0.001
I0522 10:37:20.173002 19861 solver.cpp:239] Iteration 10820 (9.73808 iter/s, 2.05379s/20 iters), loss = 0.0046748
I0522 10:37:20.182343 19861 solver.cpp:258]     Train net output #0: loss = 0.00467474 (* 1 = 0.00467474 loss)
I0522 10:37:20.182350 19861 sgd_solver.cpp:112] Iteration 10820, lr = 0.001
I0522 10:37:22.242911 19861 solver.cpp:239] Iteration 10840 (9.70609 iter/s, 2.06056s/20 iters), loss = 0.00471746
I0522 10:37:22.252302 19861 solver.cpp:258]     Train net output #0: loss = 0.0047174 (* 1 = 0.0047174 loss)
I0522 10:37:22.252313 19861 sgd_solver.cpp:112] Iteration 10840, lr = 0.001
I0522 10:37:24.302100 19861 solver.cpp:239] Iteration 10860 (9.75727 iter/s, 2.04975s/20 iters), loss = 0.000613379
I0522 10:37:24.311682 19861 solver.cpp:258]     Train net output #0: loss = 0.00061332 (* 1 = 0.00061332 loss)
I0522 10:37:24.311695 19861 sgd_solver.cpp:112] Iteration 10860, lr = 0.001
I0522 10:37:25.582881 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:37:26.353410 19861 solver.cpp:239] Iteration 10880 (9.79566 iter/s, 2.04172s/20 iters), loss = 0.00268347
I0522 10:37:26.362829 19861 solver.cpp:258]     Train net output #0: loss = 0.00268341 (* 1 = 0.00268341 loss)
I0522 10:37:26.362835 19861 sgd_solver.cpp:112] Iteration 10880, lr = 0.001
I0522 10:37:28.403609 19861 solver.cpp:239] Iteration 10900 (9.80018 iter/s, 2.04078s/20 iters), loss = 0.00354497
I0522 10:37:28.412688 19861 solver.cpp:258]     Train net output #0: loss = 0.00354491 (* 1 = 0.00354491 loss)
I0522 10:37:28.412695 19861 sgd_solver.cpp:112] Iteration 10900, lr = 0.001
I0522 10:37:30.452993 19861 solver.cpp:239] Iteration 10920 (9.80249 iter/s, 2.0403s/20 iters), loss = 0.00973903
I0522 10:37:30.462510 19861 solver.cpp:258]     Train net output #0: loss = 0.00973897 (* 1 = 0.00973897 loss)
I0522 10:37:30.462518 19861 sgd_solver.cpp:112] Iteration 10920, lr = 0.001
I0522 10:37:32.885941 19861 solver.cpp:239] Iteration 10940 (8.2528 iter/s, 2.42342s/20 iters), loss = 0.0101404
I0522 10:37:32.895557 19861 solver.cpp:258]     Train net output #0: loss = 0.0101404 (* 1 = 0.0101404 loss)
I0522 10:37:32.895565 19861 sgd_solver.cpp:112] Iteration 10940, lr = 0.001
I0522 10:37:34.962556 19861 solver.cpp:239] Iteration 10960 (9.67582 iter/s, 2.06701s/20 iters), loss = 0.00142655
I0522 10:37:34.973114 19861 solver.cpp:258]     Train net output #0: loss = 0.00142649 (* 1 = 0.00142649 loss)
I0522 10:37:34.973122 19861 sgd_solver.cpp:112] Iteration 10960, lr = 0.001
I0522 10:37:37.088367 19861 solver.cpp:239] Iteration 10980 (9.45512 iter/s, 2.11526s/20 iters), loss = 0.0021172
I0522 10:37:37.088397 19861 solver.cpp:258]     Train net output #0: loss = 0.00211714 (* 1 = 0.00211714 loss)
I0522 10:37:37.088399 19861 sgd_solver.cpp:112] Iteration 10980, lr = 0.001
I0522 10:37:39.032361 19861 solver.cpp:347] Iteration 11000, Testing net (#0)
I0522 10:37:40.868782 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:37:45.159157 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:37:49.053755 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:37:51.149709 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:37:53.337709 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:37:55.385685 19861 solver.cpp:414]     Test net output #0: accuracy = 0.871301
I0522 10:37:55.385759 19861 solver.cpp:414]     Test net output #1: loss = 0.776664 (* 1 = 0.776664 loss)
I0522 10:37:55.486773 19861 solver.cpp:239] Iteration 11000 (1.08705 iter/s, 18.3985s/20 iters), loss = 0.00184747
I0522 10:37:55.489411 19861 solver.cpp:258]     Train net output #0: loss = 0.00184741 (* 1 = 0.00184741 loss)
I0522 10:37:55.489425 19861 sgd_solver.cpp:112] Iteration 11000, lr = 0.001
I0522 10:37:57.712815 19861 solver.cpp:239] Iteration 11020 (8.99519 iter/s, 2.22341s/20 iters), loss = 0.000537948
I0522 10:37:57.712836 19861 solver.cpp:258]     Train net output #0: loss = 0.000537883 (* 1 = 0.000537883 loss)
I0522 10:37:57.712839 19861 sgd_solver.cpp:112] Iteration 11020, lr = 0.001
I0522 10:37:58.363342 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:38:00.140393 19861 solver.cpp:239] Iteration 11040 (8.23879 iter/s, 2.42754s/20 iters), loss = 0.0064339
I0522 10:38:00.140470 19861 solver.cpp:258]     Train net output #0: loss = 0.00643384 (* 1 = 0.00643384 loss)
I0522 10:38:00.140475 19861 sgd_solver.cpp:112] Iteration 11040, lr = 0.001
I0522 10:38:02.294569 19861 solver.cpp:239] Iteration 11060 (9.28468 iter/s, 2.15409s/20 iters), loss = 0.00250963
I0522 10:38:02.294618 19861 solver.cpp:258]     Train net output #0: loss = 0.00250957 (* 1 = 0.00250957 loss)
I0522 10:38:02.294622 19861 sgd_solver.cpp:112] Iteration 11060, lr = 0.001
I0522 10:38:04.531611 19861 solver.cpp:239] Iteration 11080 (8.94058 iter/s, 2.23699s/20 iters), loss = 0.003036
I0522 10:38:04.531651 19861 solver.cpp:258]     Train net output #0: loss = 0.00303594 (* 1 = 0.00303594 loss)
I0522 10:38:04.531656 19861 sgd_solver.cpp:112] Iteration 11080, lr = 0.001
I0522 10:38:07.075372 19861 solver.cpp:239] Iteration 11100 (7.86253 iter/s, 2.54371s/20 iters), loss = 0.0035322
I0522 10:38:07.075464 19861 solver.cpp:258]     Train net output #0: loss = 0.00353214 (* 1 = 0.00353214 loss)
I0522 10:38:07.075469 19861 sgd_solver.cpp:112] Iteration 11100, lr = 0.001
I0522 10:38:09.287027 19861 solver.cpp:239] Iteration 11120 (9.04348 iter/s, 2.21154s/20 iters), loss = 0.00750245
I0522 10:38:09.287312 19861 solver.cpp:258]     Train net output #0: loss = 0.00750239 (* 1 = 0.00750239 loss)
I0522 10:38:09.287317 19861 sgd_solver.cpp:112] Iteration 11120, lr = 0.001
I0522 10:38:11.492156 19861 solver.cpp:239] Iteration 11140 (9.07097 iter/s, 2.20484s/20 iters), loss = 0.00223728
I0522 10:38:11.492219 19861 solver.cpp:258]     Train net output #0: loss = 0.00223722 (* 1 = 0.00223722 loss)
I0522 10:38:11.492223 19861 sgd_solver.cpp:112] Iteration 11140, lr = 0.001
I0522 10:38:13.919423 19861 solver.cpp:239] Iteration 11160 (8.23997 iter/s, 2.42719s/20 iters), loss = 0.00104337
I0522 10:38:13.919495 19861 solver.cpp:258]     Train net output #0: loss = 0.00104331 (* 1 = 0.00104331 loss)
I0522 10:38:13.919499 19861 sgd_solver.cpp:112] Iteration 11160, lr = 0.001
I0522 10:38:16.055516 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:38:16.177937 19861 solver.cpp:239] Iteration 11180 (8.85574 iter/s, 2.25842s/20 iters), loss = 0.00107553
I0522 10:38:16.178026 19861 solver.cpp:258]     Train net output #0: loss = 0.00107547 (* 1 = 0.00107547 loss)
I0522 10:38:16.178037 19861 sgd_solver.cpp:112] Iteration 11180, lr = 0.001
I0522 10:38:18.380400 19861 solver.cpp:239] Iteration 11200 (9.08116 iter/s, 2.20236s/20 iters), loss = 0.00330592
I0522 10:38:18.380494 19861 solver.cpp:258]     Train net output #0: loss = 0.00330586 (* 1 = 0.00330586 loss)
I0522 10:38:18.380498 19861 sgd_solver.cpp:112] Iteration 11200, lr = 0.001
I0522 10:38:20.858387 19861 solver.cpp:239] Iteration 11220 (8.07146 iter/s, 2.47787s/20 iters), loss = 0.00946376
I0522 10:38:20.858503 19861 solver.cpp:258]     Train net output #0: loss = 0.00946369 (* 1 = 0.00946369 loss)
I0522 10:38:20.858515 19861 sgd_solver.cpp:112] Iteration 11220, lr = 0.001
I0522 10:38:23.065446 19861 solver.cpp:239] Iteration 11240 (9.06236 iter/s, 2.20693s/20 iters), loss = 0.00913797
I0522 10:38:23.065519 19861 solver.cpp:258]     Train net output #0: loss = 0.00913791 (* 1 = 0.00913791 loss)
I0522 10:38:23.065522 19861 sgd_solver.cpp:112] Iteration 11240, lr = 0.001
I0522 10:38:25.268954 19861 solver.cpp:239] Iteration 11260 (9.07683 iter/s, 2.20341s/20 iters), loss = 0.00555122
I0522 10:38:25.269050 19861 solver.cpp:258]     Train net output #0: loss = 0.00555115 (* 1 = 0.00555115 loss)
I0522 10:38:25.269054 19861 sgd_solver.cpp:112] Iteration 11260, lr = 0.001
I0522 10:38:27.648851 19861 solver.cpp:239] Iteration 11280 (8.40412 iter/s, 2.37979s/20 iters), loss = 0.0062932
I0522 10:38:27.663257 19861 solver.cpp:258]     Train net output #0: loss = 0.00629314 (* 1 = 0.00629314 loss)
I0522 10:38:27.663266 19861 sgd_solver.cpp:112] Iteration 11280, lr = 0.001
I0522 10:38:30.047909 19861 solver.cpp:239] Iteration 11300 (8.38702 iter/s, 2.38464s/20 iters), loss = 0.00793323
I0522 10:38:30.047968 19861 solver.cpp:258]     Train net output #0: loss = 0.00793317 (* 1 = 0.00793317 loss)
I0522 10:38:30.047973 19861 sgd_solver.cpp:112] Iteration 11300, lr = 0.001
I0522 10:38:32.242820 19861 solver.cpp:239] Iteration 11320 (9.11233 iter/s, 2.19483s/20 iters), loss = 0.00176618
I0522 10:38:32.242911 19861 solver.cpp:258]     Train net output #0: loss = 0.00176611 (* 1 = 0.00176611 loss)
I0522 10:38:32.242916 19861 sgd_solver.cpp:112] Iteration 11320, lr = 0.001
I0522 10:38:33.556172 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:38:34.459501 19861 solver.cpp:239] Iteration 11340 (9.02291 iter/s, 2.21658s/20 iters), loss = 0.00276756
I0522 10:38:34.459553 19861 solver.cpp:258]     Train net output #0: loss = 0.00276751 (* 1 = 0.00276751 loss)
I0522 10:38:34.459558 19861 sgd_solver.cpp:112] Iteration 11340, lr = 0.001
I0522 10:38:36.927150 19861 solver.cpp:239] Iteration 11360 (8.10508 iter/s, 2.46759s/20 iters), loss = 0.00281436
I0522 10:38:36.927208 19861 solver.cpp:258]     Train net output #0: loss = 0.0028143 (* 1 = 0.0028143 loss)
I0522 10:38:36.927212 19861 sgd_solver.cpp:112] Iteration 11360, lr = 0.001
I0522 10:38:39.108731 19861 solver.cpp:239] Iteration 11380 (9.16794 iter/s, 2.18151s/20 iters), loss = 0.00424041
I0522 10:38:39.108830 19861 solver.cpp:258]     Train net output #0: loss = 0.00424035 (* 1 = 0.00424035 loss)
I0522 10:38:39.108834 19861 sgd_solver.cpp:112] Iteration 11380, lr = 0.001
I0522 10:38:41.264073 19861 solver.cpp:239] Iteration 11400 (9.27973 iter/s, 2.15523s/20 iters), loss = 0.00112371
I0522 10:38:41.273226 19861 solver.cpp:258]     Train net output #0: loss = 0.00112365 (* 1 = 0.00112365 loss)
I0522 10:38:41.273234 19861 sgd_solver.cpp:112] Iteration 11400, lr = 0.001
I0522 10:38:43.773571 19861 solver.cpp:239] Iteration 11420 (7.99893 iter/s, 2.50033s/20 iters), loss = 0.00367251
I0522 10:38:43.773653 19861 solver.cpp:258]     Train net output #0: loss = 0.00367245 (* 1 = 0.00367245 loss)
I0522 10:38:43.773658 19861 sgd_solver.cpp:112] Iteration 11420, lr = 0.001
I0522 10:38:45.904745 19861 solver.cpp:239] Iteration 11440 (9.385 iter/s, 2.13106s/20 iters), loss = 0.00645907
I0522 10:38:45.904881 19861 solver.cpp:258]     Train net output #0: loss = 0.00645901 (* 1 = 0.00645901 loss)
I0522 10:38:45.904894 19861 sgd_solver.cpp:112] Iteration 11440, lr = 0.001
I0522 10:38:47.982910 19861 solver.cpp:239] Iteration 11460 (9.62455 iter/s, 2.07802s/20 iters), loss = 0.00126417
I0522 10:38:47.991983 19861 solver.cpp:258]     Train net output #0: loss = 0.00126411 (* 1 = 0.00126411 loss)
I0522 10:38:47.991994 19861 sgd_solver.cpp:112] Iteration 11460, lr = 0.001
I0522 10:38:50.086500 19861 solver.cpp:239] Iteration 11480 (9.54886 iter/s, 2.09449s/20 iters), loss = 0.00213265
I0522 10:38:50.086606 19861 solver.cpp:258]     Train net output #0: loss = 0.00213258 (* 1 = 0.00213258 loss)
I0522 10:38:50.086621 19861 sgd_solver.cpp:112] Iteration 11480, lr = 0.001
I0522 10:38:50.919461 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:38:52.503226 19861 solver.cpp:239] Iteration 11500 (8.27621 iter/s, 2.41656s/20 iters), loss = 0.00224483
I0522 10:38:52.503371 19861 solver.cpp:258]     Train net output #0: loss = 0.00224477 (* 1 = 0.00224477 loss)
I0522 10:38:52.503386 19861 sgd_solver.cpp:112] Iteration 11500, lr = 0.001
I0522 10:38:55.018795 19861 solver.cpp:239] Iteration 11520 (7.95103 iter/s, 2.5154s/20 iters), loss = 0.00156594
I0522 10:38:55.018923 19861 solver.cpp:258]     Train net output #0: loss = 0.00156587 (* 1 = 0.00156587 loss)
I0522 10:38:55.018941 19861 sgd_solver.cpp:112] Iteration 11520, lr = 0.001
I0522 10:38:57.398561 19861 solver.cpp:239] Iteration 11540 (8.40464 iter/s, 2.37964s/20 iters), loss = 0.00361026
I0522 10:38:57.398718 19861 solver.cpp:258]     Train net output #0: loss = 0.0036102 (* 1 = 0.0036102 loss)
I0522 10:38:57.398736 19861 sgd_solver.cpp:112] Iteration 11540, lr = 0.001
I0522 10:38:59.705097 19861 solver.cpp:239] Iteration 11560 (8.67165 iter/s, 2.30637s/20 iters), loss = 0.0101586
I0522 10:38:59.705163 19861 solver.cpp:258]     Train net output #0: loss = 0.0101585 (* 1 = 0.0101585 loss)
I0522 10:38:59.705170 19861 sgd_solver.cpp:112] Iteration 11560, lr = 0.001
I0522 10:39:02.215183 19861 solver.cpp:239] Iteration 11580 (7.96807 iter/s, 2.51002s/20 iters), loss = 0.00626482
I0522 10:39:02.215232 19861 solver.cpp:258]     Train net output #0: loss = 0.00626476 (* 1 = 0.00626476 loss)
I0522 10:39:02.215236 19861 sgd_solver.cpp:112] Iteration 11580, lr = 0.001
I0522 10:39:04.433387 19861 solver.cpp:239] Iteration 11600 (9.01665 iter/s, 2.21812s/20 iters), loss = 0.02423
I0522 10:39:04.445642 19861 solver.cpp:258]     Train net output #0: loss = 0.02423 (* 1 = 0.02423 loss)
I0522 10:39:04.445650 19861 sgd_solver.cpp:112] Iteration 11600, lr = 0.001
I0522 10:39:06.555341 19861 solver.cpp:239] Iteration 11620 (9.47999 iter/s, 2.10971s/20 iters), loss = 0.00132974
I0522 10:39:06.555362 19861 solver.cpp:258]     Train net output #0: loss = 0.00132967 (* 1 = 0.00132967 loss)
I0522 10:39:06.555366 19861 sgd_solver.cpp:112] Iteration 11620, lr = 0.001
I0522 10:39:08.553812 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:39:08.720329 19861 solver.cpp:239] Iteration 11640 (9.23804 iter/s, 2.16496s/20 iters), loss = 0.00279649
I0522 10:39:08.729686 19861 solver.cpp:258]     Train net output #0: loss = 0.00279642 (* 1 = 0.00279642 loss)
I0522 10:39:08.729691 19861 sgd_solver.cpp:112] Iteration 11640, lr = 0.001
I0522 10:39:11.192795 19861 solver.cpp:239] Iteration 11660 (8.11983 iter/s, 2.4631s/20 iters), loss = 0.00161903
I0522 10:39:11.192847 19861 solver.cpp:258]     Train net output #0: loss = 0.00161896 (* 1 = 0.00161896 loss)
I0522 10:39:11.192896 19861 sgd_solver.cpp:112] Iteration 11660, lr = 0.001
I0522 10:39:13.350435 19861 solver.cpp:239] Iteration 11680 (9.26962 iter/s, 2.15759s/20 iters), loss = 0.00724199
I0522 10:39:13.350657 19861 solver.cpp:258]     Train net output #0: loss = 0.00724192 (* 1 = 0.00724192 loss)
I0522 10:39:13.350662 19861 sgd_solver.cpp:112] Iteration 11680, lr = 0.001
I0522 10:39:15.467509 19861 solver.cpp:239] Iteration 11700 (9.44801 iter/s, 2.11685s/20 iters), loss = 0.0048915
I0522 10:39:15.476585 19861 solver.cpp:258]     Train net output #0: loss = 0.00489143 (* 1 = 0.00489143 loss)
I0522 10:39:15.476593 19861 sgd_solver.cpp:112] Iteration 11700, lr = 0.001
I0522 10:39:17.946466 19861 solver.cpp:239] Iteration 11720 (8.09756 iter/s, 2.46988s/20 iters), loss = 0.00486915
I0522 10:39:17.946509 19861 solver.cpp:258]     Train net output #0: loss = 0.00486908 (* 1 = 0.00486908 loss)
I0522 10:39:17.946513 19861 sgd_solver.cpp:112] Iteration 11720, lr = 0.001
I0522 10:39:20.147003 19861 solver.cpp:239] Iteration 11740 (9.08896 iter/s, 2.20047s/20 iters), loss = 0.000628289
I0522 10:39:20.147084 19861 solver.cpp:258]     Train net output #0: loss = 0.000628218 (* 1 = 0.000628218 loss)
I0522 10:39:20.147090 19861 sgd_solver.cpp:112] Iteration 11740, lr = 0.001
I0522 10:39:22.387328 19861 solver.cpp:239] Iteration 11760 (8.92762 iter/s, 2.24024s/20 iters), loss = 0.00101719
I0522 10:39:22.387374 19861 solver.cpp:258]     Train net output #0: loss = 0.00101712 (* 1 = 0.00101712 loss)
I0522 10:39:22.387378 19861 sgd_solver.cpp:112] Iteration 11760, lr = 0.001
I0522 10:39:23.716961 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:39:24.529479 19861 solver.cpp:239] Iteration 11780 (9.33664 iter/s, 2.1421s/20 iters), loss = 0.00255461
I0522 10:39:24.529521 19861 solver.cpp:258]     Train net output #0: loss = 0.00255454 (* 1 = 0.00255454 loss)
I0522 10:39:24.529527 19861 sgd_solver.cpp:112] Iteration 11780, lr = 0.001
I0522 10:39:26.057623 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:39:26.964051 19861 solver.cpp:239] Iteration 11800 (8.21522 iter/s, 2.43451s/20 iters), loss = 0.00313694
I0522 10:39:26.964128 19861 solver.cpp:258]     Train net output #0: loss = 0.00313687 (* 1 = 0.00313687 loss)
I0522 10:39:26.964131 19861 sgd_solver.cpp:112] Iteration 11800, lr = 0.001
I0522 10:39:29.105666 19861 solver.cpp:239] Iteration 11820 (9.33906 iter/s, 2.14154s/20 iters), loss = 0.00235217
I0522 10:39:29.105692 19861 solver.cpp:258]     Train net output #0: loss = 0.0023521 (* 1 = 0.0023521 loss)
I0522 10:39:29.105696 19861 sgd_solver.cpp:112] Iteration 11820, lr = 0.001
I0522 10:39:31.232972 19861 solver.cpp:239] Iteration 11840 (9.40169 iter/s, 2.12728s/20 iters), loss = 0.00382124
I0522 10:39:31.233012 19861 solver.cpp:258]     Train net output #0: loss = 0.00382116 (* 1 = 0.00382116 loss)
I0522 10:39:31.233016 19861 sgd_solver.cpp:112] Iteration 11840, lr = 0.001
I0522 10:39:33.633574 19861 solver.cpp:239] Iteration 11860 (8.3314 iter/s, 2.40056s/20 iters), loss = 0.00137113
I0522 10:39:33.633625 19861 solver.cpp:258]     Train net output #0: loss = 0.00137106 (* 1 = 0.00137106 loss)
I0522 10:39:33.633630 19861 sgd_solver.cpp:112] Iteration 11860, lr = 0.001
I0522 10:39:35.784224 19861 solver.cpp:239] Iteration 11880 (9.29981 iter/s, 2.15058s/20 iters), loss = 0.00556146
I0522 10:39:35.784291 19861 solver.cpp:258]     Train net output #0: loss = 0.00556139 (* 1 = 0.00556139 loss)
I0522 10:39:35.784296 19861 sgd_solver.cpp:112] Iteration 11880, lr = 0.001
I0522 10:39:37.900862 19861 solver.cpp:239] Iteration 11900 (9.44926 iter/s, 2.11657s/20 iters), loss = 0.00182372
I0522 10:39:37.900905 19861 solver.cpp:258]     Train net output #0: loss = 0.00182365 (* 1 = 0.00182365 loss)
I0522 10:39:37.900909 19861 sgd_solver.cpp:112] Iteration 11900, lr = 0.001
I0522 10:39:40.026386 19861 solver.cpp:239] Iteration 11920 (9.40965 iter/s, 2.12548s/20 iters), loss = 0.00191848
I0522 10:39:40.026418 19861 solver.cpp:258]     Train net output #0: loss = 0.00191841 (* 1 = 0.00191841 loss)
I0522 10:39:40.026422 19861 sgd_solver.cpp:112] Iteration 11920, lr = 0.001
I0522 10:39:42.426841 19861 solver.cpp:239] Iteration 11940 (8.3319 iter/s, 2.40041s/20 iters), loss = 0.00232614
I0522 10:39:42.426888 19861 solver.cpp:258]     Train net output #0: loss = 0.00232606 (* 1 = 0.00232606 loss)
I0522 10:39:42.426955 19861 sgd_solver.cpp:112] Iteration 11940, lr = 0.001
I0522 10:39:42.932840 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:39:44.571544 19861 solver.cpp:239] Iteration 11960 (9.32552 iter/s, 2.14465s/20 iters), loss = 0.0114238
I0522 10:39:44.571861 19861 solver.cpp:258]     Train net output #0: loss = 0.0114237 (* 1 = 0.0114237 loss)
I0522 10:39:44.571864 19861 sgd_solver.cpp:112] Iteration 11960, lr = 0.001
I0522 10:39:46.763933 19861 solver.cpp:239] Iteration 11980 (9.12385 iter/s, 2.19206s/20 iters), loss = 0.00212486
I0522 10:39:46.763998 19861 solver.cpp:258]     Train net output #0: loss = 0.00212479 (* 1 = 0.00212479 loss)
I0522 10:39:46.764001 19861 sgd_solver.cpp:112] Iteration 11980, lr = 0.001
I0522 10:39:49.026926 19861 solver.cpp:347] Iteration 12000, Testing net (#0)
I0522 10:39:51.138339 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:39:55.130777 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:39:59.363512 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:40:01.905730 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:40:03.559949 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:40:05.419102 19861 solver.cpp:414]     Test net output #0: accuracy = 0.873561
I0522 10:40:05.419178 19861 solver.cpp:414]     Test net output #1: loss = 0.803242 (* 1 = 0.803242 loss)
I0522 10:40:05.517338 19861 solver.cpp:239] Iteration 12000 (1.06648 iter/s, 18.7534s/20 iters), loss = 0.00540469
I0522 10:40:05.520248 19861 solver.cpp:258]     Train net output #0: loss = 0.00540462 (* 1 = 0.00540462 loss)
I0522 10:40:05.520264 19861 sgd_solver.cpp:112] Iteration 12000, lr = 0.001
I0522 10:40:07.690644 19861 solver.cpp:239] Iteration 12020 (9.21493 iter/s, 2.17039s/20 iters), loss = 0.00252152
I0522 10:40:07.704499 19861 solver.cpp:258]     Train net output #0: loss = 0.00252145 (* 1 = 0.00252145 loss)
I0522 10:40:07.704541 19861 sgd_solver.cpp:112] Iteration 12020, lr = 0.001
I0522 10:40:09.991971 19861 solver.cpp:239] Iteration 12040 (8.74329 iter/s, 2.28747s/20 iters), loss = 0.00141048
I0522 10:40:10.004530 19861 solver.cpp:258]     Train net output #0: loss = 0.00141041 (* 1 = 0.00141041 loss)
I0522 10:40:10.004539 19861 sgd_solver.cpp:112] Iteration 12040, lr = 0.001
I0522 10:40:12.364558 19861 solver.cpp:239] Iteration 12060 (8.47457 iter/s, 2.36s/20 iters), loss = 0.0004367
I0522 10:40:12.364634 19861 solver.cpp:258]     Train net output #0: loss = 0.000436629 (* 1 = 0.000436629 loss)
I0522 10:40:12.364637 19861 sgd_solver.cpp:112] Iteration 12060, lr = 0.001
I0522 10:40:14.532428 19861 solver.cpp:239] Iteration 12080 (9.22596 iter/s, 2.1678s/20 iters), loss = 0.00358995
I0522 10:40:14.532455 19861 solver.cpp:258]     Train net output #0: loss = 0.00358988 (* 1 = 0.00358988 loss)
I0522 10:40:14.532459 19861 sgd_solver.cpp:112] Iteration 12080, lr = 0.001
I0522 10:40:16.460832 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:40:16.698199 19861 solver.cpp:239] Iteration 12100 (9.23476 iter/s, 2.16573s/20 iters), loss = 0.000682784
I0522 10:40:16.698266 19861 solver.cpp:258]     Train net output #0: loss = 0.000682714 (* 1 = 0.000682714 loss)
I0522 10:40:16.698271 19861 sgd_solver.cpp:112] Iteration 12100, lr = 0.001
I0522 10:40:19.201346 19861 solver.cpp:239] Iteration 12120 (7.99022 iter/s, 2.50306s/20 iters), loss = 0.000759174
I0522 10:40:19.201437 19861 solver.cpp:258]     Train net output #0: loss = 0.000759103 (* 1 = 0.000759103 loss)
I0522 10:40:19.201442 19861 sgd_solver.cpp:112] Iteration 12120, lr = 0.001
I0522 10:40:21.384635 19861 solver.cpp:239] Iteration 12140 (9.16101 iter/s, 2.18317s/20 iters), loss = 0.00116731
I0522 10:40:21.384742 19861 solver.cpp:258]     Train net output #0: loss = 0.00116724 (* 1 = 0.00116724 loss)
I0522 10:40:21.384750 19861 sgd_solver.cpp:112] Iteration 12140, lr = 0.001
I0522 10:40:23.531607 19861 solver.cpp:239] Iteration 12160 (9.3159 iter/s, 2.14687s/20 iters), loss = 0.00346397
I0522 10:40:23.540829 19861 solver.cpp:258]     Train net output #0: loss = 0.0034639 (* 1 = 0.0034639 loss)
I0522 10:40:23.540838 19861 sgd_solver.cpp:112] Iteration 12160, lr = 0.001
I0522 10:40:26.113605 19861 solver.cpp:239] Iteration 12180 (7.77381 iter/s, 2.57274s/20 iters), loss = 0.003442
I0522 10:40:26.113739 19861 solver.cpp:258]     Train net output #0: loss = 0.00344193 (* 1 = 0.00344193 loss)
I0522 10:40:26.113754 19861 sgd_solver.cpp:112] Iteration 12180, lr = 0.001
I0522 10:40:28.349733 19861 solver.cpp:239] Iteration 12200 (8.94456 iter/s, 2.236s/20 iters), loss = 0.000745609
I0522 10:40:28.349825 19861 solver.cpp:258]     Train net output #0: loss = 0.000745537 (* 1 = 0.000745537 loss)
I0522 10:40:28.349830 19861 sgd_solver.cpp:112] Iteration 12200, lr = 0.001
I0522 10:40:30.518272 19861 solver.cpp:239] Iteration 12220 (9.22318 iter/s, 2.16845s/20 iters), loss = 0.000544957
I0522 10:40:30.531621 19861 solver.cpp:258]     Train net output #0: loss = 0.000544885 (* 1 = 0.000544885 loss)
I0522 10:40:30.531631 19861 sgd_solver.cpp:112] Iteration 12220, lr = 0.001
I0522 10:40:32.951335 19861 solver.cpp:239] Iteration 12240 (8.26546 iter/s, 2.41971s/20 iters), loss = 0.000479419
I0522 10:40:32.961654 19861 solver.cpp:258]     Train net output #0: loss = 0.000479347 (* 1 = 0.000479347 loss)
I0522 10:40:32.961660 19861 sgd_solver.cpp:112] Iteration 12240, lr = 0.001
I0522 10:40:34.111307 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:40:35.183709 19861 solver.cpp:239] Iteration 12260 (9.00071 iter/s, 2.22205s/20 iters), loss = 0.00144836
I0522 10:40:35.183760 19861 solver.cpp:258]     Train net output #0: loss = 0.00144828 (* 1 = 0.00144828 loss)
I0522 10:40:35.183764 19861 sgd_solver.cpp:112] Iteration 12260, lr = 0.001
I0522 10:40:37.366324 19861 solver.cpp:239] Iteration 12280 (9.16358 iter/s, 2.18255s/20 iters), loss = 0.000389725
I0522 10:40:37.377230 19861 solver.cpp:258]     Train net output #0: loss = 0.000389652 (* 1 = 0.000389652 loss)
I0522 10:40:37.377238 19861 sgd_solver.cpp:112] Iteration 12280, lr = 0.001
I0522 10:40:39.589207 19861 solver.cpp:239] Iteration 12300 (9.04168 iter/s, 2.21198s/20 iters), loss = 0.00659967
I0522 10:40:39.599262 19861 solver.cpp:258]     Train net output #0: loss = 0.0065996 (* 1 = 0.0065996 loss)
I0522 10:40:39.599269 19861 sgd_solver.cpp:112] Iteration 12300, lr = 0.001
I0522 10:40:42.106858 19861 solver.cpp:239] Iteration 12320 (7.97578 iter/s, 2.50759s/20 iters), loss = 0.00211259
I0522 10:40:42.115943 19861 solver.cpp:258]     Train net output #0: loss = 0.00211251 (* 1 = 0.00211251 loss)
I0522 10:40:42.115950 19861 sgd_solver.cpp:112] Iteration 12320, lr = 0.001
I0522 10:40:44.274046 19861 solver.cpp:239] Iteration 12340 (9.2675 iter/s, 2.15808s/20 iters), loss = 0.000618165
I0522 10:40:44.274144 19861 solver.cpp:258]     Train net output #0: loss = 0.000618093 (* 1 = 0.000618093 loss)
I0522 10:40:44.274150 19861 sgd_solver.cpp:112] Iteration 12340, lr = 0.001
I0522 10:40:46.455955 19861 solver.cpp:239] Iteration 12360 (9.16673 iter/s, 2.1818s/20 iters), loss = 0.00220999
I0522 10:40:46.456055 19861 solver.cpp:258]     Train net output #0: loss = 0.00220992 (* 1 = 0.00220992 loss)
I0522 10:40:46.456060 19861 sgd_solver.cpp:112] Iteration 12360, lr = 0.001
I0522 10:40:48.841394 19861 solver.cpp:239] Iteration 12380 (8.38456 iter/s, 2.38534s/20 iters), loss = 0.00122329
I0522 10:40:48.841534 19861 solver.cpp:258]     Train net output #0: loss = 0.00122322 (* 1 = 0.00122322 loss)
I0522 10:40:48.841538 19861 sgd_solver.cpp:112] Iteration 12380, lr = 0.001
I0522 10:40:51.029970 19861 solver.cpp:239] Iteration 12400 (9.13904 iter/s, 2.18841s/20 iters), loss = 0.00114746
I0522 10:40:51.030061 19861 solver.cpp:258]     Train net output #0: loss = 0.00114738 (* 1 = 0.00114738 loss)
I0522 10:40:51.030066 19861 sgd_solver.cpp:112] Iteration 12400, lr = 0.001
I0522 10:40:51.458860 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:40:53.231775 19861 solver.cpp:239] Iteration 12420 (9.08388 iter/s, 2.2017s/20 iters), loss = 0.00517423
I0522 10:40:53.244318 19861 solver.cpp:258]     Train net output #0: loss = 0.00517415 (* 1 = 0.00517415 loss)
I0522 10:40:53.244326 19861 sgd_solver.cpp:112] Iteration 12420, lr = 0.001
I0522 10:40:55.740083 19861 solver.cpp:239] Iteration 12440 (8.01359 iter/s, 2.49576s/20 iters), loss = 0.00507663
I0522 10:40:55.740139 19861 solver.cpp:258]     Train net output #0: loss = 0.00507656 (* 1 = 0.00507656 loss)
I0522 10:40:55.740142 19861 sgd_solver.cpp:112] Iteration 12440, lr = 0.001
I0522 10:40:57.876230 19861 solver.cpp:239] Iteration 12460 (9.36295 iter/s, 2.13608s/20 iters), loss = 0.00258151
I0522 10:40:57.885295 19861 solver.cpp:258]     Train net output #0: loss = 0.00258144 (* 1 = 0.00258144 loss)
I0522 10:40:57.885308 19861 sgd_solver.cpp:112] Iteration 12460, lr = 0.001
I0522 10:40:59.968127 19861 solver.cpp:239] Iteration 12480 (9.6025 iter/s, 2.08279s/20 iters), loss = 0.00260495
I0522 10:40:59.968267 19861 solver.cpp:258]     Train net output #0: loss = 0.00260488 (* 1 = 0.00260488 loss)
I0522 10:40:59.968281 19861 sgd_solver.cpp:112] Iteration 12480, lr = 0.001
I0522 10:41:02.108573 19861 solver.cpp:239] Iteration 12500 (9.34481 iter/s, 2.14022s/20 iters), loss = 0.00199229
I0522 10:41:02.108777 19861 solver.cpp:258]     Train net output #0: loss = 0.00199222 (* 1 = 0.00199222 loss)
I0522 10:41:02.108795 19861 sgd_solver.cpp:112] Iteration 12500, lr = 0.001
I0522 10:41:04.580219 19861 solver.cpp:239] Iteration 12520 (8.09241 iter/s, 2.47145s/20 iters), loss = 0.00170215
I0522 10:41:04.580268 19861 solver.cpp:258]     Train net output #0: loss = 0.00170207 (* 1 = 0.00170207 loss)
I0522 10:41:04.580272 19861 sgd_solver.cpp:112] Iteration 12520, lr = 0.001
I0522 10:41:06.749639 19861 solver.cpp:239] Iteration 12540 (9.21937 iter/s, 2.16935s/20 iters), loss = 0.010593
I0522 10:41:06.749722 19861 solver.cpp:258]     Train net output #0: loss = 0.0105929 (* 1 = 0.0105929 loss)
I0522 10:41:06.749727 19861 sgd_solver.cpp:112] Iteration 12540, lr = 0.001
I0522 10:41:08.666450 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:41:08.948875 19861 solver.cpp:239] Iteration 12560 (9.09451 iter/s, 2.19913s/20 iters), loss = 0.00137999
I0522 10:41:08.948973 19861 solver.cpp:258]     Train net output #0: loss = 0.00137992 (* 1 = 0.00137992 loss)
I0522 10:41:08.948978 19861 sgd_solver.cpp:112] Iteration 12560, lr = 0.001
I0522 10:41:11.421268 19861 solver.cpp:239] Iteration 12580 (8.08965 iter/s, 2.47229s/20 iters), loss = 0.000623146
I0522 10:41:11.433244 19861 solver.cpp:258]     Train net output #0: loss = 0.000623073 (* 1 = 0.000623073 loss)
I0522 10:41:11.433252 19861 sgd_solver.cpp:112] Iteration 12580, lr = 0.001
I0522 10:41:13.562508 19861 solver.cpp:239] Iteration 12600 (9.39294 iter/s, 2.12926s/20 iters), loss = 0.000669659
I0522 10:41:13.562566 19861 solver.cpp:258]     Train net output #0: loss = 0.000669587 (* 1 = 0.000669587 loss)
I0522 10:41:13.562572 19861 sgd_solver.cpp:112] Iteration 12600, lr = 0.001
I0522 10:41:15.714722 19861 solver.cpp:239] Iteration 12620 (9.29306 iter/s, 2.15214s/20 iters), loss = 0.00588777
I0522 10:41:15.714781 19861 solver.cpp:258]     Train net output #0: loss = 0.00588769 (* 1 = 0.00588769 loss)
I0522 10:41:15.714783 19861 sgd_solver.cpp:112] Iteration 12620, lr = 0.001
I0522 10:41:18.277647 19861 solver.cpp:239] Iteration 12640 (7.80377 iter/s, 2.56287s/20 iters), loss = 0.00145847
I0522 10:41:18.277760 19861 solver.cpp:258]     Train net output #0: loss = 0.00145839 (* 1 = 0.00145839 loss)
I0522 10:41:18.277763 19861 sgd_solver.cpp:112] Iteration 12640, lr = 0.001
I0522 10:41:20.476559 19861 solver.cpp:239] Iteration 12660 (9.09593 iter/s, 2.19878s/20 iters), loss = 0.00383073
I0522 10:41:20.489532 19861 solver.cpp:258]     Train net output #0: loss = 0.00383066 (* 1 = 0.00383066 loss)
I0522 10:41:20.489540 19861 sgd_solver.cpp:112] Iteration 12660, lr = 0.001
I0522 10:41:22.688256 19861 solver.cpp:239] Iteration 12680 (9.09625 iter/s, 2.19871s/20 iters), loss = 0.00231721
I0522 10:41:22.688330 19861 solver.cpp:258]     Train net output #0: loss = 0.00231714 (* 1 = 0.00231714 loss)
I0522 10:41:22.688336 19861 sgd_solver.cpp:112] Iteration 12680, lr = 0.001
I0522 10:41:25.255775 19861 solver.cpp:239] Iteration 12700 (7.78985 iter/s, 2.56744s/20 iters), loss = 0.00112498
I0522 10:41:25.265952 19861 solver.cpp:258]     Train net output #0: loss = 0.00112491 (* 1 = 0.00112491 loss)
I0522 10:41:25.265964 19861 sgd_solver.cpp:112] Iteration 12700, lr = 0.001
I0522 10:41:26.440032 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:41:27.505832 19861 solver.cpp:239] Iteration 12720 (8.92913 iter/s, 2.23986s/20 iters), loss = 0.00101195
I0522 10:41:27.515388 19861 solver.cpp:258]     Train net output #0: loss = 0.00101188 (* 1 = 0.00101188 loss)
I0522 10:41:27.515398 19861 sgd_solver.cpp:112] Iteration 12720, lr = 0.001
I0522 10:41:29.550050 19861 solver.cpp:239] Iteration 12740 (9.82976 iter/s, 2.03464s/20 iters), loss = 0.00128218
I0522 10:41:29.559466 19861 solver.cpp:258]     Train net output #0: loss = 0.0012821 (* 1 = 0.0012821 loss)
I0522 10:41:29.559474 19861 sgd_solver.cpp:112] Iteration 12740, lr = 0.001
I0522 10:41:31.598891 19861 solver.cpp:239] Iteration 12760 (9.80671 iter/s, 2.03942s/20 iters), loss = 0.00338075
I0522 10:41:31.608474 19861 solver.cpp:258]     Train net output #0: loss = 0.00338068 (* 1 = 0.00338068 loss)
I0522 10:41:31.608481 19861 sgd_solver.cpp:112] Iteration 12760, lr = 0.001
I0522 10:41:33.647444 19861 solver.cpp:239] Iteration 12780 (9.80897 iter/s, 2.03895s/20 iters), loss = 0.00753577
I0522 10:41:33.656848 19861 solver.cpp:258]     Train net output #0: loss = 0.0075357 (* 1 = 0.0075357 loss)
I0522 10:41:33.656857 19861 sgd_solver.cpp:112] Iteration 12780, lr = 0.001
I0522 10:41:36.866976 19861 solver.cpp:239] Iteration 12800 (6.23028 iter/s, 3.21013s/20 iters), loss = 0.00589623
I0522 10:41:36.876228 19861 solver.cpp:258]     Train net output #0: loss = 0.00589615 (* 1 = 0.00589615 loss)
I0522 10:41:36.876235 19861 sgd_solver.cpp:112] Iteration 12800, lr = 0.001
I0522 10:41:39.284337 19861 solver.cpp:239] Iteration 12820 (8.30531 iter/s, 2.4081s/20 iters), loss = 0.00598395
I0522 10:41:39.293859 19861 solver.cpp:258]     Train net output #0: loss = 0.00598388 (* 1 = 0.00598388 loss)
I0522 10:41:39.293867 19861 sgd_solver.cpp:112] Iteration 12820, lr = 0.001
I0522 10:41:41.331944 19861 solver.cpp:239] Iteration 12840 (9.81325 iter/s, 2.03806s/20 iters), loss = 0.0119086
I0522 10:41:41.341559 19861 solver.cpp:258]     Train net output #0: loss = 0.0119085 (* 1 = 0.0119085 loss)
I0522 10:41:41.341567 19861 sgd_solver.cpp:112] Iteration 12840, lr = 0.001
I0522 10:41:43.375862 19861 solver.cpp:239] Iteration 12860 (9.8314 iter/s, 2.0343s/20 iters), loss = 0.00163941
I0522 10:41:43.385408 19861 solver.cpp:258]     Train net output #0: loss = 0.00163934 (* 1 = 0.00163934 loss)
I0522 10:41:43.385416 19861 sgd_solver.cpp:112] Iteration 12860, lr = 0.001
I0522 10:41:43.741735 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:41:44.545306 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:41:45.469039 19861 solver.cpp:239] Iteration 12880 (9.59869 iter/s, 2.08362s/20 iters), loss = 0.00158516
I0522 10:41:45.469118 19861 solver.cpp:258]     Train net output #0: loss = 0.00158509 (* 1 = 0.00158509 loss)
I0522 10:41:45.469125 19861 sgd_solver.cpp:112] Iteration 12880, lr = 0.001
I0522 10:41:49.060401 19861 solver.cpp:239] Iteration 12900 (5.56904 iter/s, 3.59129s/20 iters), loss = 0.0195533
I0522 10:41:49.070015 19861 solver.cpp:258]     Train net output #0: loss = 0.0195533 (* 1 = 0.0195533 loss)
I0522 10:41:49.070024 19861 sgd_solver.cpp:112] Iteration 12900, lr = 0.001
I0522 10:41:51.114784 19861 solver.cpp:239] Iteration 12920 (9.78112 iter/s, 2.04476s/20 iters), loss = 0.00207995
I0522 10:41:51.124308 19861 solver.cpp:258]     Train net output #0: loss = 0.00207988 (* 1 = 0.00207988 loss)
I0522 10:41:51.124320 19861 sgd_solver.cpp:112] Iteration 12920, lr = 0.001
I0522 10:41:53.166111 19861 solver.cpp:239] Iteration 12940 (9.7953 iter/s, 2.04179s/20 iters), loss = 0.000598984
I0522 10:41:53.175652 19861 solver.cpp:258]     Train net output #0: loss = 0.000598915 (* 1 = 0.000598915 loss)
I0522 10:41:53.175665 19861 sgd_solver.cpp:112] Iteration 12940, lr = 0.001
I0522 10:41:55.220368 19861 solver.cpp:239] Iteration 12960 (9.78136 iter/s, 2.04471s/20 iters), loss = 0.00242926
I0522 10:41:55.229809 19861 solver.cpp:258]     Train net output #0: loss = 0.00242919 (* 1 = 0.00242919 loss)
I0522 10:41:55.229842 19861 sgd_solver.cpp:112] Iteration 12960, lr = 0.001
I0522 10:41:58.523840 19861 solver.cpp:239] Iteration 12980 (6.07159 iter/s, 3.29403s/20 iters), loss = 0.00932181
I0522 10:41:58.533085 19861 solver.cpp:258]     Train net output #0: loss = 0.00932174 (* 1 = 0.00932174 loss)
I0522 10:41:58.533095 19861 sgd_solver.cpp:112] Iteration 12980, lr = 0.001
I0522 10:42:00.876543 19861 solver.cpp:347] Iteration 13000, Testing net (#0)
I0522 10:42:02.907613 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:42:06.594197 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:42:11.706764 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:42:15.392853 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:42:16.034909 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:42:16.965013 19861 solver.cpp:414]     Test net output #0: accuracy = 0.877382
I0522 10:42:16.965083 19861 solver.cpp:414]     Test net output #1: loss = 0.780715 (* 1 = 0.780715 loss)
I0522 10:42:17.061764 19861 solver.cpp:239] Iteration 13000 (1.0794 iter/s, 18.5287s/20 iters), loss = 0.00158256
I0522 10:42:17.063905 19861 solver.cpp:258]     Train net output #0: loss = 0.00158249 (* 1 = 0.00158249 loss)
I0522 10:42:17.063927 19861 sgd_solver.cpp:112] Iteration 13000, lr = 0.001
I0522 10:42:19.970703 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:42:20.604806 19861 solver.cpp:239] Iteration 13020 (5.64827 iter/s, 3.54091s/20 iters), loss = 0.00261712
I0522 10:42:20.604876 19861 solver.cpp:258]     Train net output #0: loss = 0.00261705 (* 1 = 0.00261705 loss)
I0522 10:42:20.604882 19861 sgd_solver.cpp:112] Iteration 13020, lr = 0.001
I0522 10:42:22.666451 19861 solver.cpp:239] Iteration 13040 (9.70139 iter/s, 2.06156s/20 iters), loss = 0.00625157
I0522 10:42:22.676028 19861 solver.cpp:258]     Train net output #0: loss = 0.0062515 (* 1 = 0.0062515 loss)
I0522 10:42:22.676036 19861 sgd_solver.cpp:112] Iteration 13040, lr = 0.001
I0522 10:42:24.702858 19861 solver.cpp:239] Iteration 13060 (9.86765 iter/s, 2.02683s/20 iters), loss = 0.000590735
I0522 10:42:24.712384 19861 solver.cpp:258]     Train net output #0: loss = 0.000590664 (* 1 = 0.000590664 loss)
I0522 10:42:24.712391 19861 sgd_solver.cpp:112] Iteration 13060, lr = 0.001
I0522 10:42:26.741197 19861 solver.cpp:239] Iteration 13080 (9.858 iter/s, 2.02881s/20 iters), loss = 0.00648737
I0522 10:42:26.750746 19861 solver.cpp:258]     Train net output #0: loss = 0.0064873 (* 1 = 0.0064873 loss)
I0522 10:42:26.750756 19861 sgd_solver.cpp:112] Iteration 13080, lr = 0.001
I0522 10:42:30.016870 19861 solver.cpp:239] Iteration 13100 (6.12347 iter/s, 3.26612s/20 iters), loss = 0.00863268
I0522 10:42:30.026026 19861 solver.cpp:258]     Train net output #0: loss = 0.00863261 (* 1 = 0.00863261 loss)
I0522 10:42:30.026033 19861 sgd_solver.cpp:112] Iteration 13100, lr = 0.001
I0522 10:42:32.503408 19861 solver.cpp:239] Iteration 13120 (8.07304 iter/s, 2.47738s/20 iters), loss = 0.000363981
I0522 10:42:32.503453 19861 solver.cpp:258]     Train net output #0: loss = 0.000363911 (* 1 = 0.000363911 loss)
I0522 10:42:32.503455 19861 sgd_solver.cpp:112] Iteration 13120, lr = 0.001
I0522 10:42:34.696684 19861 solver.cpp:239] Iteration 13140 (9.11915 iter/s, 2.19319s/20 iters), loss = 0.00335635
I0522 10:42:34.696810 19861 solver.cpp:258]     Train net output #0: loss = 0.00335628 (* 1 = 0.00335628 loss)
I0522 10:42:34.696816 19861 sgd_solver.cpp:112] Iteration 13140, lr = 0.001
I0522 10:42:36.845173 19861 solver.cpp:239] Iteration 13160 (9.30948 iter/s, 2.14835s/20 iters), loss = 0.0109529
I0522 10:42:36.854666 19861 solver.cpp:258]     Train net output #0: loss = 0.0109528 (* 1 = 0.0109528 loss)
I0522 10:42:36.854676 19861 sgd_solver.cpp:112] Iteration 13160, lr = 0.001
I0522 10:42:37.840538 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:42:38.907023 19861 solver.cpp:239] Iteration 13180 (9.74496 iter/s, 2.05234s/20 iters), loss = 0.00276268
I0522 10:42:38.907115 19861 solver.cpp:258]     Train net output #0: loss = 0.00276261 (* 1 = 0.00276261 loss)
I0522 10:42:38.907119 19861 sgd_solver.cpp:112] Iteration 13180, lr = 0.001
I0522 10:42:42.502566 19861 solver.cpp:239] Iteration 13200 (5.56259 iter/s, 3.59545s/20 iters), loss = 0.00352825
I0522 10:42:42.512287 19861 solver.cpp:258]     Train net output #0: loss = 0.00352818 (* 1 = 0.00352818 loss)
I0522 10:42:42.512295 19861 sgd_solver.cpp:112] Iteration 13200, lr = 0.001
I0522 10:42:44.558341 19861 solver.cpp:239] Iteration 13220 (9.77498 iter/s, 2.04604s/20 iters), loss = 0.000953074
I0522 10:42:44.567760 19861 solver.cpp:258]     Train net output #0: loss = 0.000953004 (* 1 = 0.000953004 loss)
I0522 10:42:44.567771 19861 sgd_solver.cpp:112] Iteration 13220, lr = 0.001
I0522 10:42:46.605335 19861 solver.cpp:239] Iteration 13240 (9.81566 iter/s, 2.03756s/20 iters), loss = 0.000818288
I0522 10:42:46.614784 19861 solver.cpp:258]     Train net output #0: loss = 0.000818218 (* 1 = 0.000818218 loss)
I0522 10:42:46.614795 19861 sgd_solver.cpp:112] Iteration 13240, lr = 0.001
I0522 10:42:48.655992 19861 solver.cpp:239] Iteration 13260 (9.79816 iter/s, 2.0412s/20 iters), loss = 0.000809091
I0522 10:42:48.665495 19861 solver.cpp:258]     Train net output #0: loss = 0.00080902 (* 1 = 0.00080902 loss)
I0522 10:42:48.665511 19861 sgd_solver.cpp:112] Iteration 13260, lr = 0.001
I0522 10:42:50.729212 19861 solver.cpp:239] Iteration 13280 (9.69127 iter/s, 2.06371s/20 iters), loss = 0.000934718
I0522 10:42:50.740706 19861 solver.cpp:258]     Train net output #0: loss = 0.000934649 (* 1 = 0.000934649 loss)
I0522 10:42:50.740713 19861 sgd_solver.cpp:112] Iteration 13280, lr = 0.001
I0522 10:42:54.283516 19861 solver.cpp:239] Iteration 13300 (5.64523 iter/s, 3.54281s/20 iters), loss = 0.00106697
I0522 10:42:54.292773 19861 solver.cpp:258]     Train net output #0: loss = 0.0010669 (* 1 = 0.0010669 loss)
I0522 10:42:54.292783 19861 sgd_solver.cpp:112] Iteration 13300, lr = 0.001
I0522 10:42:56.334436 19861 solver.cpp:239] Iteration 13320 (9.79626 iter/s, 2.04159s/20 iters), loss = 0.00254986
I0522 10:42:56.343888 19861 solver.cpp:258]     Train net output #0: loss = 0.00254979 (* 1 = 0.00254979 loss)
I0522 10:42:56.343896 19861 sgd_solver.cpp:112] Iteration 13320, lr = 0.001
I0522 10:42:56.628368 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:42:58.383477 19861 solver.cpp:239] Iteration 13340 (9.80598 iter/s, 2.03957s/20 iters), loss = 0.00113725
I0522 10:42:58.392918 19861 solver.cpp:258]     Train net output #0: loss = 0.00113718 (* 1 = 0.00113718 loss)
I0522 10:42:58.392927 19861 sgd_solver.cpp:112] Iteration 13340, lr = 0.001
I0522 10:43:00.435385 19861 solver.cpp:239] Iteration 13360 (9.79211 iter/s, 2.04246s/20 iters), loss = 0.00375936
I0522 10:43:00.444866 19861 solver.cpp:258]     Train net output #0: loss = 0.00375929 (* 1 = 0.00375929 loss)
I0522 10:43:00.444875 19861 sgd_solver.cpp:112] Iteration 13360, lr = 0.001
I0522 10:43:03.308001 19861 solver.cpp:239] Iteration 13380 (6.98535 iter/s, 2.86313s/20 iters), loss = 0.00687851
I0522 10:43:03.317510 19861 solver.cpp:258]     Train net output #0: loss = 0.00687844 (* 1 = 0.00687844 loss)
I0522 10:43:03.317517 19861 sgd_solver.cpp:112] Iteration 13380, lr = 0.001
I0522 10:43:06.208282 19861 solver.cpp:239] Iteration 13400 (6.91857 iter/s, 2.89077s/20 iters), loss = 0.00492877
I0522 10:43:06.208333 19861 solver.cpp:258]     Train net output #0: loss = 0.0049287 (* 1 = 0.0049287 loss)
I0522 10:43:06.208335 19861 sgd_solver.cpp:112] Iteration 13400, lr = 0.001
I0522 10:43:08.397449 19861 solver.cpp:239] Iteration 13420 (9.13613 iter/s, 2.18911s/20 iters), loss = 0.010897
I0522 10:43:08.397501 19861 solver.cpp:258]     Train net output #0: loss = 0.0108969 (* 1 = 0.0108969 loss)
I0522 10:43:08.397505 19861 sgd_solver.cpp:112] Iteration 13420, lr = 0.001
I0522 10:43:10.595304 19861 solver.cpp:239] Iteration 13440 (9.10004 iter/s, 2.19779s/20 iters), loss = 0.0145117
I0522 10:43:10.595364 19861 solver.cpp:258]     Train net output #0: loss = 0.0145117 (* 1 = 0.0145117 loss)
I0522 10:43:10.595371 19861 sgd_solver.cpp:112] Iteration 13440, lr = 0.001
I0522 10:43:12.791635 19861 solver.cpp:239] Iteration 13460 (9.10638 iter/s, 2.19626s/20 iters), loss = 0.00427048
I0522 10:43:12.791703 19861 solver.cpp:258]     Train net output #0: loss = 0.00427041 (* 1 = 0.00427041 loss)
I0522 10:43:12.791708 19861 sgd_solver.cpp:112] Iteration 13460, lr = 0.001
I0522 10:43:15.698096 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:43:16.303709 19861 solver.cpp:239] Iteration 13480 (5.69476 iter/s, 3.512s/20 iters), loss = 0.00345151
I0522 10:43:16.303786 19861 solver.cpp:258]     Train net output #0: loss = 0.00345144 (* 1 = 0.00345144 loss)
I0522 10:43:16.303788 19861 sgd_solver.cpp:112] Iteration 13480, lr = 0.001
I0522 10:43:18.355813 19861 solver.cpp:239] Iteration 13500 (9.74652 iter/s, 2.05201s/20 iters), loss = 0.00416455
I0522 10:43:18.365330 19861 solver.cpp:258]     Train net output #0: loss = 0.00416448 (* 1 = 0.00416448 loss)
I0522 10:43:18.365340 19861 sgd_solver.cpp:112] Iteration 13500, lr = 0.001
I0522 10:43:20.404135 19861 solver.cpp:239] Iteration 13520 (9.80971 iter/s, 2.0388s/20 iters), loss = 0.00127968
I0522 10:43:20.413558 19861 solver.cpp:258]     Train net output #0: loss = 0.0012796 (* 1 = 0.0012796 loss)
I0522 10:43:20.413570 19861 sgd_solver.cpp:112] Iteration 13520, lr = 0.001
I0522 10:43:22.455669 19861 solver.cpp:239] Iteration 13540 (9.79383 iter/s, 2.0421s/20 iters), loss = 0.000284604
I0522 10:43:22.465159 19861 solver.cpp:258]     Train net output #0: loss = 0.000284531 (* 1 = 0.000284531 loss)
I0522 10:43:22.465170 19861 sgd_solver.cpp:112] Iteration 13540, lr = 0.001
I0522 10:43:24.522977 19861 solver.cpp:239] Iteration 13560 (9.71965 iter/s, 2.05769s/20 iters), loss = 0.00482425
I0522 10:43:24.525498 19861 solver.cpp:258]     Train net output #0: loss = 0.00482418 (* 1 = 0.00482418 loss)
I0522 10:43:24.525581 19861 sgd_solver.cpp:112] Iteration 13560, lr = 0.001
I0522 10:43:28.089185 19861 solver.cpp:239] Iteration 13580 (5.61194 iter/s, 3.56383s/20 iters), loss = 0.000798758
I0522 10:43:28.098582 19861 solver.cpp:258]     Train net output #0: loss = 0.000798688 (* 1 = 0.000798688 loss)
I0522 10:43:28.098590 19861 sgd_solver.cpp:112] Iteration 13580, lr = 0.001
I0522 10:43:30.135499 19861 solver.cpp:239] Iteration 13600 (9.81882 iter/s, 2.03691s/20 iters), loss = 0.00188945
I0522 10:43:30.145073 19861 solver.cpp:258]     Train net output #0: loss = 0.00188938 (* 1 = 0.00188938 loss)
I0522 10:43:30.145081 19861 sgd_solver.cpp:112] Iteration 13600, lr = 0.001
I0522 10:43:32.182852 19861 solver.cpp:239] Iteration 13620 (9.8147 iter/s, 2.03776s/20 iters), loss = 0.000615228
I0522 10:43:32.192747 19861 solver.cpp:258]     Train net output #0: loss = 0.000615158 (* 1 = 0.000615158 loss)
I0522 10:43:32.192757 19861 sgd_solver.cpp:112] Iteration 13620, lr = 0.001
I0522 10:43:33.144632 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:43:34.232839 19861 solver.cpp:239] Iteration 13640 (9.80355 iter/s, 2.04008s/20 iters), loss = 0.00147093
I0522 10:43:34.242444 19861 solver.cpp:258]     Train net output #0: loss = 0.00147086 (* 1 = 0.00147086 loss)
I0522 10:43:34.242452 19861 sgd_solver.cpp:112] Iteration 13640, lr = 0.001
I0522 10:43:37.400352 19861 solver.cpp:239] Iteration 13660 (6.3333 iter/s, 3.15791s/20 iters), loss = 0.00928553
I0522 10:43:37.409557 19861 solver.cpp:258]     Train net output #0: loss = 0.00928546 (* 1 = 0.00928546 loss)
I0522 10:43:37.409564 19861 sgd_solver.cpp:112] Iteration 13660, lr = 0.001
I0522 10:43:39.908771 19861 solver.cpp:239] Iteration 13680 (8.00259 iter/s, 2.49919s/20 iters), loss = 0.00123093
I0522 10:43:39.918254 19861 solver.cpp:258]     Train net output #0: loss = 0.00123085 (* 1 = 0.00123085 loss)
I0522 10:43:39.918263 19861 sgd_solver.cpp:112] Iteration 13680, lr = 0.001
I0522 10:43:41.956117 19861 solver.cpp:239] Iteration 13700 (9.81424 iter/s, 2.03786s/20 iters), loss = 0.000848238
I0522 10:43:41.965615 19861 solver.cpp:258]     Train net output #0: loss = 0.000848165 (* 1 = 0.000848165 loss)
I0522 10:43:41.965623 19861 sgd_solver.cpp:112] Iteration 13700, lr = 0.001
I0522 10:43:44.003741 19861 solver.cpp:239] Iteration 13720 (9.81299 iter/s, 2.03812s/20 iters), loss = 0.00132463
I0522 10:43:44.013391 19861 solver.cpp:258]     Train net output #0: loss = 0.00132456 (* 1 = 0.00132456 loss)
I0522 10:43:44.013402 19861 sgd_solver.cpp:112] Iteration 13720, lr = 0.001
I0522 10:43:46.049942 19861 solver.cpp:239] Iteration 13740 (9.82042 iter/s, 2.03657s/20 iters), loss = 0.0013469
I0522 10:43:46.061480 19861 solver.cpp:258]     Train net output #0: loss = 0.00134683 (* 1 = 0.00134683 loss)
I0522 10:43:46.061489 19861 sgd_solver.cpp:112] Iteration 13740, lr = 0.001
I0522 10:43:49.653230 19861 solver.cpp:239] Iteration 13760 (5.5683 iter/s, 3.59176s/20 iters), loss = 0.000622995
I0522 10:43:49.662624 19861 solver.cpp:258]     Train net output #0: loss = 0.000622923 (* 1 = 0.000622923 loss)
I0522 10:43:49.662631 19861 sgd_solver.cpp:112] Iteration 13760, lr = 0.001
I0522 10:43:51.699282 19861 solver.cpp:239] Iteration 13780 (9.82012 iter/s, 2.03664s/20 iters), loss = 0.00127403
I0522 10:43:51.699367 19861 solver.cpp:258]     Train net output #0: loss = 0.00127396 (* 1 = 0.00127396 loss)
I0522 10:43:51.699376 19861 sgd_solver.cpp:112] Iteration 13780, lr = 0.001
I0522 10:43:51.974488 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:43:53.761222 19861 solver.cpp:239] Iteration 13800 (9.70008 iter/s, 2.06184s/20 iters), loss = 0.00118071
I0522 10:43:53.770609 19861 solver.cpp:258]     Train net output #0: loss = 0.00118064 (* 1 = 0.00118064 loss)
I0522 10:43:53.770620 19861 sgd_solver.cpp:112] Iteration 13800, lr = 0.001
I0522 10:43:56.817961 19861 solver.cpp:239] Iteration 13820 (6.56309 iter/s, 3.04735s/20 iters), loss = 0.00209742
I0522 10:43:56.818658 19861 solver.cpp:258]     Train net output #0: loss = 0.00209735 (* 1 = 0.00209735 loss)
I0522 10:43:56.818663 19861 sgd_solver.cpp:112] Iteration 13820, lr = 0.001
I0522 10:43:59.014987 19861 solver.cpp:239] Iteration 13840 (9.10611 iter/s, 2.19633s/20 iters), loss = 0.0023118
I0522 10:43:59.015033 19861 solver.cpp:258]     Train net output #0: loss = 0.00231173 (* 1 = 0.00231173 loss)
I0522 10:43:59.015036 19861 sgd_solver.cpp:112] Iteration 13840, lr = 0.001
I0522 10:44:01.155117 19861 solver.cpp:239] Iteration 13860 (9.34544 iter/s, 2.14008s/20 iters), loss = 0.000694757
I0522 10:44:01.164366 19861 solver.cpp:258]     Train net output #0: loss = 0.000694684 (* 1 = 0.000694684 loss)
I0522 10:44:01.164373 19861 sgd_solver.cpp:112] Iteration 13860, lr = 0.001
I0522 10:44:03.205826 19861 solver.cpp:239] Iteration 13880 (9.79697 iter/s, 2.04145s/20 iters), loss = 0.00115553
I0522 10:44:03.215497 19861 solver.cpp:258]     Train net output #0: loss = 0.00115546 (* 1 = 0.00115546 loss)
I0522 10:44:03.215550 19861 sgd_solver.cpp:112] Iteration 13880, lr = 0.001
I0522 10:44:05.251966 19861 solver.cpp:239] Iteration 13900 (9.82068 iter/s, 2.03652s/20 iters), loss = 0.00080853
I0522 10:44:05.261054 19861 solver.cpp:258]     Train net output #0: loss = 0.000808457 (* 1 = 0.000808457 loss)
I0522 10:44:05.261060 19861 sgd_solver.cpp:112] Iteration 13900, lr = 0.001
I0522 10:44:07.300055 19861 solver.cpp:239] Iteration 13920 (9.80873 iter/s, 2.039s/20 iters), loss = 0.00218887
I0522 10:44:07.309137 19861 solver.cpp:258]     Train net output #0: loss = 0.00218879 (* 1 = 0.00218879 loss)
I0522 10:44:07.309144 19861 sgd_solver.cpp:112] Iteration 13920, lr = 0.001
I0522 10:44:08.893441 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:44:09.347154 19861 solver.cpp:239] Iteration 13940 (9.81348 iter/s, 2.03801s/20 iters), loss = 0.00208674
I0522 10:44:09.356225 19861 solver.cpp:258]     Train net output #0: loss = 0.00208667 (* 1 = 0.00208667 loss)
I0522 10:44:09.356231 19861 sgd_solver.cpp:112] Iteration 13940, lr = 0.001
I0522 10:44:11.398545 19861 solver.cpp:239] Iteration 13960 (9.79279 iter/s, 2.04232s/20 iters), loss = 0.00168471
I0522 10:44:11.407644 19861 solver.cpp:258]     Train net output #0: loss = 0.00168464 (* 1 = 0.00168464 loss)
I0522 10:44:11.407651 19861 sgd_solver.cpp:112] Iteration 13960, lr = 0.001
I0522 10:44:13.443044 19861 solver.cpp:239] Iteration 13980 (9.82609 iter/s, 2.0354s/20 iters), loss = 0.000626915
I0522 10:44:13.443091 19861 solver.cpp:258]     Train net output #0: loss = 0.000626844 (* 1 = 0.000626844 loss)
I0522 10:44:13.443094 19861 sgd_solver.cpp:112] Iteration 13980, lr = 0.001
I0522 10:44:15.337188 19861 solver.cpp:347] Iteration 14000, Testing net (#0)
I0522 10:44:19.162341 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:44:20.049629 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:44:23.077773 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:44:26.694065 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:44:30.578850 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:44:32.012060 19861 solver.cpp:414]     Test net output #0: accuracy = 0.873842
I0522 10:44:32.012111 19861 solver.cpp:414]     Test net output #1: loss = 0.785761 (* 1 = 0.785761 loss)
I0522 10:44:32.110735 19861 solver.cpp:239] Iteration 14000 (1.07137 iter/s, 18.6677s/20 iters), loss = 0.000821747
I0522 10:44:32.112752 19861 solver.cpp:258]     Train net output #0: loss = 0.000821676 (* 1 = 0.000821676 loss)
I0522 10:44:32.112761 19861 sgd_solver.cpp:112] Iteration 14000, lr = 0.001
I0522 10:44:34.195775 19861 solver.cpp:239] Iteration 14020 (9.60157 iter/s, 2.08299s/20 iters), loss = 0.000814933
I0522 10:44:34.195859 19861 solver.cpp:258]     Train net output #0: loss = 0.000814862 (* 1 = 0.000814862 loss)
I0522 10:44:34.195864 19861 sgd_solver.cpp:112] Iteration 14020, lr = 0.001
I0522 10:44:36.292464 19861 solver.cpp:239] Iteration 14040 (9.53929 iter/s, 2.09659s/20 iters), loss = 0.00261226
I0522 10:44:36.292515 19861 solver.cpp:258]     Train net output #0: loss = 0.00261219 (* 1 = 0.00261219 loss)
I0522 10:44:36.292520 19861 sgd_solver.cpp:112] Iteration 14040, lr = 0.001
I0522 10:44:38.399935 19861 solver.cpp:239] Iteration 14060 (9.49043 iter/s, 2.10739s/20 iters), loss = 0.00144107
I0522 10:44:38.400025 19861 solver.cpp:258]     Train net output #0: loss = 0.001441 (* 1 = 0.001441 loss)
I0522 10:44:38.400030 19861 sgd_solver.cpp:112] Iteration 14060, lr = 0.001
I0522 10:44:40.529541 19861 solver.cpp:239] Iteration 14080 (9.39184 iter/s, 2.12951s/20 iters), loss = 0.00110905
I0522 10:44:40.529582 19861 solver.cpp:258]     Train net output #0: loss = 0.00110898 (* 1 = 0.00110898 loss)
I0522 10:44:40.529587 19861 sgd_solver.cpp:112] Iteration 14080, lr = 0.001
I0522 10:44:41.673179 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:44:42.836815 19861 solver.cpp:239] Iteration 14100 (8.66845 iter/s, 2.30722s/20 iters), loss = 0.00149116
I0522 10:44:42.849598 19861 solver.cpp:258]     Train net output #0: loss = 0.00149109 (* 1 = 0.00149109 loss)
I0522 10:44:42.849611 19861 sgd_solver.cpp:112] Iteration 14100, lr = 0.001
I0522 10:44:44.961259 19861 solver.cpp:239] Iteration 14120 (9.4712 iter/s, 2.11166s/20 iters), loss = 0.00474371
I0522 10:44:44.961300 19861 solver.cpp:258]     Train net output #0: loss = 0.00474364 (* 1 = 0.00474364 loss)
I0522 10:44:44.961305 19861 sgd_solver.cpp:112] Iteration 14120, lr = 0.001
I0522 10:44:47.078277 19861 solver.cpp:239] Iteration 14140 (9.44748 iter/s, 2.11697s/20 iters), loss = 0.00630959
I0522 10:44:47.078325 19861 solver.cpp:258]     Train net output #0: loss = 0.00630952 (* 1 = 0.00630952 loss)
I0522 10:44:47.078332 19861 sgd_solver.cpp:112] Iteration 14140, lr = 0.001
I0522 10:44:49.213819 19861 solver.cpp:239] Iteration 14160 (9.36562 iter/s, 2.13547s/20 iters), loss = 0.000927819
I0522 10:44:49.213933 19861 solver.cpp:258]     Train net output #0: loss = 0.000927747 (* 1 = 0.000927747 loss)
I0522 10:44:49.213946 19861 sgd_solver.cpp:112] Iteration 14160, lr = 0.001
I0522 10:44:51.593232 19861 solver.cpp:239] Iteration 14180 (8.40584 iter/s, 2.3793s/20 iters), loss = 0.00452842
I0522 10:44:51.593300 19861 solver.cpp:258]     Train net output #0: loss = 0.00452835 (* 1 = 0.00452835 loss)
I0522 10:44:51.593304 19861 sgd_solver.cpp:112] Iteration 14180, lr = 0.001
I0522 10:44:53.731843 19861 solver.cpp:239] Iteration 14200 (9.35227 iter/s, 2.13852s/20 iters), loss = 0.00270594
I0522 10:44:53.731940 19861 solver.cpp:258]     Train net output #0: loss = 0.00270587 (* 1 = 0.00270587 loss)
I0522 10:44:53.731945 19861 sgd_solver.cpp:112] Iteration 14200, lr = 0.001
I0522 10:44:55.859565 19861 solver.cpp:239] Iteration 14220 (9.40032 iter/s, 2.12759s/20 iters), loss = 0.000894308
I0522 10:44:55.859622 19861 solver.cpp:258]     Train net output #0: loss = 0.000894235 (* 1 = 0.000894235 loss)
I0522 10:44:55.859627 19861 sgd_solver.cpp:112] Iteration 14220, lr = 0.001
I0522 10:44:56.233284 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:44:58.231010 19861 solver.cpp:239] Iteration 14240 (8.43394 iter/s, 2.37137s/20 iters), loss = 0.000829111
I0522 10:44:58.231076 19861 solver.cpp:258]     Train net output #0: loss = 0.000829039 (* 1 = 0.000829039 loss)
I0522 10:44:58.231153 19861 sgd_solver.cpp:112] Iteration 14240, lr = 0.001
I0522 10:44:58.423393 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:45:00.356573 19861 solver.cpp:239] Iteration 14260 (9.40961 iter/s, 2.12549s/20 iters), loss = 0.00174335
I0522 10:45:00.369343 19861 solver.cpp:258]     Train net output #0: loss = 0.00174327 (* 1 = 0.00174327 loss)
I0522 10:45:00.369351 19861 sgd_solver.cpp:112] Iteration 14260, lr = 0.001
I0522 10:45:02.523888 19861 solver.cpp:239] Iteration 14280 (9.28276 iter/s, 2.15453s/20 iters), loss = 0.0020102
I0522 10:45:02.537401 19861 solver.cpp:258]     Train net output #0: loss = 0.00201013 (* 1 = 0.00201013 loss)
I0522 10:45:02.537410 19861 sgd_solver.cpp:112] Iteration 14280, lr = 0.001
I0522 10:45:04.880017 19861 solver.cpp:239] Iteration 14300 (8.53747 iter/s, 2.34261s/20 iters), loss = 0.00229774
I0522 10:45:04.880065 19861 solver.cpp:258]     Train net output #0: loss = 0.00229767 (* 1 = 0.00229767 loss)
I0522 10:45:04.880070 19861 sgd_solver.cpp:112] Iteration 14300, lr = 0.001
I0522 10:45:06.991624 19861 solver.cpp:239] Iteration 14320 (9.47173 iter/s, 2.11155s/20 iters), loss = 0.0050002
I0522 10:45:06.991675 19861 solver.cpp:258]     Train net output #0: loss = 0.00500014 (* 1 = 0.00500014 loss)
I0522 10:45:06.991679 19861 sgd_solver.cpp:112] Iteration 14320, lr = 0.001
I0522 10:45:09.118815 19861 solver.cpp:239] Iteration 14340 (9.40232 iter/s, 2.12713s/20 iters), loss = 0.00470479
I0522 10:45:09.127887 19861 solver.cpp:258]     Train net output #0: loss = 0.00470472 (* 1 = 0.00470472 loss)
I0522 10:45:09.127894 19861 sgd_solver.cpp:112] Iteration 14340, lr = 0.001
I0522 10:45:11.229791 19861 solver.cpp:239] Iteration 14360 (9.51521 iter/s, 2.1019s/20 iters), loss = 0.0089672
I0522 10:45:11.229840 19861 solver.cpp:258]     Train net output #0: loss = 0.00896713 (* 1 = 0.00896713 loss)
I0522 10:45:11.229843 19861 sgd_solver.cpp:112] Iteration 14360, lr = 0.001
I0522 10:45:13.584220 19861 solver.cpp:239] Iteration 14380 (8.49482 iter/s, 2.35437s/20 iters), loss = 0.00997758
I0522 10:45:13.594012 19861 solver.cpp:258]     Train net output #0: loss = 0.00997751 (* 1 = 0.00997751 loss)
I0522 10:45:13.594019 19861 sgd_solver.cpp:112] Iteration 14380, lr = 0.001
I0522 10:45:15.220477 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:45:15.712746 19861 solver.cpp:239] Iteration 14400 (9.43967 iter/s, 2.11872s/20 iters), loss = 0.004509
I0522 10:45:15.712832 19861 solver.cpp:258]     Train net output #0: loss = 0.00450893 (* 1 = 0.00450893 loss)
I0522 10:45:15.712836 19861 sgd_solver.cpp:112] Iteration 14400, lr = 0.001
I0522 10:45:17.862862 19861 solver.cpp:239] Iteration 14420 (9.30228 iter/s, 2.15001s/20 iters), loss = 0.00074292
I0522 10:45:17.862942 19861 solver.cpp:258]     Train net output #0: loss = 0.000742851 (* 1 = 0.000742851 loss)
I0522 10:45:17.862946 19861 sgd_solver.cpp:112] Iteration 14420, lr = 0.001
I0522 10:45:20.269194 19861 solver.cpp:239] Iteration 14440 (8.31171 iter/s, 2.40624s/20 iters), loss = 0.000723057
I0522 10:45:20.269260 19861 solver.cpp:258]     Train net output #0: loss = 0.000722988 (* 1 = 0.000722988 loss)
I0522 10:45:20.269264 19861 sgd_solver.cpp:112] Iteration 14440, lr = 0.001
I0522 10:45:22.379613 19861 solver.cpp:239] Iteration 14460 (9.47717 iter/s, 2.11034s/20 iters), loss = 0.00467544
I0522 10:45:22.388679 19861 solver.cpp:258]     Train net output #0: loss = 0.00467537 (* 1 = 0.00467537 loss)
I0522 10:45:22.388691 19861 sgd_solver.cpp:112] Iteration 14460, lr = 0.001
I0522 10:45:24.456491 19861 solver.cpp:239] Iteration 14480 (9.67242 iter/s, 2.06774s/20 iters), loss = 0.00400946
I0522 10:45:24.469679 19861 solver.cpp:258]     Train net output #0: loss = 0.00400939 (* 1 = 0.00400939 loss)
I0522 10:45:24.469710 19861 sgd_solver.cpp:112] Iteration 14480, lr = 0.001
I0522 10:45:26.829811 19861 solver.cpp:239] Iteration 14500 (8.47413 iter/s, 2.36012s/20 iters), loss = 0.000558885
I0522 10:45:26.843116 19861 solver.cpp:258]     Train net output #0: loss = 0.000558815 (* 1 = 0.000558815 loss)
I0522 10:45:26.843137 19861 sgd_solver.cpp:112] Iteration 14500, lr = 0.001
I0522 10:45:28.953663 19861 solver.cpp:239] Iteration 14520 (9.47618 iter/s, 2.11055s/20 iters), loss = 0.00568011
I0522 10:45:28.953728 19861 solver.cpp:258]     Train net output #0: loss = 0.00568004 (* 1 = 0.00568004 loss)
I0522 10:45:28.953733 19861 sgd_solver.cpp:112] Iteration 14520, lr = 0.001
I0522 10:45:31.161554 19861 solver.cpp:239] Iteration 14540 (9.05888 iter/s, 2.20778s/20 iters), loss = 0.000812046
I0522 10:45:31.161870 19861 solver.cpp:258]     Train net output #0: loss = 0.000811978 (* 1 = 0.000811978 loss)
I0522 10:45:31.161974 19861 sgd_solver.cpp:112] Iteration 14540, lr = 0.001
I0522 10:45:32.185123 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:45:33.633121 19861 solver.cpp:239] Iteration 14560 (8.09325 iter/s, 2.47119s/20 iters), loss = 0.000762294
I0522 10:45:33.633509 19861 solver.cpp:258]     Train net output #0: loss = 0.000762226 (* 1 = 0.000762226 loss)
I0522 10:45:33.633523 19861 sgd_solver.cpp:112] Iteration 14560, lr = 0.001
I0522 10:45:36.008493 19861 solver.cpp:239] Iteration 14580 (8.42119 iter/s, 2.37496s/20 iters), loss = 0.000508264
I0522 10:45:36.008618 19861 solver.cpp:258]     Train net output #0: loss = 0.000508196 (* 1 = 0.000508196 loss)
I0522 10:45:36.008633 19861 sgd_solver.cpp:112] Iteration 14580, lr = 0.001
I0522 10:45:38.518646 19861 solver.cpp:239] Iteration 14600 (7.96808 iter/s, 2.51001s/20 iters), loss = 0.00140808
I0522 10:45:38.533231 19861 solver.cpp:258]     Train net output #0: loss = 0.00140802 (* 1 = 0.00140802 loss)
I0522 10:45:38.533241 19861 sgd_solver.cpp:112] Iteration 14600, lr = 0.001
I0522 10:45:40.661273 19861 solver.cpp:239] Iteration 14620 (9.3984 iter/s, 2.12802s/20 iters), loss = 0.000602423
I0522 10:45:40.661520 19861 solver.cpp:258]     Train net output #0: loss = 0.000602356 (* 1 = 0.000602356 loss)
I0522 10:45:40.661543 19861 sgd_solver.cpp:112] Iteration 14620, lr = 0.001
I0522 10:45:42.812623 19861 solver.cpp:239] Iteration 14640 (9.29759 iter/s, 2.1511s/20 iters), loss = 0.00124631
I0522 10:45:42.822086 19861 solver.cpp:258]     Train net output #0: loss = 0.00124624 (* 1 = 0.00124624 loss)
I0522 10:45:42.822093 19861 sgd_solver.cpp:112] Iteration 14640, lr = 0.001
I0522 10:45:45.110390 19861 solver.cpp:239] Iteration 14660 (8.74012 iter/s, 2.2883s/20 iters), loss = 0.000661134
I0522 10:45:45.110452 19861 solver.cpp:258]     Train net output #0: loss = 0.000661067 (* 1 = 0.000661067 loss)
I0522 10:45:45.110457 19861 sgd_solver.cpp:112] Iteration 14660, lr = 0.001
I0522 10:45:47.270046 19861 solver.cpp:239] Iteration 14680 (9.26106 iter/s, 2.15958s/20 iters), loss = 0.00280603
I0522 10:45:47.270131 19861 solver.cpp:258]     Train net output #0: loss = 0.00280597 (* 1 = 0.00280597 loss)
I0522 10:45:47.270136 19861 sgd_solver.cpp:112] Iteration 14680, lr = 0.001
I0522 10:45:49.396719 19861 solver.cpp:239] Iteration 14700 (9.40489 iter/s, 2.12655s/20 iters), loss = 0.00190091
I0522 10:45:49.396832 19861 solver.cpp:258]     Train net output #0: loss = 0.00190084 (* 1 = 0.00190084 loss)
I0522 10:45:49.396843 19861 sgd_solver.cpp:112] Iteration 14700, lr = 0.001
I0522 10:45:49.568226 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:45:51.533500 19861 solver.cpp:239] Iteration 14720 (9.36037 iter/s, 2.13667s/20 iters), loss = 0.00313549
I0522 10:45:51.542961 19861 solver.cpp:258]     Train net output #0: loss = 0.00313543 (* 1 = 0.00313543 loss)
I0522 10:45:51.542969 19861 sgd_solver.cpp:112] Iteration 14720, lr = 0.001
I0522 10:45:53.958343 19861 solver.cpp:239] Iteration 14740 (8.28027 iter/s, 2.41538s/20 iters), loss = 0.00327453
I0522 10:45:53.958392 19861 solver.cpp:258]     Train net output #0: loss = 0.00327446 (* 1 = 0.00327446 loss)
I0522 10:45:53.958397 19861 sgd_solver.cpp:112] Iteration 14740, lr = 0.001
I0522 10:45:56.076709 19861 solver.cpp:239] Iteration 14760 (9.4415 iter/s, 2.11831s/20 iters), loss = 0.00125904
I0522 10:45:56.076756 19861 solver.cpp:258]     Train net output #0: loss = 0.00125898 (* 1 = 0.00125898 loss)
I0522 10:45:56.076759 19861 sgd_solver.cpp:112] Iteration 14760, lr = 0.001
I0522 10:45:58.203147 19861 solver.cpp:239] Iteration 14780 (9.40566 iter/s, 2.12638s/20 iters), loss = 0.000340284
I0522 10:45:58.212229 19861 solver.cpp:258]     Train net output #0: loss = 0.000340217 (* 1 = 0.000340217 loss)
I0522 10:45:58.212235 19861 sgd_solver.cpp:112] Iteration 14780, lr = 0.001
I0522 10:46:00.652688 19861 solver.cpp:239] Iteration 14800 (8.19528 iter/s, 2.44043s/20 iters), loss = 0.00187927
I0522 10:46:00.652804 19861 solver.cpp:258]     Train net output #0: loss = 0.00187921 (* 1 = 0.00187921 loss)
I0522 10:46:00.652819 19861 sgd_solver.cpp:112] Iteration 14800, lr = 0.001
I0522 10:46:02.836879 19861 solver.cpp:239] Iteration 14820 (9.15721 iter/s, 2.18407s/20 iters), loss = 0.00102755
I0522 10:46:02.836933 19861 solver.cpp:258]     Train net output #0: loss = 0.00102748 (* 1 = 0.00102748 loss)
I0522 10:46:02.836995 19861 sgd_solver.cpp:112] Iteration 14820, lr = 0.001
I0522 10:46:05.023656 19861 solver.cpp:239] Iteration 14840 (9.14621 iter/s, 2.1867s/20 iters), loss = 0.00389563
I0522 10:46:05.024060 19861 solver.cpp:258]     Train net output #0: loss = 0.00389557 (* 1 = 0.00389557 loss)
I0522 10:46:05.024101 19861 sgd_solver.cpp:112] Iteration 14840, lr = 0.001
I0522 10:46:06.790808 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:46:07.375579 19861 solver.cpp:239] Iteration 14860 (8.50516 iter/s, 2.35151s/20 iters), loss = 0.00262016
I0522 10:46:07.375639 19861 solver.cpp:258]     Train net output #0: loss = 0.00262009 (* 1 = 0.00262009 loss)
I0522 10:46:07.375643 19861 sgd_solver.cpp:112] Iteration 14860, lr = 0.001
I0522 10:46:09.522563 19861 solver.cpp:239] Iteration 14880 (9.31594 iter/s, 2.14686s/20 iters), loss = 0.000586391
I0522 10:46:09.522697 19861 solver.cpp:258]     Train net output #0: loss = 0.000586325 (* 1 = 0.000586325 loss)
I0522 10:46:09.522711 19861 sgd_solver.cpp:112] Iteration 14880, lr = 0.001
I0522 10:46:11.703213 19861 solver.cpp:239] Iteration 14900 (9.1722 iter/s, 2.1805s/20 iters), loss = 0.00122984
I0522 10:46:11.703308 19861 solver.cpp:258]     Train net output #0: loss = 0.00122977 (* 1 = 0.00122977 loss)
I0522 10:46:11.703320 19861 sgd_solver.cpp:112] Iteration 14900, lr = 0.001
I0522 10:46:14.031453 19861 solver.cpp:239] Iteration 14920 (8.59061 iter/s, 2.32812s/20 iters), loss = 0.000662227
I0522 10:46:14.040554 19861 solver.cpp:258]     Train net output #0: loss = 0.000662161 (* 1 = 0.000662161 loss)
I0522 10:46:14.040565 19861 sgd_solver.cpp:112] Iteration 14920, lr = 0.001
I0522 10:46:16.157372 19861 solver.cpp:239] Iteration 14940 (9.44814 iter/s, 2.11682s/20 iters), loss = 0.00288126
I0522 10:46:16.167443 19861 solver.cpp:258]     Train net output #0: loss = 0.00288119 (* 1 = 0.00288119 loss)
I0522 10:46:16.167451 19861 sgd_solver.cpp:112] Iteration 14940, lr = 0.001
I0522 10:46:18.300377 19861 solver.cpp:239] Iteration 14960 (9.37676 iter/s, 2.13293s/20 iters), loss = 0.0019205
I0522 10:46:18.309463 19861 solver.cpp:258]     Train net output #0: loss = 0.00192043 (* 1 = 0.00192043 loss)
I0522 10:46:18.309470 19861 sgd_solver.cpp:112] Iteration 14960, lr = 0.001
I0522 10:46:20.444634 19861 solver.cpp:239] Iteration 14980 (9.36697 iter/s, 2.13516s/20 iters), loss = 0.00327044
I0522 10:46:20.444707 19861 solver.cpp:258]     Train net output #0: loss = 0.00327037 (* 1 = 0.00327037 loss)
I0522 10:46:20.444711 19861 sgd_solver.cpp:112] Iteration 14980, lr = 0.001
I0522 10:46:22.682000 19861 solver.cpp:347] Iteration 15000, Testing net (#0)
I0522 10:46:25.203855 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:46:26.598033 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:46:29.204530 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:46:33.308034 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:46:37.480221 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:46:38.821897 19861 solver.cpp:414]     Test net output #0: accuracy = 0.869242
I0522 10:46:38.821991 19861 solver.cpp:414]     Test net output #1: loss = 0.808133 (* 1 = 0.808133 loss)
I0522 10:46:38.920328 19861 solver.cpp:239] Iteration 15000 (1.0825 iter/s, 18.4757s/20 iters), loss = 0.00117251
I0522 10:46:38.922791 19861 solver.cpp:258]     Train net output #0: loss = 0.00117244 (* 1 = 0.00117244 loss)
I0522 10:46:38.922803 19861 sgd_solver.cpp:112] Iteration 15000, lr = 0.001
I0522 10:46:39.699817 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:46:41.035773 19861 solver.cpp:239] Iteration 15020 (9.46529 iter/s, 2.11298s/20 iters), loss = 0.00175013
I0522 10:46:41.035804 19861 solver.cpp:258]     Train net output #0: loss = 0.00175007 (* 1 = 0.00175007 loss)
I0522 10:46:41.035809 19861 sgd_solver.cpp:112] Iteration 15020, lr = 0.001
I0522 10:46:43.204584 19861 solver.cpp:239] Iteration 15040 (9.22179 iter/s, 2.16878s/20 iters), loss = 0.001313
I0522 10:46:43.204628 19861 solver.cpp:258]     Train net output #0: loss = 0.00131294 (* 1 = 0.00131294 loss)
I0522 10:46:43.204633 19861 sgd_solver.cpp:112] Iteration 15040, lr = 0.001
I0522 10:46:45.619670 19861 solver.cpp:239] Iteration 15060 (8.28149 iter/s, 2.41503s/20 iters), loss = 0.000711707
I0522 10:46:45.619722 19861 solver.cpp:258]     Train net output #0: loss = 0.00071164 (* 1 = 0.00071164 loss)
I0522 10:46:45.619727 19861 sgd_solver.cpp:112] Iteration 15060, lr = 0.001
I0522 10:46:47.780609 19861 solver.cpp:239] Iteration 15080 (9.25553 iter/s, 2.16087s/20 iters), loss = 0.000326643
I0522 10:46:47.780674 19861 solver.cpp:258]     Train net output #0: loss = 0.000326577 (* 1 = 0.000326577 loss)
I0522 10:46:47.780679 19861 sgd_solver.cpp:112] Iteration 15080, lr = 0.001
I0522 10:46:49.911895 19861 solver.cpp:239] Iteration 15100 (9.38436 iter/s, 2.13121s/20 iters), loss = 0.000362334
I0522 10:46:49.911972 19861 solver.cpp:258]     Train net output #0: loss = 0.000362268 (* 1 = 0.000362268 loss)
I0522 10:46:49.911978 19861 sgd_solver.cpp:112] Iteration 15100, lr = 0.001
I0522 10:46:52.206586 19861 solver.cpp:239] Iteration 15120 (8.71609 iter/s, 2.29461s/20 iters), loss = 0.000883381
I0522 10:46:52.218503 19861 solver.cpp:258]     Train net output #0: loss = 0.000883315 (* 1 = 0.000883315 loss)
I0522 10:46:52.218509 19861 sgd_solver.cpp:112] Iteration 15120, lr = 0.001
I0522 10:46:54.432169 19861 solver.cpp:239] Iteration 15140 (9.03482 iter/s, 2.21366s/20 iters), loss = 0.00112457
I0522 10:46:54.432219 19861 solver.cpp:258]     Train net output #0: loss = 0.0011245 (* 1 = 0.0011245 loss)
I0522 10:46:54.432222 19861 sgd_solver.cpp:112] Iteration 15140, lr = 0.001
I0522 10:46:56.603070 19861 solver.cpp:239] Iteration 15160 (9.21297 iter/s, 2.17085s/20 iters), loss = 0.00844713
I0522 10:46:56.603091 19861 solver.cpp:258]     Train net output #0: loss = 0.00844707 (* 1 = 0.00844707 loss)
I0522 10:46:56.603093 19861 sgd_solver.cpp:112] Iteration 15160, lr = 0.001
I0522 10:46:56.704883 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:46:58.771210 19861 solver.cpp:239] Iteration 15180 (9.22459 iter/s, 2.16812s/20 iters), loss = 0.000454786
I0522 10:46:58.771239 19861 solver.cpp:258]     Train net output #0: loss = 0.00045472 (* 1 = 0.00045472 loss)
I0522 10:46:58.771243 19861 sgd_solver.cpp:112] Iteration 15180, lr = 0.001
I0522 10:47:01.085485 19861 solver.cpp:239] Iteration 15200 (8.64218 iter/s, 2.31423s/20 iters), loss = 0.00064474
I0522 10:47:01.085541 19861 solver.cpp:258]     Train net output #0: loss = 0.000644674 (* 1 = 0.000644674 loss)
I0522 10:47:01.085547 19861 sgd_solver.cpp:112] Iteration 15200, lr = 0.001
I0522 10:47:03.290372 19861 solver.cpp:239] Iteration 15220 (9.07101 iter/s, 2.20483s/20 iters), loss = 0.000349299
I0522 10:47:03.290400 19861 solver.cpp:258]     Train net output #0: loss = 0.000349233 (* 1 = 0.000349233 loss)
I0522 10:47:03.290405 19861 sgd_solver.cpp:112] Iteration 15220, lr = 0.001
I0522 10:47:05.481555 19861 solver.cpp:239] Iteration 15240 (9.12761 iter/s, 2.19115s/20 iters), loss = 0.00117574
I0522 10:47:05.481631 19861 solver.cpp:258]     Train net output #0: loss = 0.00117568 (* 1 = 0.00117568 loss)
I0522 10:47:05.481635 19861 sgd_solver.cpp:112] Iteration 15240, lr = 0.001
I0522 10:47:07.937041 19861 solver.cpp:239] Iteration 15260 (8.14529 iter/s, 2.45541s/20 iters), loss = 0.000708915
I0522 10:47:07.950371 19861 solver.cpp:258]     Train net output #0: loss = 0.000708848 (* 1 = 0.000708848 loss)
I0522 10:47:07.950378 19861 sgd_solver.cpp:112] Iteration 15260, lr = 0.001
I0522 10:47:09.725879 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:47:10.101186 19861 solver.cpp:239] Iteration 15280 (9.29878 iter/s, 2.15082s/20 iters), loss = 0.0048334
I0522 10:47:10.101209 19861 solver.cpp:258]     Train net output #0: loss = 0.00483334 (* 1 = 0.00483334 loss)
I0522 10:47:10.101212 19861 sgd_solver.cpp:112] Iteration 15280, lr = 0.001
I0522 10:47:12.236660 19861 solver.cpp:239] Iteration 15300 (9.36577 iter/s, 2.13544s/20 iters), loss = 0.00322041
I0522 10:47:12.236805 19861 solver.cpp:258]     Train net output #0: loss = 0.00322035 (* 1 = 0.00322035 loss)
I0522 10:47:12.236814 19861 sgd_solver.cpp:112] Iteration 15300, lr = 0.001
I0522 10:47:13.822463 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:47:14.584945 19861 solver.cpp:239] Iteration 15320 (8.51743 iter/s, 2.34813s/20 iters), loss = 0.00041474
I0522 10:47:14.585003 19861 solver.cpp:258]     Train net output #0: loss = 0.000414675 (* 1 = 0.000414675 loss)
I0522 10:47:14.585007 19861 sgd_solver.cpp:112] Iteration 15320, lr = 0.001
I0522 10:47:16.724263 19861 solver.cpp:239] Iteration 15340 (9.3491 iter/s, 2.13924s/20 iters), loss = 0.000949529
I0522 10:47:16.738219 19861 solver.cpp:258]     Train net output #0: loss = 0.000949464 (* 1 = 0.000949464 loss)
I0522 10:47:16.738225 19861 sgd_solver.cpp:112] Iteration 15340, lr = 0.001
I0522 10:47:18.890573 19861 solver.cpp:239] Iteration 15360 (9.29214 iter/s, 2.15236s/20 iters), loss = 0.000266515
I0522 10:47:18.890614 19861 solver.cpp:258]     Train net output #0: loss = 0.00026645 (* 1 = 0.00026645 loss)
I0522 10:47:18.890619 19861 sgd_solver.cpp:112] Iteration 15360, lr = 0.001
I0522 10:47:21.040225 19861 solver.cpp:239] Iteration 15380 (9.3041 iter/s, 2.14959s/20 iters), loss = 0.00083942
I0522 10:47:21.040308 19861 solver.cpp:258]     Train net output #0: loss = 0.000839355 (* 1 = 0.000839355 loss)
I0522 10:47:21.040314 19861 sgd_solver.cpp:112] Iteration 15380, lr = 0.001
I0522 10:47:23.523727 19861 solver.cpp:239] Iteration 15400 (8.05343 iter/s, 2.48341s/20 iters), loss = 0.000452651
I0522 10:47:23.523777 19861 solver.cpp:258]     Train net output #0: loss = 0.000452585 (* 1 = 0.000452585 loss)
I0522 10:47:23.523779 19861 sgd_solver.cpp:112] Iteration 15400, lr = 0.001
I0522 10:47:25.670681 19861 solver.cpp:239] Iteration 15420 (9.31578 iter/s, 2.14689s/20 iters), loss = 0.00103127
I0522 10:47:25.670744 19861 solver.cpp:258]     Train net output #0: loss = 0.0010312 (* 1 = 0.0010312 loss)
I0522 10:47:25.670749 19861 sgd_solver.cpp:112] Iteration 15420, lr = 0.001
I0522 10:47:27.832471 19861 solver.cpp:239] Iteration 15440 (9.2519 iter/s, 2.16172s/20 iters), loss = 0.00171697
I0522 10:47:27.846105 19861 solver.cpp:258]     Train net output #0: loss = 0.0017169 (* 1 = 0.0017169 loss)
I0522 10:47:27.846112 19861 sgd_solver.cpp:112] Iteration 15440, lr = 0.001
I0522 10:47:30.166548 19861 solver.cpp:239] Iteration 15460 (8.61911 iter/s, 2.32043s/20 iters), loss = 0.00300634
I0522 10:47:30.166615 19861 solver.cpp:258]     Train net output #0: loss = 0.00300627 (* 1 = 0.00300627 loss)
I0522 10:47:30.166618 19861 sgd_solver.cpp:112] Iteration 15460, lr = 0.001
I0522 10:47:30.966038 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:47:32.328765 19861 solver.cpp:239] Iteration 15480 (9.25003 iter/s, 2.16215s/20 iters), loss = 0.00168101
I0522 10:47:32.328802 19861 solver.cpp:258]     Train net output #0: loss = 0.00168095 (* 1 = 0.00168095 loss)
I0522 10:47:32.328806 19861 sgd_solver.cpp:112] Iteration 15480, lr = 0.001
I0522 10:47:34.510290 19861 solver.cpp:239] Iteration 15500 (9.16807 iter/s, 2.18148s/20 iters), loss = 0.000525292
I0522 10:47:34.510319 19861 solver.cpp:258]     Train net output #0: loss = 0.000525224 (* 1 = 0.000525224 loss)
I0522 10:47:34.510324 19861 sgd_solver.cpp:112] Iteration 15500, lr = 0.001
I0522 10:47:37.046718 19861 solver.cpp:239] Iteration 15520 (7.88525 iter/s, 2.53638s/20 iters), loss = 0.000366104
I0522 10:47:37.060415 19861 solver.cpp:258]     Train net output #0: loss = 0.000366037 (* 1 = 0.000366037 loss)
I0522 10:47:37.060422 19861 sgd_solver.cpp:112] Iteration 15520, lr = 0.001
I0522 10:47:39.220918 19861 solver.cpp:239] Iteration 15540 (9.25709 iter/s, 2.16051s/20 iters), loss = 0.000339217
I0522 10:47:39.230015 19861 solver.cpp:258]     Train net output #0: loss = 0.00033915 (* 1 = 0.00033915 loss)
I0522 10:47:39.230022 19861 sgd_solver.cpp:112] Iteration 15540, lr = 0.001
I0522 10:47:41.385936 19861 solver.cpp:239] Iteration 15560 (9.27679 iter/s, 2.15592s/20 iters), loss = 0.000307914
I0522 10:47:41.385968 19861 solver.cpp:258]     Train net output #0: loss = 0.000307846 (* 1 = 0.000307846 loss)
I0522 10:47:41.385972 19861 sgd_solver.cpp:112] Iteration 15560, lr = 0.001
I0522 10:47:43.530484 19861 solver.cpp:239] Iteration 15580 (9.32614 iter/s, 2.14451s/20 iters), loss = 0.00911509
I0522 10:47:43.530519 19861 solver.cpp:258]     Train net output #0: loss = 0.00911502 (* 1 = 0.00911502 loss)
I0522 10:47:43.530524 19861 sgd_solver.cpp:112] Iteration 15580, lr = 0.001
I0522 10:47:46.023797 19861 solver.cpp:239] Iteration 15600 (8.0216 iter/s, 2.49327s/20 iters), loss = 0.00127571
I0522 10:47:46.023855 19861 solver.cpp:258]     Train net output #0: loss = 0.00127565 (* 1 = 0.00127565 loss)
I0522 10:47:46.023859 19861 sgd_solver.cpp:112] Iteration 15600, lr = 0.001
I0522 10:47:48.211804 19861 solver.cpp:239] Iteration 15620 (9.14096 iter/s, 2.18795s/20 iters), loss = 0.00391637
I0522 10:47:48.211832 19861 solver.cpp:258]     Train net output #0: loss = 0.0039163 (* 1 = 0.0039163 loss)
I0522 10:47:48.211835 19861 sgd_solver.cpp:112] Iteration 15620, lr = 0.001
I0522 10:47:48.286381 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:47:50.409374 19861 solver.cpp:239] Iteration 15640 (9.10107 iter/s, 2.19754s/20 iters), loss = 0.00259894
I0522 10:47:50.409412 19861 solver.cpp:258]     Train net output #0: loss = 0.00259887 (* 1 = 0.00259887 loss)
I0522 10:47:50.409417 19861 sgd_solver.cpp:112] Iteration 15640, lr = 0.001
I0522 10:47:52.812777 19861 solver.cpp:239] Iteration 15660 (8.32171 iter/s, 2.40335s/20 iters), loss = 0.000320001
I0522 10:47:52.812834 19861 solver.cpp:258]     Train net output #0: loss = 0.000319933 (* 1 = 0.000319933 loss)
I0522 10:47:52.812836 19861 sgd_solver.cpp:112] Iteration 15660, lr = 0.001
I0522 10:47:54.999938 19861 solver.cpp:239] Iteration 15680 (9.1445 iter/s, 2.18711s/20 iters), loss = 0.00119643
I0522 10:47:55.013767 19861 solver.cpp:258]     Train net output #0: loss = 0.00119636 (* 1 = 0.00119636 loss)
I0522 10:47:55.013775 19861 sgd_solver.cpp:112] Iteration 15680, lr = 0.001
I0522 10:47:57.184132 19861 solver.cpp:239] Iteration 15700 (9.21502 iter/s, 2.17037s/20 iters), loss = 0.00194606
I0522 10:47:57.184156 19861 solver.cpp:258]     Train net output #0: loss = 0.00194599 (* 1 = 0.00194599 loss)
I0522 10:47:57.184159 19861 sgd_solver.cpp:112] Iteration 15700, lr = 0.001
I0522 10:47:59.472524 19861 solver.cpp:239] Iteration 15720 (8.73992 iter/s, 2.28835s/20 iters), loss = 0.00134666
I0522 10:47:59.487874 19861 solver.cpp:258]     Train net output #0: loss = 0.00134659 (* 1 = 0.00134659 loss)
I0522 10:47:59.487882 19861 sgd_solver.cpp:112] Iteration 15720, lr = 0.001
I0522 10:48:01.790995 19861 solver.cpp:239] Iteration 15740 (8.68485 iter/s, 2.30286s/20 iters), loss = 0.00203706
I0522 10:48:01.791054 19861 solver.cpp:258]     Train net output #0: loss = 0.00203699 (* 1 = 0.00203699 loss)
I0522 10:48:01.791059 19861 sgd_solver.cpp:112] Iteration 15740, lr = 0.001
I0522 10:48:03.944384 19861 solver.cpp:239] Iteration 15760 (9.28801 iter/s, 2.15331s/20 iters), loss = 0.00308168
I0522 10:48:03.944453 19861 solver.cpp:258]     Train net output #0: loss = 0.00308161 (* 1 = 0.00308161 loss)
I0522 10:48:03.944458 19861 sgd_solver.cpp:112] Iteration 15760, lr = 0.001
I0522 10:48:05.433602 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:48:06.104666 19861 solver.cpp:239] Iteration 15780 (9.25834 iter/s, 2.16021s/20 iters), loss = 0.00038158
I0522 10:48:06.104696 19861 solver.cpp:258]     Train net output #0: loss = 0.000381507 (* 1 = 0.000381507 loss)
I0522 10:48:06.104699 19861 sgd_solver.cpp:112] Iteration 15780, lr = 0.001
I0522 10:48:08.557008 19861 solver.cpp:239] Iteration 15800 (8.15562 iter/s, 2.4523s/20 iters), loss = 0.000336163
I0522 10:48:08.557157 19861 solver.cpp:258]     Train net output #0: loss = 0.000336089 (* 1 = 0.000336089 loss)
I0522 10:48:08.557160 19861 sgd_solver.cpp:112] Iteration 15800, lr = 0.001
I0522 10:48:10.704241 19861 solver.cpp:239] Iteration 15820 (9.31498 iter/s, 2.14708s/20 iters), loss = 0.00109261
I0522 10:48:10.704442 19861 solver.cpp:258]     Train net output #0: loss = 0.00109254 (* 1 = 0.00109254 loss)
I0522 10:48:10.704447 19861 sgd_solver.cpp:112] Iteration 15820, lr = 0.001
I0522 10:48:12.864758 19861 solver.cpp:239] Iteration 15840 (9.25796 iter/s, 2.1603s/20 iters), loss = 0.00204921
I0522 10:48:12.864840 19861 solver.cpp:258]     Train net output #0: loss = 0.00204913 (* 1 = 0.00204913 loss)
I0522 10:48:12.864845 19861 sgd_solver.cpp:112] Iteration 15840, lr = 0.001
I0522 10:48:15.223028 19861 solver.cpp:239] Iteration 15860 (8.48111 iter/s, 2.35818s/20 iters), loss = 0.00136112
I0522 10:48:15.233445 19861 solver.cpp:258]     Train net output #0: loss = 0.00136105 (* 1 = 0.00136105 loss)
I0522 10:48:15.233451 19861 sgd_solver.cpp:112] Iteration 15860, lr = 0.001
I0522 10:48:17.410753 19861 solver.cpp:239] Iteration 15880 (9.18563 iter/s, 2.17731s/20 iters), loss = 0.000750476
I0522 10:48:17.410780 19861 solver.cpp:258]     Train net output #0: loss = 0.000750404 (* 1 = 0.000750404 loss)
I0522 10:48:17.410784 19861 sgd_solver.cpp:112] Iteration 15880, lr = 0.001
I0522 10:48:19.570142 19861 solver.cpp:239] Iteration 15900 (9.26199 iter/s, 2.15936s/20 iters), loss = 0.00104169
I0522 10:48:19.570168 19861 solver.cpp:258]     Train net output #0: loss = 0.00104162 (* 1 = 0.00104162 loss)
I0522 10:48:19.570173 19861 sgd_solver.cpp:112] Iteration 15900, lr = 0.001
I0522 10:48:21.731887 19861 solver.cpp:239] Iteration 15920 (9.25191 iter/s, 2.16172s/20 iters), loss = 0.000375804
I0522 10:48:21.731920 19861 solver.cpp:258]     Train net output #0: loss = 0.000375731 (* 1 = 0.000375731 loss)
I0522 10:48:21.731925 19861 sgd_solver.cpp:112] Iteration 15920, lr = 0.001
I0522 10:48:22.499716 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:48:24.206599 19861 solver.cpp:239] Iteration 15940 (8.0819 iter/s, 2.47467s/20 iters), loss = 0.000761352
I0522 10:48:24.218160 19861 solver.cpp:258]     Train net output #0: loss = 0.00076128 (* 1 = 0.00076128 loss)
I0522 10:48:24.218168 19861 sgd_solver.cpp:112] Iteration 15940, lr = 0.001
I0522 10:48:26.306869 19861 solver.cpp:239] Iteration 15960 (9.5753 iter/s, 2.08871s/20 iters), loss = 0.00201459
I0522 10:48:26.316355 19861 solver.cpp:258]     Train net output #0: loss = 0.00201452 (* 1 = 0.00201452 loss)
I0522 10:48:26.316362 19861 sgd_solver.cpp:112] Iteration 15960, lr = 0.001
I0522 10:48:28.358371 19861 solver.cpp:239] Iteration 15980 (9.79436 iter/s, 2.04199s/20 iters), loss = 0.000947577
I0522 10:48:28.367730 19861 solver.cpp:258]     Train net output #0: loss = 0.000947504 (* 1 = 0.000947504 loss)
I0522 10:48:28.367738 19861 sgd_solver.cpp:112] Iteration 15980, lr = 0.001
I0522 10:48:30.247857 19861 solver.cpp:347] Iteration 16000, Testing net (#0)
I0522 10:48:34.171214 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:48:36.656026 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:48:37.845625 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:48:41.524432 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:48:46.610883 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:48:47.715484 19861 solver.cpp:414]     Test net output #0: accuracy = 0.873962
I0522 10:48:47.715562 19861 solver.cpp:414]     Test net output #1: loss = 0.79535 (* 1 = 0.79535 loss)
I0522 10:48:47.812813 19861 solver.cpp:239] Iteration 16000 (1.02853 iter/s, 19.4452s/20 iters), loss = 0.00689627
I0522 10:48:47.815054 19861 solver.cpp:258]     Train net output #0: loss = 0.0068962 (* 1 = 0.0068962 loss)
I0522 10:48:47.815068 19861 sgd_solver.cpp:112] Iteration 16000, lr = 0.001
I0522 10:48:50.001487 19861 solver.cpp:239] Iteration 16020 (9.14738 iter/s, 2.18642s/20 iters), loss = 0.000473511
I0522 10:48:50.001549 19861 solver.cpp:258]     Train net output #0: loss = 0.000473439 (* 1 = 0.000473439 loss)
I0522 10:48:50.001552 19861 sgd_solver.cpp:112] Iteration 16020, lr = 0.001
I0522 10:48:52.178205 19861 solver.cpp:239] Iteration 16040 (9.1885 iter/s, 2.17663s/20 iters), loss = 0.000858384
I0522 10:48:52.189512 19861 solver.cpp:258]     Train net output #0: loss = 0.000858311 (* 1 = 0.000858311 loss)
I0522 10:48:52.189519 19861 sgd_solver.cpp:112] Iteration 16040, lr = 0.001
I0522 10:48:55.711733 19861 solver.cpp:239] Iteration 16060 (5.67823 iter/s, 3.52222s/20 iters), loss = 0.0183561
I0522 10:48:55.711776 19861 solver.cpp:258]     Train net output #0: loss = 0.018356 (* 1 = 0.018356 loss)
I0522 10:48:55.711779 19861 sgd_solver.cpp:112] Iteration 16060, lr = 0.001
I0522 10:48:57.797822 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:48:57.900048 19861 solver.cpp:239] Iteration 16080 (9.13974 iter/s, 2.18825s/20 iters), loss = 0.000643298
I0522 10:48:57.900177 19861 solver.cpp:258]     Train net output #0: loss = 0.000643224 (* 1 = 0.000643224 loss)
I0522 10:48:57.900182 19861 sgd_solver.cpp:112] Iteration 16080, lr = 0.001
I0522 10:48:59.999703 19861 solver.cpp:239] Iteration 16100 (9.526 iter/s, 2.09952s/20 iters), loss = 0.000230375
I0522 10:49:00.013207 19861 solver.cpp:258]     Train net output #0: loss = 0.000230301 (* 1 = 0.000230301 loss)
I0522 10:49:00.013221 19861 sgd_solver.cpp:112] Iteration 16100, lr = 0.001
I0522 10:49:02.046222 19861 solver.cpp:239] Iteration 16120 (9.83759 iter/s, 2.03302s/20 iters), loss = 0.000542552
I0522 10:49:02.055771 19861 solver.cpp:258]     Train net output #0: loss = 0.000542477 (* 1 = 0.000542477 loss)
I0522 10:49:02.055779 19861 sgd_solver.cpp:112] Iteration 16120, lr = 0.001
I0522 10:49:04.326390 19861 solver.cpp:239] Iteration 16140 (8.80829 iter/s, 2.27059s/20 iters), loss = 0.00215437
I0522 10:49:04.326480 19861 solver.cpp:258]     Train net output #0: loss = 0.0021543 (* 1 = 0.0021543 loss)
I0522 10:49:04.326485 19861 sgd_solver.cpp:112] Iteration 16140, lr = 0.001
I0522 10:49:07.657966 19861 solver.cpp:239] Iteration 16160 (6.0069 iter/s, 3.32951s/20 iters), loss = 0.000850242
I0522 10:49:07.667567 19861 solver.cpp:258]     Train net output #0: loss = 0.000850167 (* 1 = 0.000850167 loss)
I0522 10:49:07.667595 19861 sgd_solver.cpp:112] Iteration 16160, lr = 0.001
I0522 10:49:09.700361 19861 solver.cpp:239] Iteration 16180 (9.83871 iter/s, 2.03279s/20 iters), loss = 0.00135507
I0522 10:49:09.709940 19861 solver.cpp:258]     Train net output #0: loss = 0.00135499 (* 1 = 0.00135499 loss)
I0522 10:49:09.709950 19861 sgd_solver.cpp:112] Iteration 16180, lr = 0.001
I0522 10:49:11.741062 19861 solver.cpp:239] Iteration 16200 (9.84682 iter/s, 2.03111s/20 iters), loss = 0.00217543
I0522 10:49:11.750936 19861 solver.cpp:258]     Train net output #0: loss = 0.00217536 (* 1 = 0.00217536 loss)
I0522 10:49:11.750947 19861 sgd_solver.cpp:112] Iteration 16200, lr = 0.001
I0522 10:49:13.781635 19861 solver.cpp:239] Iteration 16220 (9.84889 iter/s, 2.03069s/20 iters), loss = 0.00148223
I0522 10:49:13.781719 19861 solver.cpp:258]     Train net output #0: loss = 0.00148215 (* 1 = 0.00148215 loss)
I0522 10:49:13.781724 19861 sgd_solver.cpp:112] Iteration 16220, lr = 0.001
I0522 10:49:15.448462 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:49:17.095441 19861 solver.cpp:239] Iteration 16240 (6.03552 iter/s, 3.31372s/20 iters), loss = 0.000448021
I0522 10:49:17.104943 19861 solver.cpp:258]     Train net output #0: loss = 0.000447946 (* 1 = 0.000447946 loss)
I0522 10:49:17.104951 19861 sgd_solver.cpp:112] Iteration 16240, lr = 0.001
I0522 10:49:19.499621 19861 solver.cpp:239] Iteration 16260 (8.35192 iter/s, 2.39466s/20 iters), loss = 0.000520317
I0522 10:49:19.509160 19861 solver.cpp:258]     Train net output #0: loss = 0.000520242 (* 1 = 0.000520242 loss)
I0522 10:49:19.509168 19861 sgd_solver.cpp:112] Iteration 16260, lr = 0.001
I0522 10:49:21.559139 19861 solver.cpp:239] Iteration 16280 (9.75624 iter/s, 2.04997s/20 iters), loss = 0.000715796
I0522 10:49:21.568589 19861 solver.cpp:258]     Train net output #0: loss = 0.00071572 (* 1 = 0.00071572 loss)
I0522 10:49:21.568598 19861 sgd_solver.cpp:112] Iteration 16280, lr = 0.001
I0522 10:49:23.611215 19861 solver.cpp:239] Iteration 16300 (9.79152 iter/s, 2.04258s/20 iters), loss = 0.00281241
I0522 10:49:23.611398 19861 solver.cpp:258]     Train net output #0: loss = 0.00281233 (* 1 = 0.00281233 loss)
I0522 10:49:23.611410 19861 sgd_solver.cpp:112] Iteration 16300, lr = 0.001
I0522 10:49:25.659577 19861 solver.cpp:239] Iteration 16320 (9.76486 iter/s, 2.04816s/20 iters), loss = 0.000277065
I0522 10:49:25.671149 19861 solver.cpp:258]     Train net output #0: loss = 0.00027699 (* 1 = 0.00027699 loss)
I0522 10:49:25.671161 19861 sgd_solver.cpp:112] Iteration 16320, lr = 0.001
I0522 10:49:29.320485 19861 solver.cpp:239] Iteration 16340 (5.48043 iter/s, 3.64935s/20 iters), loss = 0.000811416
I0522 10:49:29.329964 19861 solver.cpp:258]     Train net output #0: loss = 0.00081134 (* 1 = 0.00081134 loss)
I0522 10:49:29.329972 19861 sgd_solver.cpp:112] Iteration 16340, lr = 0.001
I0522 10:49:31.373104 19861 solver.cpp:239] Iteration 16360 (9.78893 iter/s, 2.04312s/20 iters), loss = 0.000608271
I0522 10:49:31.382654 19861 solver.cpp:258]     Train net output #0: loss = 0.000608196 (* 1 = 0.000608196 loss)
I0522 10:49:31.382663 19861 sgd_solver.cpp:112] Iteration 16360, lr = 0.001
I0522 10:49:33.439414 19861 solver.cpp:239] Iteration 16380 (9.72407 iter/s, 2.05675s/20 iters), loss = 0.00104617
I0522 10:49:33.448952 19861 solver.cpp:258]     Train net output #0: loss = 0.00104609 (* 1 = 0.00104609 loss)
I0522 10:49:33.448961 19861 sgd_solver.cpp:112] Iteration 16380, lr = 0.001
I0522 10:49:34.093099 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:49:35.496552 19861 solver.cpp:239] Iteration 16400 (9.76764 iter/s, 2.04758s/20 iters), loss = 0.00431815
I0522 10:49:35.505934 19861 solver.cpp:258]     Train net output #0: loss = 0.00431807 (* 1 = 0.00431807 loss)
I0522 10:49:35.505942 19861 sgd_solver.cpp:112] Iteration 16400, lr = 0.001
I0522 10:49:37.981885 19861 solver.cpp:239] Iteration 16420 (8.07771 iter/s, 2.47595s/20 iters), loss = 0.00106697
I0522 10:49:37.994760 19861 solver.cpp:258]     Train net output #0: loss = 0.0010669 (* 1 = 0.0010669 loss)
I0522 10:49:37.994768 19861 sgd_solver.cpp:112] Iteration 16420, lr = 0.001
I0522 10:49:41.162674 19861 solver.cpp:239] Iteration 16440 (6.31331 iter/s, 3.16791s/20 iters), loss = 0.000525192
I0522 10:49:41.172186 19861 solver.cpp:258]     Train net output #0: loss = 0.000525116 (* 1 = 0.000525116 loss)
I0522 10:49:41.172194 19861 sgd_solver.cpp:112] Iteration 16440, lr = 0.001
I0522 10:49:43.214591 19861 solver.cpp:239] Iteration 16460 (9.79244 iter/s, 2.04239s/20 iters), loss = 0.000489745
I0522 10:49:43.224061 19861 solver.cpp:258]     Train net output #0: loss = 0.00048967 (* 1 = 0.00048967 loss)
I0522 10:49:43.224069 19861 sgd_solver.cpp:112] Iteration 16460, lr = 0.001
I0522 10:49:45.264901 19861 solver.cpp:239] Iteration 16480 (9.79995 iter/s, 2.04083s/20 iters), loss = 0.00153446
I0522 10:49:45.265015 19861 solver.cpp:258]     Train net output #0: loss = 0.00153438 (* 1 = 0.00153438 loss)
I0522 10:49:45.265020 19861 sgd_solver.cpp:112] Iteration 16480, lr = 0.001
I0522 10:49:45.512986 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:49:47.313602 19861 solver.cpp:239] Iteration 16500 (9.76288 iter/s, 2.04858s/20 iters), loss = 0.002004
I0522 10:49:47.322966 19861 solver.cpp:258]     Train net output #0: loss = 0.00200393 (* 1 = 0.00200393 loss)
I0522 10:49:47.322975 19861 sgd_solver.cpp:112] Iteration 16500, lr = 0.001
I0522 10:49:50.049088 19861 solver.cpp:239] Iteration 16520 (7.33643 iter/s, 2.72612s/20 iters), loss = 0.00058642
I0522 10:49:50.058706 19861 solver.cpp:258]     Train net output #0: loss = 0.000586345 (* 1 = 0.000586345 loss)
I0522 10:49:50.058714 19861 sgd_solver.cpp:112] Iteration 16520, lr = 0.001
I0522 10:49:52.924238 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:49:52.976680 19861 solver.cpp:239] Iteration 16540 (6.85409 iter/s, 2.91797s/20 iters), loss = 0.000432918
I0522 10:49:52.986198 19861 solver.cpp:258]     Train net output #0: loss = 0.000432843 (* 1 = 0.000432843 loss)
I0522 10:49:52.986219 19861 sgd_solver.cpp:112] Iteration 16540, lr = 0.001
I0522 10:49:55.025207 19861 solver.cpp:239] Iteration 16560 (9.80873 iter/s, 2.039s/20 iters), loss = 0.00141428
I0522 10:49:55.034749 19861 solver.cpp:258]     Train net output #0: loss = 0.00141421 (* 1 = 0.00141421 loss)
I0522 10:49:55.034761 19861 sgd_solver.cpp:112] Iteration 16560, lr = 0.001
I0522 10:49:57.079991 19861 solver.cpp:239] Iteration 16580 (9.77881 iter/s, 2.04524s/20 iters), loss = 0.015306
I0522 10:49:57.089545 19861 solver.cpp:258]     Train net output #0: loss = 0.0153059 (* 1 = 0.0153059 loss)
I0522 10:49:57.089560 19861 sgd_solver.cpp:112] Iteration 16580, lr = 0.001
I0522 10:49:59.144857 19861 solver.cpp:239] Iteration 16600 (9.73095 iter/s, 2.0553s/20 iters), loss = 0.00108394
I0522 10:49:59.156253 19861 solver.cpp:258]     Train net output #0: loss = 0.00108386 (* 1 = 0.00108386 loss)
I0522 10:49:59.156266 19861 sgd_solver.cpp:112] Iteration 16600, lr = 0.001
I0522 10:50:02.785251 19861 solver.cpp:239] Iteration 16620 (5.51115 iter/s, 3.62901s/20 iters), loss = 0.00788749
I0522 10:50:02.785300 19861 solver.cpp:258]     Train net output #0: loss = 0.00788741 (* 1 = 0.00788741 loss)
I0522 10:50:02.785305 19861 sgd_solver.cpp:112] Iteration 16620, lr = 0.001
I0522 10:50:04.988598 19861 solver.cpp:239] Iteration 16640 (9.07731 iter/s, 2.2033s/20 iters), loss = 0.00245556
I0522 10:50:04.988638 19861 solver.cpp:258]     Train net output #0: loss = 0.00245548 (* 1 = 0.00245548 loss)
I0522 10:50:04.988642 19861 sgd_solver.cpp:112] Iteration 16640, lr = 0.001
I0522 10:50:07.044188 19861 solver.cpp:239] Iteration 16660 (9.72979 iter/s, 2.05554s/20 iters), loss = 0.000639707
I0522 10:50:07.053658 19861 solver.cpp:258]     Train net output #0: loss = 0.000639633 (* 1 = 0.000639633 loss)
I0522 10:50:07.053668 19861 sgd_solver.cpp:112] Iteration 16660, lr = 0.001
I0522 10:50:09.103890 19861 solver.cpp:239] Iteration 16680 (9.75507 iter/s, 2.05022s/20 iters), loss = 0.000281557
I0522 10:50:09.113348 19861 solver.cpp:258]     Train net output #0: loss = 0.000281483 (* 1 = 0.000281483 loss)
I0522 10:50:09.113356 19861 sgd_solver.cpp:112] Iteration 16680, lr = 0.001
I0522 10:50:10.422976 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:50:11.733947 19861 solver.cpp:239] Iteration 16700 (7.63185 iter/s, 2.6206s/20 iters), loss = 0.00308856
I0522 10:50:11.744228 19861 solver.cpp:258]     Train net output #0: loss = 0.00308848 (* 1 = 0.00308848 loss)
I0522 10:50:11.744237 19861 sgd_solver.cpp:112] Iteration 16700, lr = 0.001
I0522 10:50:14.765971 19861 solver.cpp:239] Iteration 16720 (6.61873 iter/s, 3.02173s/20 iters), loss = 0.000895074
I0522 10:50:14.775555 19861 solver.cpp:258]     Train net output #0: loss = 0.000894999 (* 1 = 0.000894999 loss)
I0522 10:50:14.775564 19861 sgd_solver.cpp:112] Iteration 16720, lr = 0.001
I0522 10:50:16.810947 19861 solver.cpp:239] Iteration 16740 (9.82618 iter/s, 2.03538s/20 iters), loss = 0.000861599
I0522 10:50:16.811025 19861 solver.cpp:258]     Train net output #0: loss = 0.000861524 (* 1 = 0.000861524 loss)
I0522 10:50:16.811031 19861 sgd_solver.cpp:112] Iteration 16740, lr = 0.001
I0522 10:50:18.855643 19861 solver.cpp:239] Iteration 16760 (9.78188 iter/s, 2.0446s/20 iters), loss = 0.0037646
I0522 10:50:18.865070 19861 solver.cpp:258]     Train net output #0: loss = 0.00376452 (* 1 = 0.00376452 loss)
I0522 10:50:18.865079 19861 sgd_solver.cpp:112] Iteration 16760, lr = 0.001
I0522 10:50:20.903662 19861 solver.cpp:239] Iteration 16780 (9.81074 iter/s, 2.03858s/20 iters), loss = 0.00491634
I0522 10:50:20.913095 19861 solver.cpp:258]     Train net output #0: loss = 0.00491627 (* 1 = 0.00491627 loss)
I0522 10:50:20.913106 19861 sgd_solver.cpp:112] Iteration 16780, lr = 0.001
I0522 10:50:24.108881 19861 solver.cpp:239] Iteration 16800 (6.25823 iter/s, 3.19579s/20 iters), loss = 0.000738872
I0522 10:50:24.118129 19861 solver.cpp:258]     Train net output #0: loss = 0.000738796 (* 1 = 0.000738796 loss)
I0522 10:50:24.118135 19861 sgd_solver.cpp:112] Iteration 16800, lr = 0.001
I0522 10:50:26.628639 19861 solver.cpp:239] Iteration 16820 (7.96668 iter/s, 2.51046s/20 iters), loss = 0.00515862
I0522 10:50:26.638123 19861 solver.cpp:258]     Train net output #0: loss = 0.00515854 (* 1 = 0.00515854 loss)
I0522 10:50:26.638132 19861 sgd_solver.cpp:112] Iteration 16820, lr = 0.001
I0522 10:50:28.684300 19861 solver.cpp:239] Iteration 16840 (9.77432 iter/s, 2.04618s/20 iters), loss = 0.00122511
I0522 10:50:28.693770 19861 solver.cpp:258]     Train net output #0: loss = 0.00122503 (* 1 = 0.00122503 loss)
I0522 10:50:28.693780 19861 sgd_solver.cpp:112] Iteration 16840, lr = 0.001
I0522 10:50:29.261155 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:50:30.734794 19861 solver.cpp:239] Iteration 16860 (9.7991 iter/s, 2.041s/20 iters), loss = 0.00207447
I0522 10:50:30.734871 19861 solver.cpp:258]     Train net output #0: loss = 0.00207439 (* 1 = 0.00207439 loss)
I0522 10:50:30.734875 19861 sgd_solver.cpp:112] Iteration 16860, lr = 0.001
I0522 10:50:32.777856 19861 solver.cpp:239] Iteration 16880 (9.78966 iter/s, 2.04297s/20 iters), loss = 0.00131664
I0522 10:50:32.787442 19861 solver.cpp:258]     Train net output #0: loss = 0.00131656 (* 1 = 0.00131656 loss)
I0522 10:50:32.787451 19861 sgd_solver.cpp:112] Iteration 16880, lr = 0.001
I0522 10:50:36.397964 19861 solver.cpp:239] Iteration 16900 (5.53939 iter/s, 3.61051s/20 iters), loss = 0.000872578
I0522 10:50:36.398049 19861 solver.cpp:258]     Train net output #0: loss = 0.000872502 (* 1 = 0.000872502 loss)
I0522 10:50:36.398053 19861 sgd_solver.cpp:112] Iteration 16900, lr = 0.001
I0522 10:50:38.473069 19861 solver.cpp:239] Iteration 16920 (9.63853 iter/s, 2.07501s/20 iters), loss = 0.000931922
I0522 10:50:38.482620 19861 solver.cpp:258]     Train net output #0: loss = 0.000931846 (* 1 = 0.000931846 loss)
I0522 10:50:38.482630 19861 sgd_solver.cpp:112] Iteration 16920, lr = 0.001
I0522 10:50:40.521764 19861 solver.cpp:239] Iteration 16940 (9.80807 iter/s, 2.03914s/20 iters), loss = 0.00077217
I0522 10:50:40.531358 19861 solver.cpp:258]     Train net output #0: loss = 0.000772095 (* 1 = 0.000772095 loss)
I0522 10:50:40.531368 19861 sgd_solver.cpp:112] Iteration 16940, lr = 0.001
I0522 10:50:42.570783 19861 solver.cpp:239] Iteration 16960 (9.80672 iter/s, 2.03942s/20 iters), loss = 0.000925193
I0522 10:50:42.580392 19861 solver.cpp:258]     Train net output #0: loss = 0.000925118 (* 1 = 0.000925118 loss)
I0522 10:50:42.580402 19861 sgd_solver.cpp:112] Iteration 16960, lr = 0.001
I0522 10:50:45.454515 19861 solver.cpp:239] Iteration 16980 (6.95864 iter/s, 2.87412s/20 iters), loss = 0.000429945
I0522 10:50:45.463939 19861 solver.cpp:258]     Train net output #0: loss = 0.000429869 (* 1 = 0.000429869 loss)
I0522 10:50:45.463946 19861 sgd_solver.cpp:112] Iteration 16980, lr = 0.001
I0522 10:50:48.043267 19861 solver.cpp:347] Iteration 17000, Testing net (#0)
I0522 10:50:48.076687 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:50:51.280254 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:50:56.039239 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:50:58.229650 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:50:59.621271 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:51:03.231891 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:51:04.177297 19861 solver.cpp:414]     Test net output #0: accuracy = 0.870522
I0522 10:51:04.177336 19861 solver.cpp:414]     Test net output #1: loss = 0.807619 (* 1 = 0.807619 loss)
I0522 10:51:04.273762 19861 solver.cpp:239] Iteration 17000 (1.06327 iter/s, 18.8099s/20 iters), loss = 0.00433155
I0522 10:51:04.275629 19861 solver.cpp:258]     Train net output #0: loss = 0.00433148 (* 1 = 0.00433148 loss)
I0522 10:51:04.275638 19861 sgd_solver.cpp:112] Iteration 17000, lr = 0.001
I0522 10:51:06.327262 19861 solver.cpp:239] Iteration 17020 (9.74834 iter/s, 2.05163s/20 iters), loss = 0.00229153
I0522 10:51:06.336472 19861 solver.cpp:258]     Train net output #0: loss = 0.00229145 (* 1 = 0.00229145 loss)
I0522 10:51:06.336479 19861 sgd_solver.cpp:112] Iteration 17020, lr = 0.001
I0522 10:51:08.371752 19861 solver.cpp:239] Iteration 17040 (9.82668 iter/s, 2.03527s/20 iters), loss = 0.000936433
I0522 10:51:08.381009 19861 solver.cpp:258]     Train net output #0: loss = 0.000936358 (* 1 = 0.000936358 loss)
I0522 10:51:08.381018 19861 sgd_solver.cpp:112] Iteration 17040, lr = 0.001
I0522 10:51:10.408375 19861 solver.cpp:239] Iteration 17060 (9.86505 iter/s, 2.02736s/20 iters), loss = 0.000757591
I0522 10:51:10.417764 19861 solver.cpp:258]     Train net output #0: loss = 0.000757516 (* 1 = 0.000757516 loss)
I0522 10:51:10.417773 19861 sgd_solver.cpp:112] Iteration 17060, lr = 0.001
I0522 10:51:12.444733 19861 solver.cpp:239] Iteration 17080 (9.86696 iter/s, 2.02697s/20 iters), loss = 0.000507614
I0522 10:51:12.453832 19861 solver.cpp:258]     Train net output #0: loss = 0.000507539 (* 1 = 0.000507539 loss)
I0522 10:51:12.453840 19861 sgd_solver.cpp:112] Iteration 17080, lr = 0.001
I0522 10:51:14.473515 19861 solver.cpp:239] Iteration 17100 (9.90256 iter/s, 2.01968s/20 iters), loss = 0.00153673
I0522 10:51:14.482637 19861 solver.cpp:258]     Train net output #0: loss = 0.00153666 (* 1 = 0.00153666 loss)
I0522 10:51:14.482645 19861 sgd_solver.cpp:112] Iteration 17100, lr = 0.001
I0522 10:51:16.505600 19861 solver.cpp:239] Iteration 17120 (9.88649 iter/s, 2.02296s/20 iters), loss = 0.000595881
I0522 10:51:16.514803 19861 solver.cpp:258]     Train net output #0: loss = 0.000595806 (* 1 = 0.000595806 loss)
I0522 10:51:16.514811 19861 sgd_solver.cpp:112] Iteration 17120, lr = 0.001
I0522 10:51:18.548413 19861 solver.cpp:239] Iteration 17140 (9.83473 iter/s, 2.03361s/20 iters), loss = 0.00164082
I0522 10:51:18.558029 19861 solver.cpp:258]     Train net output #0: loss = 0.00164074 (* 1 = 0.00164074 loss)
I0522 10:51:18.558035 19861 sgd_solver.cpp:112] Iteration 17140, lr = 0.001
I0522 10:51:19.761504 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:51:20.599426 19861 solver.cpp:239] Iteration 17160 (9.79722 iter/s, 2.0414s/20 iters), loss = 0.00174501
I0522 10:51:20.608505 19861 solver.cpp:258]     Train net output #0: loss = 0.00174493 (* 1 = 0.00174493 loss)
I0522 10:51:20.608511 19861 sgd_solver.cpp:112] Iteration 17160, lr = 0.001
I0522 10:51:22.672399 19861 solver.cpp:239] Iteration 17180 (9.69044 iter/s, 2.06389s/20 iters), loss = 0.00110491
I0522 10:51:22.681524 19861 solver.cpp:258]     Train net output #0: loss = 0.00110483 (* 1 = 0.00110483 loss)
I0522 10:51:22.681533 19861 sgd_solver.cpp:112] Iteration 17180, lr = 0.001
I0522 10:51:25.110719 19861 solver.cpp:239] Iteration 17200 (8.23324 iter/s, 2.42918s/20 iters), loss = 0.000660393
I0522 10:51:25.110810 19861 solver.cpp:258]     Train net output #0: loss = 0.00066032 (* 1 = 0.00066032 loss)
I0522 10:51:25.110813 19861 sgd_solver.cpp:112] Iteration 17200, lr = 0.001
I0522 10:51:27.184790 19861 solver.cpp:239] Iteration 17220 (9.64328 iter/s, 2.07398s/20 iters), loss = 0.00124028
I0522 10:51:27.195315 19861 solver.cpp:258]     Train net output #0: loss = 0.00124021 (* 1 = 0.00124021 loss)
I0522 10:51:27.195322 19861 sgd_solver.cpp:112] Iteration 17220, lr = 0.001
I0522 10:51:29.246732 19861 solver.cpp:239] Iteration 17240 (9.74939 iter/s, 2.05141s/20 iters), loss = 0.000502188
I0522 10:51:29.256500 19861 solver.cpp:258]     Train net output #0: loss = 0.000502114 (* 1 = 0.000502114 loss)
I0522 10:51:29.256507 19861 sgd_solver.cpp:112] Iteration 17240, lr = 0.001
I0522 10:51:31.328599 19861 solver.cpp:239] Iteration 17260 (9.65215 iter/s, 2.07208s/20 iters), loss = 0.00097759
I0522 10:51:31.328685 19861 solver.cpp:258]     Train net output #0: loss = 0.000977515 (* 1 = 0.000977515 loss)
I0522 10:51:31.328688 19861 sgd_solver.cpp:112] Iteration 17260, lr = 0.001
I0522 10:51:33.402096 19861 solver.cpp:239] Iteration 17280 (9.64598 iter/s, 2.0734s/20 iters), loss = 0.000310151
I0522 10:51:33.412570 19861 solver.cpp:258]     Train net output #0: loss = 0.000310076 (* 1 = 0.000310076 loss)
I0522 10:51:33.412578 19861 sgd_solver.cpp:112] Iteration 17280, lr = 0.001
I0522 10:51:35.499110 19861 solver.cpp:239] Iteration 17300 (9.58533 iter/s, 2.08652s/20 iters), loss = 0.00236183
I0522 10:51:35.499202 19861 solver.cpp:258]     Train net output #0: loss = 0.00236176 (* 1 = 0.00236176 loss)
I0522 10:51:35.499207 19861 sgd_solver.cpp:112] Iteration 17300, lr = 0.001
I0522 10:51:36.165577 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:51:37.905373 19861 solver.cpp:239] Iteration 17320 (8.31198 iter/s, 2.40617s/20 iters), loss = 0.00103787
I0522 10:51:37.914441 19861 solver.cpp:258]     Train net output #0: loss = 0.00103779 (* 1 = 0.00103779 loss)
I0522 10:51:37.914448 19861 sgd_solver.cpp:112] Iteration 17320, lr = 0.001
I0522 10:51:40.052737 19861 solver.cpp:239] Iteration 17340 (9.35358 iter/s, 2.13822s/20 iters), loss = 0.00155623
I0522 10:51:40.052909 19861 solver.cpp:258]     Train net output #0: loss = 0.00155616 (* 1 = 0.00155616 loss)
I0522 10:51:40.052930 19861 sgd_solver.cpp:112] Iteration 17340, lr = 0.001
I0522 10:51:42.190801 19861 solver.cpp:239] Iteration 17360 (9.35508 iter/s, 2.13787s/20 iters), loss = 0.000256061
I0522 10:51:42.190894 19861 solver.cpp:258]     Train net output #0: loss = 0.000255987 (* 1 = 0.000255987 loss)
I0522 10:51:42.190902 19861 sgd_solver.cpp:112] Iteration 17360, lr = 0.001
I0522 10:51:44.351011 19861 solver.cpp:239] Iteration 17380 (9.25881 iter/s, 2.1601s/20 iters), loss = 0.000306968
I0522 10:51:44.351138 19861 solver.cpp:258]     Train net output #0: loss = 0.000306894 (* 1 = 0.000306894 loss)
I0522 10:51:44.351143 19861 sgd_solver.cpp:112] Iteration 17380, lr = 0.001
I0522 10:51:46.833467 19861 solver.cpp:239] Iteration 17400 (8.05699 iter/s, 2.48232s/20 iters), loss = 0.00242209
I0522 10:51:46.833719 19861 solver.cpp:258]     Train net output #0: loss = 0.00242202 (* 1 = 0.00242202 loss)
I0522 10:51:46.833724 19861 sgd_solver.cpp:112] Iteration 17400, lr = 0.001
I0522 10:51:49.055438 19861 solver.cpp:239] Iteration 17420 (9.00202 iter/s, 2.22172s/20 iters), loss = 0.000944189
I0522 10:51:49.055476 19861 solver.cpp:258]     Train net output #0: loss = 0.000944114 (* 1 = 0.000944114 loss)
I0522 10:51:49.055481 19861 sgd_solver.cpp:112] Iteration 17420, lr = 0.001
I0522 10:51:51.281469 19861 solver.cpp:239] Iteration 17440 (8.98475 iter/s, 2.22599s/20 iters), loss = 0.000241715
I0522 10:51:51.294409 19861 solver.cpp:258]     Train net output #0: loss = 0.000241641 (* 1 = 0.000241641 loss)
I0522 10:51:51.294416 19861 sgd_solver.cpp:112] Iteration 17440, lr = 0.001
I0522 10:51:53.585254 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:51:53.842708 19861 solver.cpp:239] Iteration 17460 (7.84837 iter/s, 2.5483s/20 iters), loss = 0.00167846
I0522 10:51:53.842754 19861 solver.cpp:258]     Train net output #0: loss = 0.00167839 (* 1 = 0.00167839 loss)
I0522 10:51:53.842759 19861 sgd_solver.cpp:112] Iteration 17460, lr = 0.001
I0522 10:51:56.050489 19861 solver.cpp:239] Iteration 17480 (9.05906 iter/s, 2.20773s/20 iters), loss = 0.0020562
I0522 10:51:56.050527 19861 solver.cpp:258]     Train net output #0: loss = 0.00205613 (* 1 = 0.00205613 loss)
I0522 10:51:56.050532 19861 sgd_solver.cpp:112] Iteration 17480, lr = 0.001
I0522 10:51:58.217770 19861 solver.cpp:239] Iteration 17500 (9.22842 iter/s, 2.16722s/20 iters), loss = 0.00105616
I0522 10:51:58.230819 19861 solver.cpp:258]     Train net output #0: loss = 0.00105609 (* 1 = 0.00105609 loss)
I0522 10:51:58.230834 19861 sgd_solver.cpp:112] Iteration 17500, lr = 0.001
I0522 10:52:00.651327 19861 solver.cpp:239] Iteration 17520 (8.26276 iter/s, 2.4205s/20 iters), loss = 0.00105811
I0522 10:52:00.664695 19861 solver.cpp:258]     Train net output #0: loss = 0.00105803 (* 1 = 0.00105803 loss)
I0522 10:52:00.664702 19861 sgd_solver.cpp:112] Iteration 17520, lr = 0.001
I0522 10:52:03.036830 19861 solver.cpp:239] Iteration 17540 (8.43124 iter/s, 2.37213s/20 iters), loss = 0.00065908
I0522 10:52:03.036880 19861 solver.cpp:258]     Train net output #0: loss = 0.000659005 (* 1 = 0.000659005 loss)
I0522 10:52:03.036885 19861 sgd_solver.cpp:112] Iteration 17540, lr = 0.001
I0522 10:52:05.211566 19861 solver.cpp:239] Iteration 17560 (9.19676 iter/s, 2.17468s/20 iters), loss = 0.00181293
I0522 10:52:05.211622 19861 solver.cpp:258]     Train net output #0: loss = 0.00181285 (* 1 = 0.00181285 loss)
I0522 10:52:05.211627 19861 sgd_solver.cpp:112] Iteration 17560, lr = 0.001
I0522 10:52:07.442438 19861 solver.cpp:239] Iteration 17580 (8.96535 iter/s, 2.23081s/20 iters), loss = 0.000493373
I0522 10:52:07.442487 19861 solver.cpp:258]     Train net output #0: loss = 0.000493297 (* 1 = 0.000493297 loss)
I0522 10:52:07.442490 19861 sgd_solver.cpp:112] Iteration 17580, lr = 0.001
I0522 10:52:09.994654 19861 solver.cpp:239] Iteration 17600 (7.83649 iter/s, 2.55216s/20 iters), loss = 0.00420372
I0522 10:52:09.994704 19861 solver.cpp:258]     Train net output #0: loss = 0.00420365 (* 1 = 0.00420365 loss)
I0522 10:52:09.994709 19861 sgd_solver.cpp:112] Iteration 17600, lr = 0.001
I0522 10:52:11.266013 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:52:12.201391 19861 solver.cpp:239] Iteration 17620 (9.06339 iter/s, 2.20668s/20 iters), loss = 0.000656657
I0522 10:52:12.210731 19861 solver.cpp:258]     Train net output #0: loss = 0.000656581 (* 1 = 0.000656581 loss)
I0522 10:52:12.210738 19861 sgd_solver.cpp:112] Iteration 17620, lr = 0.001
I0522 10:52:12.782380 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:52:14.380259 19861 solver.cpp:239] Iteration 17640 (9.21869 iter/s, 2.16951s/20 iters), loss = 0.000430402
I0522 10:52:14.380362 19861 solver.cpp:258]     Train net output #0: loss = 0.000430326 (* 1 = 0.000430326 loss)
I0522 10:52:14.380367 19861 sgd_solver.cpp:112] Iteration 17640, lr = 0.001
I0522 10:52:16.888111 19861 solver.cpp:239] Iteration 17660 (7.97529 iter/s, 2.50775s/20 iters), loss = 0.00272638
I0522 10:52:16.888386 19861 solver.cpp:258]     Train net output #0: loss = 0.00272631 (* 1 = 0.00272631 loss)
I0522 10:52:16.888391 19861 sgd_solver.cpp:112] Iteration 17660, lr = 0.001
I0522 10:52:19.155388 19861 solver.cpp:239] Iteration 17680 (8.82223 iter/s, 2.267s/20 iters), loss = 0.000997337
I0522 10:52:19.155422 19861 solver.cpp:258]     Train net output #0: loss = 0.000997261 (* 1 = 0.000997261 loss)
I0522 10:52:19.155428 19861 sgd_solver.cpp:112] Iteration 17680, lr = 0.001
I0522 10:52:21.334581 19861 solver.cpp:239] Iteration 17700 (9.17794 iter/s, 2.17914s/20 iters), loss = 0.000686927
I0522 10:52:21.347941 19861 solver.cpp:258]     Train net output #0: loss = 0.000686851 (* 1 = 0.000686851 loss)
I0522 10:52:21.347954 19861 sgd_solver.cpp:112] Iteration 17700, lr = 0.001
I0522 10:52:23.592207 19861 solver.cpp:239] Iteration 17720 (8.9116 iter/s, 2.24427s/20 iters), loss = 0.00167543
I0522 10:52:23.602695 19861 solver.cpp:258]     Train net output #0: loss = 0.00167535 (* 1 = 0.00167535 loss)
I0522 10:52:23.602703 19861 sgd_solver.cpp:112] Iteration 17720, lr = 0.001
I0522 10:52:26.041890 19861 solver.cpp:239] Iteration 17740 (8.19944 iter/s, 2.43919s/20 iters), loss = 0.000302328
I0522 10:52:26.041944 19861 solver.cpp:258]     Train net output #0: loss = 0.000302251 (* 1 = 0.000302251 loss)
I0522 10:52:26.041947 19861 sgd_solver.cpp:112] Iteration 17740, lr = 0.001
I0522 10:52:28.282649 19861 solver.cpp:239] Iteration 17760 (8.92583 iter/s, 2.24069s/20 iters), loss = 0.000906892
I0522 10:52:28.282729 19861 solver.cpp:258]     Train net output #0: loss = 0.000906815 (* 1 = 0.000906815 loss)
I0522 10:52:28.282733 19861 sgd_solver.cpp:112] Iteration 17760, lr = 0.001
I0522 10:52:28.807278 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:52:30.489034 19861 solver.cpp:239] Iteration 17780 (9.06494 iter/s, 2.2063s/20 iters), loss = 0.000989609
I0522 10:52:30.489081 19861 solver.cpp:258]     Train net output #0: loss = 0.000989532 (* 1 = 0.000989532 loss)
I0522 10:52:30.489085 19861 sgd_solver.cpp:112] Iteration 17780, lr = 0.001
I0522 10:52:33.057863 19861 solver.cpp:239] Iteration 17800 (7.78582 iter/s, 2.56877s/20 iters), loss = 0.000265089
I0522 10:52:33.057911 19861 solver.cpp:258]     Train net output #0: loss = 0.000265012 (* 1 = 0.000265012 loss)
I0522 10:52:33.057915 19861 sgd_solver.cpp:112] Iteration 17800, lr = 0.001
I0522 10:52:35.230228 19861 solver.cpp:239] Iteration 17820 (9.20677 iter/s, 2.17231s/20 iters), loss = 0.000626619
I0522 10:52:35.230275 19861 solver.cpp:258]     Train net output #0: loss = 0.000626542 (* 1 = 0.000626542 loss)
I0522 10:52:35.230278 19861 sgd_solver.cpp:112] Iteration 17820, lr = 0.001
I0522 10:52:37.443743 19861 solver.cpp:239] Iteration 17840 (9.03559 iter/s, 2.21347s/20 iters), loss = 0.000551317
I0522 10:52:37.443779 19861 solver.cpp:258]     Train net output #0: loss = 0.00055124 (* 1 = 0.00055124 loss)
I0522 10:52:37.443784 19861 sgd_solver.cpp:112] Iteration 17840, lr = 0.001
I0522 10:52:39.948705 19861 solver.cpp:239] Iteration 17860 (7.98432 iter/s, 2.50491s/20 iters), loss = 0.000824476
I0522 10:52:39.948770 19861 solver.cpp:258]     Train net output #0: loss = 0.000824398 (* 1 = 0.000824398 loss)
I0522 10:52:39.948774 19861 sgd_solver.cpp:112] Iteration 17860, lr = 0.001
I0522 10:52:42.131845 19861 solver.cpp:239] Iteration 17880 (9.16139 iter/s, 2.18307s/20 iters), loss = 0.00420857
I0522 10:52:42.140931 19861 solver.cpp:258]     Train net output #0: loss = 0.00420849 (* 1 = 0.00420849 loss)
I0522 10:52:42.140938 19861 sgd_solver.cpp:112] Iteration 17880, lr = 0.001
I0522 10:52:44.315343 19861 solver.cpp:239] Iteration 17900 (9.19791 iter/s, 2.17441s/20 iters), loss = 0.0098622
I0522 10:52:44.315393 19861 solver.cpp:258]     Train net output #0: loss = 0.00986212 (* 1 = 0.00986212 loss)
I0522 10:52:44.315397 19861 sgd_solver.cpp:112] Iteration 17900, lr = 0.001
I0522 10:52:46.291800 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:52:46.520151 19861 solver.cpp:239] Iteration 17920 (9.07131 iter/s, 2.20475s/20 iters), loss = 0.00113303
I0522 10:52:46.520299 19861 solver.cpp:258]     Train net output #0: loss = 0.00113295 (* 1 = 0.00113295 loss)
I0522 10:52:46.520328 19861 sgd_solver.cpp:112] Iteration 17920, lr = 0.001
I0522 10:52:49.090720 19861 solver.cpp:239] Iteration 17940 (7.78082 iter/s, 2.57042s/20 iters), loss = 0.000609221
I0522 10:52:49.090849 19861 solver.cpp:258]     Train net output #0: loss = 0.000609142 (* 1 = 0.000609142 loss)
I0522 10:52:49.090854 19861 sgd_solver.cpp:112] Iteration 17940, lr = 0.001
I0522 10:52:51.329311 19861 solver.cpp:239] Iteration 17960 (8.93481 iter/s, 2.23844s/20 iters), loss = 0.000974297
I0522 10:52:51.329398 19861 solver.cpp:258]     Train net output #0: loss = 0.000974218 (* 1 = 0.000974218 loss)
I0522 10:52:51.329402 19861 sgd_solver.cpp:112] Iteration 17960, lr = 0.001
I0522 10:52:53.499341 19861 solver.cpp:239] Iteration 17980 (9.21684 iter/s, 2.16994s/20 iters), loss = 0.00136426
I0522 10:52:53.499389 19861 solver.cpp:258]     Train net output #0: loss = 0.00136418 (* 1 = 0.00136418 loss)
I0522 10:52:53.499393 19861 sgd_solver.cpp:112] Iteration 17980, lr = 0.001
I0522 10:52:55.834808 19861 solver.cpp:347] Iteration 18000, Testing net (#0)
I0522 10:52:58.855981 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:53:03.042443 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:53:06.376453 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:53:06.975632 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:53:11.218168 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:53:12.094975 19861 solver.cpp:414]     Test net output #0: accuracy = 0.876062
I0522 10:53:12.095031 19861 solver.cpp:414]     Test net output #1: loss = 0.778986 (* 1 = 0.778986 loss)
I0522 10:53:12.192060 19861 solver.cpp:239] Iteration 18000 (1.06993 iter/s, 18.6928s/20 iters), loss = 0.00154381
I0522 10:53:12.194538 19861 solver.cpp:258]     Train net output #0: loss = 0.00154373 (* 1 = 0.00154373 loss)
I0522 10:53:12.194550 19861 sgd_solver.cpp:112] Iteration 18000, lr = 0.001
I0522 10:53:14.395889 19861 solver.cpp:239] Iteration 18020 (9.08535 iter/s, 2.20135s/20 iters), loss = 0.00194915
I0522 10:53:14.395952 19861 solver.cpp:258]     Train net output #0: loss = 0.00194907 (* 1 = 0.00194907 loss)
I0522 10:53:14.395957 19861 sgd_solver.cpp:112] Iteration 18020, lr = 0.001
I0522 10:53:16.628187 19861 solver.cpp:239] Iteration 18040 (8.95973 iter/s, 2.23221s/20 iters), loss = 0.00125448
I0522 10:53:16.628284 19861 solver.cpp:258]     Train net output #0: loss = 0.0012544 (* 1 = 0.0012544 loss)
I0522 10:53:16.628289 19861 sgd_solver.cpp:112] Iteration 18040, lr = 0.001
I0522 10:53:19.172839 19861 solver.cpp:239] Iteration 18060 (7.85999 iter/s, 2.54453s/20 iters), loss = 0.000946373
I0522 10:53:19.173100 19861 solver.cpp:258]     Train net output #0: loss = 0.000946294 (* 1 = 0.000946294 loss)
I0522 10:53:19.173107 19861 sgd_solver.cpp:112] Iteration 18060, lr = 0.001
I0522 10:53:20.350742 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:53:21.364753 19861 solver.cpp:239] Iteration 18080 (9.12557 iter/s, 2.19164s/20 iters), loss = 0.00106929
I0522 10:53:21.364806 19861 solver.cpp:258]     Train net output #0: loss = 0.00106921 (* 1 = 0.00106921 loss)
I0522 10:53:21.364811 19861 sgd_solver.cpp:112] Iteration 18080, lr = 0.001
I0522 10:53:23.591841 19861 solver.cpp:239] Iteration 18100 (8.98062 iter/s, 2.22702s/20 iters), loss = 0.00694734
I0522 10:53:23.591905 19861 solver.cpp:258]     Train net output #0: loss = 0.00694726 (* 1 = 0.00694726 loss)
I0522 10:53:23.591909 19861 sgd_solver.cpp:112] Iteration 18100, lr = 0.001
I0522 10:53:26.072387 19861 solver.cpp:239] Iteration 18120 (8.06295 iter/s, 2.48048s/20 iters), loss = 0.000854044
I0522 10:53:26.083528 19861 solver.cpp:258]     Train net output #0: loss = 0.000853965 (* 1 = 0.000853965 loss)
I0522 10:53:26.083536 19861 sgd_solver.cpp:112] Iteration 18120, lr = 0.001
I0522 10:53:28.158938 19861 solver.cpp:239] Iteration 18140 (9.63664 iter/s, 2.07541s/20 iters), loss = 0.000672403
I0522 10:53:28.158980 19861 solver.cpp:258]     Train net output #0: loss = 0.000672323 (* 1 = 0.000672323 loss)
I0522 10:53:28.158984 19861 sgd_solver.cpp:112] Iteration 18140, lr = 0.001
I0522 10:53:30.303712 19861 solver.cpp:239] Iteration 18160 (9.32526 iter/s, 2.14471s/20 iters), loss = 0.00232312
I0522 10:53:30.317184 19861 solver.cpp:258]     Train net output #0: loss = 0.00232304 (* 1 = 0.00232304 loss)
I0522 10:53:30.317203 19861 sgd_solver.cpp:112] Iteration 18160, lr = 0.001
I0522 10:53:32.459178 19861 solver.cpp:239] Iteration 18180 (9.33708 iter/s, 2.142s/20 iters), loss = 0.000902806
I0522 10:53:32.470502 19861 solver.cpp:258]     Train net output #0: loss = 0.000902726 (* 1 = 0.000902726 loss)
I0522 10:53:32.470511 19861 sgd_solver.cpp:112] Iteration 18180, lr = 0.001
I0522 10:53:34.785511 19861 solver.cpp:239] Iteration 18200 (8.6393 iter/s, 2.315s/20 iters), loss = 0.000985927
I0522 10:53:34.785570 19861 solver.cpp:258]     Train net output #0: loss = 0.000985846 (* 1 = 0.000985846 loss)
I0522 10:53:34.785574 19861 sgd_solver.cpp:112] Iteration 18200, lr = 0.001
I0522 10:53:36.916810 19861 solver.cpp:239] Iteration 18220 (9.38427 iter/s, 2.13123s/20 iters), loss = 0.000546227
I0522 10:53:36.916873 19861 solver.cpp:258]     Train net output #0: loss = 0.000546147 (* 1 = 0.000546147 loss)
I0522 10:53:36.916877 19861 sgd_solver.cpp:112] Iteration 18220, lr = 0.001
I0522 10:53:37.377830 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:53:39.056861 19861 solver.cpp:239] Iteration 18240 (9.34585 iter/s, 2.13999s/20 iters), loss = 0.00115628
I0522 10:53:39.066377 19861 solver.cpp:258]     Train net output #0: loss = 0.0011562 (* 1 = 0.0011562 loss)
I0522 10:53:39.066385 19861 sgd_solver.cpp:112] Iteration 18240, lr = 0.001
I0522 10:53:41.529426 19861 solver.cpp:239] Iteration 18260 (8.1201 iter/s, 2.46303s/20 iters), loss = 0.004082
I0522 10:53:41.529522 19861 solver.cpp:258]     Train net output #0: loss = 0.00408192 (* 1 = 0.00408192 loss)
I0522 10:53:41.529527 19861 sgd_solver.cpp:112] Iteration 18260, lr = 0.001
I0522 10:53:43.683766 19861 solver.cpp:239] Iteration 18280 (9.28404 iter/s, 2.15424s/20 iters), loss = 0.00389066
I0522 10:53:43.695617 19861 solver.cpp:258]     Train net output #0: loss = 0.00389058 (* 1 = 0.00389058 loss)
I0522 10:53:43.695624 19861 sgd_solver.cpp:112] Iteration 18280, lr = 0.001
I0522 10:53:45.829298 19861 solver.cpp:239] Iteration 18300 (9.37358 iter/s, 2.13366s/20 iters), loss = 0.0019553
I0522 10:53:45.829394 19861 solver.cpp:258]     Train net output #0: loss = 0.00195522 (* 1 = 0.00195522 loss)
I0522 10:53:45.829398 19861 sgd_solver.cpp:112] Iteration 18300, lr = 0.001
I0522 10:53:48.215871 19861 solver.cpp:239] Iteration 18320 (8.38066 iter/s, 2.38645s/20 iters), loss = 0.00103746
I0522 10:53:48.216090 19861 solver.cpp:258]     Train net output #0: loss = 0.00103738 (* 1 = 0.00103738 loss)
I0522 10:53:48.216095 19861 sgd_solver.cpp:112] Iteration 18320, lr = 0.001
I0522 10:53:50.376683 19861 solver.cpp:239] Iteration 18340 (9.25675 iter/s, 2.16058s/20 iters), loss = 0.000313059
I0522 10:53:50.376930 19861 solver.cpp:258]     Train net output #0: loss = 0.00031298 (* 1 = 0.00031298 loss)
I0522 10:53:50.376935 19861 sgd_solver.cpp:112] Iteration 18340, lr = 0.001
I0522 10:53:52.568661 19861 solver.cpp:239] Iteration 18360 (9.12522 iter/s, 2.19173s/20 iters), loss = 0.000569952
I0522 10:53:52.568712 19861 solver.cpp:258]     Train net output #0: loss = 0.000569873 (* 1 = 0.000569873 loss)
I0522 10:53:52.568715 19861 sgd_solver.cpp:112] Iteration 18360, lr = 0.001
I0522 10:53:54.464803 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:53:54.993294 19861 solver.cpp:239] Iteration 18380 (8.24888 iter/s, 2.42457s/20 iters), loss = 0.00173017
I0522 10:53:55.005095 19861 solver.cpp:258]     Train net output #0: loss = 0.00173009 (* 1 = 0.00173009 loss)
I0522 10:53:55.005102 19861 sgd_solver.cpp:112] Iteration 18380, lr = 0.001
I0522 10:53:57.274121 19861 solver.cpp:239] Iteration 18400 (8.81433 iter/s, 2.26903s/20 iters), loss = 0.00376247
I0522 10:53:57.287437 19861 solver.cpp:258]     Train net output #0: loss = 0.00376239 (* 1 = 0.00376239 loss)
I0522 10:53:57.287444 19861 sgd_solver.cpp:112] Iteration 18400, lr = 0.001
I0522 10:53:59.429388 19861 solver.cpp:239] Iteration 18420 (9.33731 iter/s, 2.14195s/20 iters), loss = 0.000498562
I0522 10:53:59.442504 19861 solver.cpp:258]     Train net output #0: loss = 0.000498484 (* 1 = 0.000498484 loss)
I0522 10:53:59.442514 19861 sgd_solver.cpp:112] Iteration 18420, lr = 0.001
I0522 10:54:01.565897 19861 solver.cpp:239] Iteration 18440 (9.41886 iter/s, 2.1234s/20 iters), loss = 0.00115794
I0522 10:54:01.579165 19861 solver.cpp:258]     Train net output #0: loss = 0.00115786 (* 1 = 0.00115786 loss)
I0522 10:54:01.579172 19861 sgd_solver.cpp:112] Iteration 18440, lr = 0.001
I0522 10:54:03.984897 19861 solver.cpp:239] Iteration 18460 (8.31351 iter/s, 2.40572s/20 iters), loss = 0.000636781
I0522 10:54:03.984948 19861 solver.cpp:258]     Train net output #0: loss = 0.000636703 (* 1 = 0.000636703 loss)
I0522 10:54:03.984953 19861 sgd_solver.cpp:112] Iteration 18460, lr = 0.001
I0522 10:54:06.135169 19861 solver.cpp:239] Iteration 18480 (9.30148 iter/s, 2.1502s/20 iters), loss = 0.00624387
I0522 10:54:06.135249 19861 solver.cpp:258]     Train net output #0: loss = 0.00624379 (* 1 = 0.00624379 loss)
I0522 10:54:06.135253 19861 sgd_solver.cpp:112] Iteration 18480, lr = 0.001
I0522 10:54:08.262949 19861 solver.cpp:239] Iteration 18500 (9.39991 iter/s, 2.12768s/20 iters), loss = 0.00219058
I0522 10:54:08.263032 19861 solver.cpp:258]     Train net output #0: loss = 0.00219051 (* 1 = 0.00219051 loss)
I0522 10:54:08.263037 19861 sgd_solver.cpp:112] Iteration 18500, lr = 0.001
I0522 10:54:10.648780 19861 solver.cpp:239] Iteration 18520 (8.38314 iter/s, 2.38574s/20 iters), loss = 0.00226112
I0522 10:54:10.648834 19861 solver.cpp:258]     Train net output #0: loss = 0.00226104 (* 1 = 0.00226104 loss)
I0522 10:54:10.648838 19861 sgd_solver.cpp:112] Iteration 18520, lr = 0.001
I0522 10:54:11.823384 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:54:12.846472 19861 solver.cpp:239] Iteration 18540 (9.10071 iter/s, 2.19763s/20 iters), loss = 0.000223004
I0522 10:54:12.846534 19861 solver.cpp:258]     Train net output #0: loss = 0.000222926 (* 1 = 0.000222926 loss)
I0522 10:54:12.846537 19861 sgd_solver.cpp:112] Iteration 18540, lr = 0.001
I0522 10:54:15.008716 19861 solver.cpp:239] Iteration 18560 (9.24997 iter/s, 2.16217s/20 iters), loss = 0.00043673
I0522 10:54:15.021764 19861 solver.cpp:258]     Train net output #0: loss = 0.000436652 (* 1 = 0.000436652 loss)
I0522 10:54:15.021772 19861 sgd_solver.cpp:112] Iteration 18560, lr = 0.001
I0522 10:54:17.136157 19861 solver.cpp:239] Iteration 18580 (9.459 iter/s, 2.11439s/20 iters), loss = 0.000482688
I0522 10:54:17.136212 19861 solver.cpp:258]     Train net output #0: loss = 0.00048261 (* 1 = 0.00048261 loss)
I0522 10:54:17.136216 19861 sgd_solver.cpp:112] Iteration 18580, lr = 0.001
I0522 10:54:19.628518 19861 solver.cpp:239] Iteration 18600 (8.02473 iter/s, 2.4923s/20 iters), loss = 0.000199208
I0522 10:54:19.628639 19861 solver.cpp:258]     Train net output #0: loss = 0.00019913 (* 1 = 0.00019913 loss)
I0522 10:54:19.628643 19861 sgd_solver.cpp:112] Iteration 18600, lr = 0.001
I0522 10:54:21.808145 19861 solver.cpp:239] Iteration 18620 (9.17649 iter/s, 2.17948s/20 iters), loss = 0.000575653
I0522 10:54:21.808497 19861 solver.cpp:258]     Train net output #0: loss = 0.000575574 (* 1 = 0.000575574 loss)
I0522 10:54:21.808502 19861 sgd_solver.cpp:112] Iteration 18620, lr = 0.001
I0522 10:54:23.983963 19861 solver.cpp:239] Iteration 18640 (9.19353 iter/s, 2.17544s/20 iters), loss = 0.00270037
I0522 10:54:23.984055 19861 solver.cpp:258]     Train net output #0: loss = 0.00270029 (* 1 = 0.00270029 loss)
I0522 10:54:23.984061 19861 sgd_solver.cpp:112] Iteration 18640, lr = 0.001
I0522 10:54:26.459980 19861 solver.cpp:239] Iteration 18660 (8.0778 iter/s, 2.47592s/20 iters), loss = 0.00124244
I0522 10:54:26.460034 19861 solver.cpp:258]     Train net output #0: loss = 0.00124236 (* 1 = 0.00124236 loss)
I0522 10:54:26.460038 19861 sgd_solver.cpp:112] Iteration 18660, lr = 0.001
I0522 10:54:28.642386 19861 solver.cpp:239] Iteration 18680 (9.16449 iter/s, 2.18234s/20 iters), loss = 0.000277675
I0522 10:54:28.642460 19861 solver.cpp:258]     Train net output #0: loss = 0.000277596 (* 1 = 0.000277596 loss)
I0522 10:54:28.642464 19861 sgd_solver.cpp:112] Iteration 18680, lr = 0.001
I0522 10:54:29.014456 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:54:29.052846 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:54:30.817528 19861 solver.cpp:239] Iteration 18700 (9.19515 iter/s, 2.17506s/20 iters), loss = 0.000721243
I0522 10:54:30.817590 19861 solver.cpp:258]     Train net output #0: loss = 0.000721164 (* 1 = 0.000721164 loss)
I0522 10:54:30.817595 19861 sgd_solver.cpp:112] Iteration 18700, lr = 0.001
I0522 10:54:33.351476 19861 solver.cpp:239] Iteration 18720 (7.89309 iter/s, 2.53386s/20 iters), loss = 0.000295267
I0522 10:54:33.351567 19861 solver.cpp:258]     Train net output #0: loss = 0.000295188 (* 1 = 0.000295188 loss)
I0522 10:54:33.351572 19861 sgd_solver.cpp:112] Iteration 18720, lr = 0.001
I0522 10:54:35.516191 19861 solver.cpp:239] Iteration 18740 (9.23955 iter/s, 2.16461s/20 iters), loss = 0.00834229
I0522 10:54:35.516280 19861 solver.cpp:258]     Train net output #0: loss = 0.00834221 (* 1 = 0.00834221 loss)
I0522 10:54:35.516285 19861 sgd_solver.cpp:112] Iteration 18740, lr = 0.001
I0522 10:54:37.698658 19861 solver.cpp:239] Iteration 18760 (9.16431 iter/s, 2.18238s/20 iters), loss = 0.000181805
I0522 10:54:37.709122 19861 solver.cpp:258]     Train net output #0: loss = 0.000181726 (* 1 = 0.000181726 loss)
I0522 10:54:37.709131 19861 sgd_solver.cpp:112] Iteration 18760, lr = 0.001
I0522 10:54:39.869480 19861 solver.cpp:239] Iteration 18780 (9.25774 iter/s, 2.16035s/20 iters), loss = 0.00271325
I0522 10:54:39.869540 19861 solver.cpp:258]     Train net output #0: loss = 0.00271317 (* 1 = 0.00271317 loss)
I0522 10:54:39.869544 19861 sgd_solver.cpp:112] Iteration 18780, lr = 0.001
I0522 10:54:42.345005 19861 solver.cpp:239] Iteration 18800 (8.07934 iter/s, 2.47545s/20 iters), loss = 0.000536736
I0522 10:54:42.345093 19861 solver.cpp:258]     Train net output #0: loss = 0.000536656 (* 1 = 0.000536656 loss)
I0522 10:54:42.345099 19861 sgd_solver.cpp:112] Iteration 18800, lr = 0.001
I0522 10:54:44.510769 19861 solver.cpp:239] Iteration 18820 (9.23514 iter/s, 2.16564s/20 iters), loss = 0.000338264
I0522 10:54:44.510875 19861 solver.cpp:258]     Train net output #0: loss = 0.000338185 (* 1 = 0.000338185 loss)
I0522 10:54:44.510880 19861 sgd_solver.cpp:112] Iteration 18820, lr = 0.001
I0522 10:54:46.343575 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:54:46.682441 19861 solver.cpp:239] Iteration 18840 (9.20995 iter/s, 2.17156s/20 iters), loss = 0.000548308
I0522 10:54:46.682492 19861 solver.cpp:258]     Train net output #0: loss = 0.000548229 (* 1 = 0.000548229 loss)
I0522 10:54:46.682497 19861 sgd_solver.cpp:112] Iteration 18840, lr = 0.001
I0522 10:54:49.243139 19861 solver.cpp:239] Iteration 18860 (7.81054 iter/s, 2.56064s/20 iters), loss = 0.00169612
I0522 10:54:49.243196 19861 solver.cpp:258]     Train net output #0: loss = 0.00169604 (* 1 = 0.00169604 loss)
I0522 10:54:49.243199 19861 sgd_solver.cpp:112] Iteration 18860, lr = 0.001
I0522 10:54:51.433262 19861 solver.cpp:239] Iteration 18880 (9.13217 iter/s, 2.19006s/20 iters), loss = 0.00059456
I0522 10:54:51.433382 19861 solver.cpp:258]     Train net output #0: loss = 0.00059448 (* 1 = 0.00059448 loss)
I0522 10:54:51.433387 19861 sgd_solver.cpp:112] Iteration 18880, lr = 0.001
I0522 10:54:53.579206 19861 solver.cpp:239] Iteration 18900 (9.32048 iter/s, 2.14581s/20 iters), loss = 0.000667198
I0522 10:54:53.588315 19861 solver.cpp:258]     Train net output #0: loss = 0.000667118 (* 1 = 0.000667118 loss)
I0522 10:54:53.588325 19861 sgd_solver.cpp:112] Iteration 18900, lr = 0.001
I0522 10:54:55.992507 19861 solver.cpp:239] Iteration 18920 (8.31898 iter/s, 2.40414s/20 iters), loss = 0.0015553
I0522 10:54:56.005726 19861 solver.cpp:258]     Train net output #0: loss = 0.00155522 (* 1 = 0.00155522 loss)
I0522 10:54:56.005767 19861 sgd_solver.cpp:112] Iteration 18920, lr = 0.001
I0522 10:54:58.079931 19861 solver.cpp:239] Iteration 18940 (9.64235 iter/s, 2.07418s/20 iters), loss = 0.000992142
I0522 10:54:58.089395 19861 solver.cpp:258]     Train net output #0: loss = 0.000992062 (* 1 = 0.000992062 loss)
I0522 10:54:58.089406 19861 sgd_solver.cpp:112] Iteration 18940, lr = 0.001
I0522 10:55:00.203609 19861 solver.cpp:239] Iteration 18960 (9.45977 iter/s, 2.11422s/20 iters), loss = 0.00600463
I0522 10:55:00.213778 19861 solver.cpp:258]     Train net output #0: loss = 0.00600455 (* 1 = 0.00600455 loss)
I0522 10:55:00.213784 19861 sgd_solver.cpp:112] Iteration 18960, lr = 0.001
I0522 10:55:02.376039 19861 solver.cpp:239] Iteration 18980 (9.24967 iter/s, 2.16224s/20 iters), loss = 0.00182215
I0522 10:55:02.376121 19861 solver.cpp:258]     Train net output #0: loss = 0.00182207 (* 1 = 0.00182207 loss)
I0522 10:55:02.376125 19861 sgd_solver.cpp:112] Iteration 18980, lr = 0.001
I0522 10:55:03.631697 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:55:04.552198 19861 solver.cpp:347] Iteration 19000, Testing net (#0)
I0522 10:55:07.821022 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:55:12.167038 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:55:16.041008 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:55:16.245867 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:55:20.197036 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:55:20.856317 19861 solver.cpp:414]     Test net output #0: accuracy = 0.881482
I0522 10:55:20.856389 19861 solver.cpp:414]     Test net output #1: loss = 0.755713 (* 1 = 0.755713 loss)
I0522 10:55:20.953593 19861 solver.cpp:239] Iteration 19000 (1.07657 iter/s, 18.5776s/20 iters), loss = 0.00114782
I0522 10:55:20.955510 19861 solver.cpp:258]     Train net output #0: loss = 0.00114774 (* 1 = 0.00114774 loss)
I0522 10:55:20.955521 19861 sgd_solver.cpp:112] Iteration 19000, lr = 0.001
I0522 10:55:23.102339 19861 solver.cpp:239] Iteration 19020 (9.31611 iter/s, 2.14682s/20 iters), loss = 0.000429535
I0522 10:55:23.111894 19861 solver.cpp:258]     Train net output #0: loss = 0.000429455 (* 1 = 0.000429455 loss)
I0522 10:55:23.111901 19861 sgd_solver.cpp:112] Iteration 19020, lr = 0.001
I0522 10:55:25.157200 19861 solver.cpp:239] Iteration 19040 (9.77852 iter/s, 2.0453s/20 iters), loss = 0.000829338
I0522 10:55:25.157402 19861 solver.cpp:258]     Train net output #0: loss = 0.000829259 (* 1 = 0.000829259 loss)
I0522 10:55:25.157409 19861 sgd_solver.cpp:112] Iteration 19040, lr = 0.001
I0522 10:55:27.217788 19861 solver.cpp:239] Iteration 19060 (9.70699 iter/s, 2.06037s/20 iters), loss = 0.000254209
I0522 10:55:27.217881 19861 solver.cpp:258]     Train net output #0: loss = 0.000254129 (* 1 = 0.000254129 loss)
I0522 10:55:27.217886 19861 sgd_solver.cpp:112] Iteration 19060, lr = 0.001
I0522 10:55:30.822203 19861 solver.cpp:239] Iteration 19080 (5.54892 iter/s, 3.60431s/20 iters), loss = 0.000449625
I0522 10:55:30.822260 19861 solver.cpp:258]     Train net output #0: loss = 0.000449546 (* 1 = 0.000449546 loss)
I0522 10:55:30.822263 19861 sgd_solver.cpp:112] Iteration 19080, lr = 0.001
I0522 10:55:32.874919 19861 solver.cpp:239] Iteration 19100 (9.74353 iter/s, 2.05264s/20 iters), loss = 0.00116207
I0522 10:55:32.884336 19861 solver.cpp:258]     Train net output #0: loss = 0.00116199 (* 1 = 0.00116199 loss)
I0522 10:55:32.884344 19861 sgd_solver.cpp:112] Iteration 19100, lr = 0.001
I0522 10:55:34.908624 19861 solver.cpp:239] Iteration 19120 (9.88008 iter/s, 2.02427s/20 iters), loss = 0.000913742
I0522 10:55:34.918042 19861 solver.cpp:258]     Train net output #0: loss = 0.000913664 (* 1 = 0.000913664 loss)
I0522 10:55:34.918056 19861 sgd_solver.cpp:112] Iteration 19120, lr = 0.001
I0522 10:55:36.948055 19861 solver.cpp:239] Iteration 19140 (9.8522 iter/s, 2.03s/20 iters), loss = 0.000410907
I0522 10:55:36.957559 19861 solver.cpp:258]     Train net output #0: loss = 0.000410829 (* 1 = 0.000410829 loss)
I0522 10:55:36.957568 19861 sgd_solver.cpp:112] Iteration 19140, lr = 0.001
I0522 10:55:37.276849 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:55:39.225365 19861 solver.cpp:239] Iteration 19160 (8.81928 iter/s, 2.26776s/20 iters), loss = 0.000694598
I0522 10:55:39.225518 19861 solver.cpp:258]     Train net output #0: loss = 0.00069452 (* 1 = 0.00069452 loss)
I0522 10:55:39.225538 19861 sgd_solver.cpp:112] Iteration 19160, lr = 0.001
I0522 10:55:42.586761 19861 solver.cpp:239] Iteration 19180 (5.95017 iter/s, 3.36125s/20 iters), loss = 0.00038543
I0522 10:55:42.596294 19861 solver.cpp:258]     Train net output #0: loss = 0.000385352 (* 1 = 0.000385352 loss)
I0522 10:55:42.596309 19861 sgd_solver.cpp:112] Iteration 19180, lr = 0.001
I0522 10:55:44.631773 19861 solver.cpp:239] Iteration 19200 (9.8257 iter/s, 2.03548s/20 iters), loss = 0.00067009
I0522 10:55:44.641398 19861 solver.cpp:258]     Train net output #0: loss = 0.000670012 (* 1 = 0.000670012 loss)
I0522 10:55:44.641408 19861 sgd_solver.cpp:112] Iteration 19200, lr = 0.001
I0522 10:55:46.681740 19861 solver.cpp:239] Iteration 19220 (9.80231 iter/s, 2.04034s/20 iters), loss = 0.000106048
I0522 10:55:46.691368 19861 solver.cpp:258]     Train net output #0: loss = 0.000105971 (* 1 = 0.000105971 loss)
I0522 10:55:46.691378 19861 sgd_solver.cpp:112] Iteration 19220, lr = 0.001
I0522 10:55:48.728365 19861 solver.cpp:239] Iteration 19240 (9.8184 iter/s, 2.03699s/20 iters), loss = 0.000250853
I0522 10:55:48.738080 19861 solver.cpp:258]     Train net output #0: loss = 0.000250776 (* 1 = 0.000250776 loss)
I0522 10:55:48.738090 19861 sgd_solver.cpp:112] Iteration 19240, lr = 0.001
I0522 10:55:51.977828 19861 solver.cpp:239] Iteration 19260 (6.17332 iter/s, 3.23975s/20 iters), loss = 0.000479553
I0522 10:55:51.987332 19861 solver.cpp:258]     Train net output #0: loss = 0.000479476 (* 1 = 0.000479476 loss)
I0522 10:55:51.987339 19861 sgd_solver.cpp:112] Iteration 19260, lr = 0.001
I0522 10:55:54.487780 19861 solver.cpp:239] Iteration 19280 (7.99859 iter/s, 2.50044s/20 iters), loss = 0.000583799
I0522 10:55:54.487848 19861 solver.cpp:258]     Train net output #0: loss = 0.000583722 (* 1 = 0.000583722 loss)
I0522 10:55:54.487852 19861 sgd_solver.cpp:112] Iteration 19280, lr = 0.001
I0522 10:55:56.174116 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:55:56.544728 19861 solver.cpp:239] Iteration 19300 (9.72351 iter/s, 2.05687s/20 iters), loss = 0.000543297
I0522 10:55:56.554446 19861 solver.cpp:258]     Train net output #0: loss = 0.00054322 (* 1 = 0.00054322 loss)
I0522 10:55:56.554455 19861 sgd_solver.cpp:112] Iteration 19300, lr = 0.001
I0522 10:55:58.594902 19861 solver.cpp:239] Iteration 19320 (9.80181 iter/s, 2.04044s/20 iters), loss = 0.000699014
I0522 10:55:58.604432 19861 solver.cpp:258]     Train net output #0: loss = 0.000698937 (* 1 = 0.000698937 loss)
I0522 10:55:58.604441 19861 sgd_solver.cpp:112] Iteration 19320, lr = 0.001
I0522 10:56:00.870767 19861 solver.cpp:239] Iteration 19340 (8.82484 iter/s, 2.26633s/20 iters), loss = 0.000154867
I0522 10:56:00.881945 19861 solver.cpp:258]     Train net output #0: loss = 0.00015479 (* 1 = 0.00015479 loss)
I0522 10:56:00.881963 19861 sgd_solver.cpp:112] Iteration 19340, lr = 0.001
I0522 10:56:04.290982 19861 solver.cpp:239] Iteration 19360 (5.86676 iter/s, 3.40904s/20 iters), loss = 0.0031429
I0522 10:56:04.291049 19861 solver.cpp:258]     Train net output #0: loss = 0.00314282 (* 1 = 0.00314282 loss)
I0522 10:56:04.291054 19861 sgd_solver.cpp:112] Iteration 19360, lr = 0.001
I0522 10:56:06.491791 19861 solver.cpp:239] Iteration 19380 (9.0879 iter/s, 2.20073s/20 iters), loss = 0.000208416
I0522 10:56:06.491878 19861 solver.cpp:258]     Train net output #0: loss = 0.000208338 (* 1 = 0.000208338 loss)
I0522 10:56:06.491883 19861 sgd_solver.cpp:112] Iteration 19380, lr = 0.001
I0522 10:56:08.586449 19861 solver.cpp:239] Iteration 19400 (9.54854 iter/s, 2.09456s/20 iters), loss = 0.000905025
I0522 10:56:08.595973 19861 solver.cpp:258]     Train net output #0: loss = 0.000904948 (* 1 = 0.000904948 loss)
I0522 10:56:08.595983 19861 sgd_solver.cpp:112] Iteration 19400, lr = 0.001
I0522 10:56:10.645153 19861 solver.cpp:239] Iteration 19420 (9.76006 iter/s, 2.04917s/20 iters), loss = 0.00141312
I0522 10:56:10.656323 19861 solver.cpp:258]     Train net output #0: loss = 0.00141305 (* 1 = 0.00141305 loss)
I0522 10:56:10.656335 19861 sgd_solver.cpp:112] Iteration 19420, lr = 0.001
I0522 10:56:14.222350 19861 solver.cpp:239] Iteration 19440 (5.60847 iter/s, 3.56604s/20 iters), loss = 0.000986949
I0522 10:56:14.222394 19861 solver.cpp:258]     Train net output #0: loss = 0.000986871 (* 1 = 0.000986871 loss)
I0522 10:56:14.222398 19861 sgd_solver.cpp:112] Iteration 19440, lr = 0.001
I0522 10:56:15.189774 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:56:16.420315 19861 solver.cpp:239] Iteration 19460 (9.09953 iter/s, 2.19791s/20 iters), loss = 0.000413392
I0522 10:56:16.430176 19861 solver.cpp:258]     Train net output #0: loss = 0.000413314 (* 1 = 0.000413314 loss)
I0522 10:56:16.430186 19861 sgd_solver.cpp:112] Iteration 19460, lr = 0.001
I0522 10:56:18.499729 19861 solver.cpp:239] Iteration 19480 (9.66392 iter/s, 2.06955s/20 iters), loss = 0.00185223
I0522 10:56:18.509236 19861 solver.cpp:258]     Train net output #0: loss = 0.00185215 (* 1 = 0.00185215 loss)
I0522 10:56:18.509243 19861 sgd_solver.cpp:112] Iteration 19480, lr = 0.001
I0522 10:56:20.540650 19861 solver.cpp:239] Iteration 19500 (9.84539 iter/s, 2.03141s/20 iters), loss = 0.000609119
I0522 10:56:20.550084 19861 solver.cpp:258]     Train net output #0: loss = 0.000609041 (* 1 = 0.000609041 loss)
I0522 10:56:20.550094 19861 sgd_solver.cpp:112] Iteration 19500, lr = 0.001
I0522 10:56:22.606940 19861 solver.cpp:239] Iteration 19520 (9.72369 iter/s, 2.05683s/20 iters), loss = 0.000296701
I0522 10:56:22.619097 19861 solver.cpp:258]     Train net output #0: loss = 0.000296624 (* 1 = 0.000296624 loss)
I0522 10:56:22.619112 19861 sgd_solver.cpp:112] Iteration 19520, lr = 0.001
I0522 10:56:26.244110 19861 solver.cpp:239] Iteration 19540 (5.51721 iter/s, 3.62502s/20 iters), loss = 0.00106729
I0522 10:56:26.244374 19861 solver.cpp:258]     Train net output #0: loss = 0.00106721 (* 1 = 0.00106721 loss)
I0522 10:56:26.244379 19861 sgd_solver.cpp:112] Iteration 19540, lr = 0.001
I0522 10:56:28.317915 19861 solver.cpp:239] Iteration 19560 (9.64543 iter/s, 2.07352s/20 iters), loss = 0.000477805
I0522 10:56:28.328845 19861 solver.cpp:258]     Train net output #0: loss = 0.000477727 (* 1 = 0.000477727 loss)
I0522 10:56:28.328852 19861 sgd_solver.cpp:112] Iteration 19560, lr = 0.001
I0522 10:56:30.365675 19861 solver.cpp:239] Iteration 19580 (9.81922 iter/s, 2.03682s/20 iters), loss = 0.000265633
I0522 10:56:30.375217 19861 solver.cpp:258]     Train net output #0: loss = 0.000265555 (* 1 = 0.000265555 loss)
I0522 10:56:30.375228 19861 sgd_solver.cpp:112] Iteration 19580, lr = 0.001
I0522 10:56:32.408541 19861 solver.cpp:239] Iteration 19600 (9.83613 iter/s, 2.03332s/20 iters), loss = 0.000384012
I0522 10:56:32.418032 19861 solver.cpp:258]     Train net output #0: loss = 0.000383934 (* 1 = 0.000383934 loss)
I0522 10:56:32.418042 19861 sgd_solver.cpp:112] Iteration 19600, lr = 0.001
I0522 10:56:32.660589 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:56:34.674341 19861 solver.cpp:239] Iteration 19620 (8.86412 iter/s, 2.25629s/20 iters), loss = 0.00130674
I0522 10:56:34.674484 19861 solver.cpp:258]     Train net output #0: loss = 0.00130666 (* 1 = 0.00130666 loss)
I0522 10:56:34.674490 19861 sgd_solver.cpp:112] Iteration 19620, lr = 0.001
I0522 10:56:38.164113 19861 solver.cpp:239] Iteration 19640 (5.73132 iter/s, 3.4896s/20 iters), loss = 0.00411711
I0522 10:56:38.164266 19861 solver.cpp:258]     Train net output #0: loss = 0.00411703 (* 1 = 0.00411703 loss)
I0522 10:56:38.164271 19861 sgd_solver.cpp:112] Iteration 19640, lr = 0.001
I0522 10:56:40.363469 19861 solver.cpp:239] Iteration 19660 (9.09424 iter/s, 2.19919s/20 iters), loss = 0.000332315
I0522 10:56:40.363538 19861 solver.cpp:258]     Train net output #0: loss = 0.000332238 (* 1 = 0.000332238 loss)
I0522 10:56:40.363543 19861 sgd_solver.cpp:112] Iteration 19660, lr = 0.001
I0522 10:56:42.569875 19861 solver.cpp:239] Iteration 19680 (9.06485 iter/s, 2.20633s/20 iters), loss = 0.000274133
I0522 10:56:42.569952 19861 solver.cpp:258]     Train net output #0: loss = 0.000274055 (* 1 = 0.000274055 loss)
I0522 10:56:42.569957 19861 sgd_solver.cpp:112] Iteration 19680, lr = 0.001
I0522 10:56:44.778859 19861 solver.cpp:239] Iteration 19700 (9.05432 iter/s, 2.20889s/20 iters), loss = 0.00043957
I0522 10:56:44.778947 19861 solver.cpp:258]     Train net output #0: loss = 0.000439493 (* 1 = 0.000439493 loss)
I0522 10:56:44.778957 19861 sgd_solver.cpp:112] Iteration 19700, lr = 0.001
I0522 10:56:47.777746 19861 solver.cpp:239] Iteration 19720 (6.66932 iter/s, 2.99881s/20 iters), loss = 0.000728591
I0522 10:56:47.787075 19861 solver.cpp:258]     Train net output #0: loss = 0.000728515 (* 1 = 0.000728515 loss)
I0522 10:56:47.787083 19861 sgd_solver.cpp:112] Iteration 19720, lr = 0.001
I0522 10:56:50.428357 19861 solver.cpp:239] Iteration 19740 (7.57211 iter/s, 2.64127s/20 iters), loss = 0.00105198
I0522 10:56:50.437913 19861 solver.cpp:258]     Train net output #0: loss = 0.0010519 (* 1 = 0.0010519 loss)
I0522 10:56:50.437922 19861 sgd_solver.cpp:112] Iteration 19740, lr = 0.001
I0522 10:56:52.031373 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:56:52.477716 19861 solver.cpp:239] Iteration 19760 (9.8049 iter/s, 2.0398s/20 iters), loss = 0.000178843
I0522 10:56:52.487242 19861 solver.cpp:258]     Train net output #0: loss = 0.000178765 (* 1 = 0.000178765 loss)
I0522 10:56:52.487251 19861 sgd_solver.cpp:112] Iteration 19760, lr = 0.001
I0522 10:56:54.526780 19861 solver.cpp:239] Iteration 19780 (9.80616 iter/s, 2.03953s/20 iters), loss = 0.00113154
I0522 10:56:54.536340 19861 solver.cpp:258]     Train net output #0: loss = 0.00113146 (* 1 = 0.00113146 loss)
I0522 10:56:54.536348 19861 sgd_solver.cpp:112] Iteration 19780, lr = 0.001
I0522 10:56:56.592291 19861 solver.cpp:239] Iteration 19800 (9.72796 iter/s, 2.05593s/20 iters), loss = 0.000188099
I0522 10:56:56.592736 19861 solver.cpp:258]     Train net output #0: loss = 0.000188021 (* 1 = 0.000188021 loss)
I0522 10:56:56.592743 19861 sgd_solver.cpp:112] Iteration 19800, lr = 0.001
I0522 10:57:00.238423 19861 solver.cpp:239] Iteration 19820 (5.48592 iter/s, 3.6457s/20 iters), loss = 0.000457127
I0522 10:57:00.238481 19861 solver.cpp:258]     Train net output #0: loss = 0.000457049 (* 1 = 0.000457049 loss)
I0522 10:57:00.238487 19861 sgd_solver.cpp:112] Iteration 19820, lr = 0.001
I0522 10:57:02.299635 19861 solver.cpp:239] Iteration 19840 (9.70336 iter/s, 2.06114s/20 iters), loss = 0.000286133
I0522 10:57:02.309278 19861 solver.cpp:258]     Train net output #0: loss = 0.000286056 (* 1 = 0.000286056 loss)
I0522 10:57:02.309288 19861 sgd_solver.cpp:112] Iteration 19840, lr = 0.001
I0522 10:57:04.351410 19861 solver.cpp:239] Iteration 19860 (9.79377 iter/s, 2.04211s/20 iters), loss = 0.000986296
I0522 10:57:04.361064 19861 solver.cpp:258]     Train net output #0: loss = 0.000986219 (* 1 = 0.000986219 loss)
I0522 10:57:04.361075 19861 sgd_solver.cpp:112] Iteration 19860, lr = 0.001
I0522 10:57:06.399978 19861 solver.cpp:239] Iteration 19880 (9.80914 iter/s, 2.03891s/20 iters), loss = 0.000456266
I0522 10:57:06.409375 19861 solver.cpp:258]     Train net output #0: loss = 0.000456189 (* 1 = 0.000456189 loss)
I0522 10:57:06.409384 19861 sgd_solver.cpp:112] Iteration 19880, lr = 0.001
I0522 10:57:09.532290 19861 solver.cpp:239] Iteration 19900 (6.40425 iter/s, 3.12293s/20 iters), loss = 0.000649783
I0522 10:57:09.541777 19861 solver.cpp:258]     Train net output #0: loss = 0.000649706 (* 1 = 0.000649706 loss)
I0522 10:57:09.541785 19861 sgd_solver.cpp:112] Iteration 19900, lr = 0.001
I0522 10:57:10.942416 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:57:12.091104 19861 solver.cpp:239] Iteration 19920 (7.84525 iter/s, 2.54931s/20 iters), loss = 0.000633578
I0522 10:57:12.100780 19861 solver.cpp:258]     Train net output #0: loss = 0.000633502 (* 1 = 0.000633502 loss)
I0522 10:57:12.100788 19861 sgd_solver.cpp:112] Iteration 19920, lr = 0.001
I0522 10:57:14.143993 19861 solver.cpp:239] Iteration 19940 (9.78855 iter/s, 2.0432s/20 iters), loss = 0.00600156
I0522 10:57:14.153631 19861 solver.cpp:258]     Train net output #0: loss = 0.00600148 (* 1 = 0.00600148 loss)
I0522 10:57:14.153640 19861 sgd_solver.cpp:112] Iteration 19940, lr = 0.001
I0522 10:57:16.194998 19861 solver.cpp:239] Iteration 19960 (9.79737 iter/s, 2.04136s/20 iters), loss = 0.000145224
I0522 10:57:16.204785 19861 solver.cpp:258]     Train net output #0: loss = 0.000145147 (* 1 = 0.000145147 loss)
I0522 10:57:16.204794 19861 sgd_solver.cpp:112] Iteration 19960, lr = 0.001
I0522 10:57:18.461984 19861 solver.cpp:239] Iteration 19980 (8.8606 iter/s, 2.25718s/20 iters), loss = 0.00185198
I0522 10:57:18.475244 19861 solver.cpp:258]     Train net output #0: loss = 0.0018519 (* 1 = 0.0018519 loss)
I0522 10:57:18.475257 19861 sgd_solver.cpp:112] Iteration 19980, lr = 0.001
I0522 10:57:21.740113 19861 solver.cpp:464] Snapshotting to binary proto file ./data/trained_models/caffenet/solver_iter_20000.caffemodel
I0522 10:57:22.853643 19861 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./data/trained_models/caffenet/solver_iter_20000.solverstate
I0522 10:57:23.161173 19861 solver.cpp:347] Iteration 20000, Testing net (#0)
I0522 10:57:23.313412 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:57:28.580123 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:57:34.322360 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:57:38.045915 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:57:43.121348 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:57:43.630488 19861 solver.cpp:414]     Test net output #0: accuracy = 0.876122
I0522 10:57:43.630533 19861 solver.cpp:414]     Test net output #1: loss = 0.812883 (* 1 = 0.812883 loss)
I0522 10:57:43.727499 19861 solver.cpp:239] Iteration 20000 (0.792004 iter/s, 25.2524s/20 iters), loss = 0.000756096
I0522 10:57:43.729413 19861 solver.cpp:258]     Train net output #0: loss = 0.000756019 (* 1 = 0.000756019 loss)
I0522 10:57:43.729423 19861 sgd_solver.cpp:112] Iteration 20000, lr = 0.0001
I0522 10:57:46.261760 19861 solver.cpp:239] Iteration 20020 (7.89781 iter/s, 2.53235s/20 iters), loss = 0.00320117
I0522 10:57:46.275121 19861 solver.cpp:258]     Train net output #0: loss = 0.00320109 (* 1 = 0.00320109 loss)
I0522 10:57:46.275132 19861 sgd_solver.cpp:112] Iteration 20020, lr = 0.0001
I0522 10:57:49.538815 19861 solver.cpp:239] Iteration 20040 (6.12801 iter/s, 3.2637s/20 iters), loss = 0.0015978
I0522 10:57:49.538854 19861 solver.cpp:258]     Train net output #0: loss = 0.00159773 (* 1 = 0.00159773 loss)
I0522 10:57:49.538858 19861 sgd_solver.cpp:112] Iteration 20040, lr = 0.0001
I0522 10:57:51.585009 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:57:52.105870 19861 solver.cpp:239] Iteration 20060 (7.79114 iter/s, 2.56702s/20 iters), loss = 0.000800867
I0522 10:57:52.105908 19861 solver.cpp:258]     Train net output #0: loss = 0.00080079 (* 1 = 0.00080079 loss)
I0522 10:57:52.105911 19861 sgd_solver.cpp:112] Iteration 20060, lr = 0.0001
I0522 10:57:52.359822 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:57:54.629017 19861 solver.cpp:239] Iteration 20080 (7.92673 iter/s, 2.52311s/20 iters), loss = 0.000590529
I0522 10:57:54.629061 19861 solver.cpp:258]     Train net output #0: loss = 0.000590453 (* 1 = 0.000590453 loss)
I0522 10:57:54.629068 19861 sgd_solver.cpp:112] Iteration 20080, lr = 0.0001
I0522 10:57:57.081568 19861 solver.cpp:239] Iteration 20100 (8.15493 iter/s, 2.4525s/20 iters), loss = 0.00031047
I0522 10:57:57.081650 19861 solver.cpp:258]     Train net output #0: loss = 0.000310394 (* 1 = 0.000310394 loss)
I0522 10:57:57.081655 19861 sgd_solver.cpp:112] Iteration 20100, lr = 0.0001
I0522 10:57:59.498237 19861 solver.cpp:239] Iteration 20120 (8.27611 iter/s, 2.41659s/20 iters), loss = 0.000618471
I0522 10:57:59.498423 19861 solver.cpp:258]     Train net output #0: loss = 0.000618394 (* 1 = 0.000618394 loss)
I0522 10:57:59.498427 19861 sgd_solver.cpp:112] Iteration 20120, lr = 0.0001
I0522 10:58:01.641314 19861 solver.cpp:239] Iteration 20140 (9.33319 iter/s, 2.14289s/20 iters), loss = 0.000223198
I0522 10:58:01.650388 19861 solver.cpp:258]     Train net output #0: loss = 0.000223122 (* 1 = 0.000223122 loss)
I0522 10:58:01.650396 19861 sgd_solver.cpp:112] Iteration 20140, lr = 0.0001
I0522 10:58:03.670920 19861 solver.cpp:239] Iteration 20160 (9.89838 iter/s, 2.02053s/20 iters), loss = 0.00464485
I0522 10:58:03.680030 19861 solver.cpp:258]     Train net output #0: loss = 0.00464477 (* 1 = 0.00464477 loss)
I0522 10:58:03.680038 19861 sgd_solver.cpp:112] Iteration 20160, lr = 0.0001
I0522 10:58:05.700093 19861 solver.cpp:239] Iteration 20180 (9.90074 iter/s, 2.02005s/20 iters), loss = 0.000947611
I0522 10:58:05.709209 19861 solver.cpp:258]     Train net output #0: loss = 0.000947535 (* 1 = 0.000947535 loss)
I0522 10:58:05.709220 19861 sgd_solver.cpp:112] Iteration 20180, lr = 0.0001
I0522 10:58:07.751338 19861 solver.cpp:239] Iteration 20200 (9.79377 iter/s, 2.04211s/20 iters), loss = 0.000191654
I0522 10:58:07.751415 19861 solver.cpp:258]     Train net output #0: loss = 0.000191578 (* 1 = 0.000191578 loss)
I0522 10:58:07.751420 19861 sgd_solver.cpp:112] Iteration 20200, lr = 0.0001
I0522 10:58:09.325183 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:58:09.799859 19861 solver.cpp:239] Iteration 20220 (9.76353 iter/s, 2.04844s/20 iters), loss = 0.000263014
I0522 10:58:09.809242 19861 solver.cpp:258]     Train net output #0: loss = 0.000262938 (* 1 = 0.000262938 loss)
I0522 10:58:09.809249 19861 sgd_solver.cpp:112] Iteration 20220, lr = 0.0001
I0522 10:58:11.844971 19861 solver.cpp:239] Iteration 20240 (9.82453 iter/s, 2.03572s/20 iters), loss = 0.000344961
I0522 10:58:11.854427 19861 solver.cpp:258]     Train net output #0: loss = 0.000344886 (* 1 = 0.000344886 loss)
I0522 10:58:11.854434 19861 sgd_solver.cpp:112] Iteration 20240, lr = 0.0001
I0522 10:58:13.885392 19861 solver.cpp:239] Iteration 20260 (9.84763 iter/s, 2.03095s/20 iters), loss = 0.000563097
I0522 10:58:13.885484 19861 solver.cpp:258]     Train net output #0: loss = 0.000563021 (* 1 = 0.000563021 loss)
I0522 10:58:13.885490 19861 sgd_solver.cpp:112] Iteration 20260, lr = 0.0001
I0522 10:58:15.938133 19861 solver.cpp:239] Iteration 20280 (9.74359 iter/s, 2.05263s/20 iters), loss = 0.000368657
I0522 10:58:15.938215 19861 solver.cpp:258]     Train net output #0: loss = 0.000368581 (* 1 = 0.000368581 loss)
I0522 10:58:15.938220 19861 sgd_solver.cpp:112] Iteration 20280, lr = 0.0001
I0522 10:58:18.025188 19861 solver.cpp:239] Iteration 20300 (9.58347 iter/s, 2.08693s/20 iters), loss = 0.00019072
I0522 10:58:18.025326 19861 solver.cpp:258]     Train net output #0: loss = 0.000190644 (* 1 = 0.000190644 loss)
I0522 10:58:18.025337 19861 sgd_solver.cpp:112] Iteration 20300, lr = 0.0001
I0522 10:58:20.291225 19861 solver.cpp:239] Iteration 20320 (8.83478 iter/s, 2.26378s/20 iters), loss = 0.000444035
I0522 10:58:20.301273 19861 solver.cpp:258]     Train net output #0: loss = 0.00044396 (* 1 = 0.00044396 loss)
I0522 10:58:20.301281 19861 sgd_solver.cpp:112] Iteration 20320, lr = 0.0001
I0522 10:58:22.355736 19861 solver.cpp:239] Iteration 20340 (9.73488 iter/s, 2.05447s/20 iters), loss = 0.00217245
I0522 10:58:22.365870 19861 solver.cpp:258]     Train net output #0: loss = 0.00217237 (* 1 = 0.00217237 loss)
I0522 10:58:22.365878 19861 sgd_solver.cpp:112] Iteration 20340, lr = 0.0001
I0522 10:58:24.459331 19861 solver.cpp:239] Iteration 20360 (9.5536 iter/s, 2.09345s/20 iters), loss = 0.000678116
I0522 10:58:24.459389 19861 solver.cpp:258]     Train net output #0: loss = 0.000678041 (* 1 = 0.000678041 loss)
I0522 10:58:24.459398 19861 sgd_solver.cpp:112] Iteration 20360, lr = 0.0001
I0522 10:58:25.351778 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:58:26.566118 19861 solver.cpp:239] Iteration 20380 (9.49343 iter/s, 2.10672s/20 iters), loss = 0.000511618
I0522 10:58:26.566256 19861 solver.cpp:258]     Train net output #0: loss = 0.000511542 (* 1 = 0.000511542 loss)
I0522 10:58:26.566262 19861 sgd_solver.cpp:112] Iteration 20380, lr = 0.0001
I0522 10:58:28.719115 19861 solver.cpp:239] Iteration 20400 (9.28997 iter/s, 2.15286s/20 iters), loss = 0.000509442
I0522 10:58:28.719163 19861 solver.cpp:258]     Train net output #0: loss = 0.000509366 (* 1 = 0.000509366 loss)
I0522 10:58:28.719167 19861 sgd_solver.cpp:112] Iteration 20400, lr = 0.0001
I0522 10:58:31.161711 19861 solver.cpp:239] Iteration 20420 (8.18824 iter/s, 2.44253s/20 iters), loss = 0.000355037
I0522 10:58:31.162052 19861 solver.cpp:258]     Train net output #0: loss = 0.000354962 (* 1 = 0.000354962 loss)
I0522 10:58:31.162060 19861 sgd_solver.cpp:112] Iteration 20420, lr = 0.0001
I0522 10:58:33.313112 19861 solver.cpp:239] Iteration 20440 (9.29772 iter/s, 2.15107s/20 iters), loss = 0.000382156
I0522 10:58:33.313143 19861 solver.cpp:258]     Train net output #0: loss = 0.000382081 (* 1 = 0.000382081 loss)
I0522 10:58:33.313148 19861 sgd_solver.cpp:112] Iteration 20440, lr = 0.0001
I0522 10:58:35.456123 19861 solver.cpp:239] Iteration 20460 (9.3328 iter/s, 2.14298s/20 iters), loss = 0.000187312
I0522 10:58:35.456147 19861 solver.cpp:258]     Train net output #0: loss = 0.000187237 (* 1 = 0.000187237 loss)
I0522 10:58:35.456151 19861 sgd_solver.cpp:112] Iteration 20460, lr = 0.0001
I0522 10:58:37.567593 19861 solver.cpp:239] Iteration 20480 (9.47231 iter/s, 2.11142s/20 iters), loss = 8.75262e-05
I0522 10:58:37.567703 19861 solver.cpp:258]     Train net output #0: loss = 8.74506e-05 (* 1 = 8.74506e-05 loss)
I0522 10:58:37.567708 19861 sgd_solver.cpp:112] Iteration 20480, lr = 0.0001
I0522 10:58:40.129348 19861 solver.cpp:239] Iteration 20500 (7.80748 iter/s, 2.56164s/20 iters), loss = 0.000416214
I0522 10:58:40.129390 19861 solver.cpp:258]     Train net output #0: loss = 0.000416138 (* 1 = 0.000416138 loss)
I0522 10:58:40.129395 19861 sgd_solver.cpp:112] Iteration 20500, lr = 0.0001
I0522 10:58:42.365379 19861 solver.cpp:239] Iteration 20520 (8.94456 iter/s, 2.236s/20 iters), loss = 0.000958302
I0522 10:58:42.365414 19861 solver.cpp:258]     Train net output #0: loss = 0.000958227 (* 1 = 0.000958227 loss)
I0522 10:58:42.365419 19861 sgd_solver.cpp:112] Iteration 20520, lr = 0.0001
I0522 10:58:42.461022 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:58:44.516150 19861 solver.cpp:239] Iteration 20540 (9.29917 iter/s, 2.15073s/20 iters), loss = 0.00122461
I0522 10:58:44.516206 19861 solver.cpp:258]     Train net output #0: loss = 0.00122453 (* 1 = 0.00122453 loss)
I0522 10:58:44.516211 19861 sgd_solver.cpp:112] Iteration 20540, lr = 0.0001
I0522 10:58:47.047288 19861 solver.cpp:239] Iteration 20560 (7.90175 iter/s, 2.53108s/20 iters), loss = 0.000345319
I0522 10:58:47.056360 19861 solver.cpp:258]     Train net output #0: loss = 0.000345244 (* 1 = 0.000345244 loss)
I0522 10:58:47.056366 19861 sgd_solver.cpp:112] Iteration 20560, lr = 0.0001
I0522 10:58:49.251171 19861 solver.cpp:239] Iteration 20580 (9.11239 iter/s, 2.19481s/20 iters), loss = 0.000632818
I0522 10:58:49.251219 19861 solver.cpp:258]     Train net output #0: loss = 0.000632743 (* 1 = 0.000632743 loss)
I0522 10:58:49.251222 19861 sgd_solver.cpp:112] Iteration 20580, lr = 0.0001
I0522 10:58:51.476388 19861 solver.cpp:239] Iteration 20600 (8.98811 iter/s, 2.22516s/20 iters), loss = 0.000689343
I0522 10:58:51.476442 19861 solver.cpp:258]     Train net output #0: loss = 0.000689267 (* 1 = 0.000689267 loss)
I0522 10:58:51.476446 19861 sgd_solver.cpp:112] Iteration 20600, lr = 0.0001
I0522 10:58:53.907516 19861 solver.cpp:239] Iteration 20620 (8.22684 iter/s, 2.43107s/20 iters), loss = 0.000670024
I0522 10:58:53.907580 19861 solver.cpp:258]     Train net output #0: loss = 0.000669949 (* 1 = 0.000669949 loss)
I0522 10:58:53.907584 19861 sgd_solver.cpp:112] Iteration 20620, lr = 0.0001
I0522 10:58:56.089217 19861 solver.cpp:239] Iteration 20640 (9.16747 iter/s, 2.18163s/20 iters), loss = 0.000415396
I0522 10:58:56.089289 19861 solver.cpp:258]     Train net output #0: loss = 0.000415321 (* 1 = 0.000415321 loss)
I0522 10:58:56.089294 19861 sgd_solver.cpp:112] Iteration 20640, lr = 0.0001
I0522 10:58:58.282284 19861 solver.cpp:239] Iteration 20660 (9.11993 iter/s, 2.193s/20 iters), loss = 0.000777323
I0522 10:58:58.282330 19861 solver.cpp:258]     Train net output #0: loss = 0.000777248 (* 1 = 0.000777248 loss)
I0522 10:58:58.282335 19861 sgd_solver.cpp:112] Iteration 20660, lr = 0.0001
I0522 10:58:59.891280 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:59:00.457067 19861 solver.cpp:239] Iteration 20680 (9.1966 iter/s, 2.17472s/20 iters), loss = 0.000671712
I0522 10:59:00.457280 19861 solver.cpp:258]     Train net output #0: loss = 0.000671637 (* 1 = 0.000671637 loss)
I0522 10:59:00.457285 19861 sgd_solver.cpp:112] Iteration 20680, lr = 0.0001
I0522 10:59:02.984077 19861 solver.cpp:239] Iteration 20700 (7.91521 iter/s, 2.52678s/20 iters), loss = 0.000181861
I0522 10:59:02.984432 19861 solver.cpp:258]     Train net output #0: loss = 0.000181786 (* 1 = 0.000181786 loss)
I0522 10:59:02.984438 19861 sgd_solver.cpp:112] Iteration 20700, lr = 0.0001
I0522 10:59:05.159693 19861 solver.cpp:239] Iteration 20720 (9.19446 iter/s, 2.17522s/20 iters), loss = 0.000315866
I0522 10:59:05.159832 19861 solver.cpp:258]     Train net output #0: loss = 0.000315791 (* 1 = 0.000315791 loss)
I0522 10:59:05.159845 19861 sgd_solver.cpp:112] Iteration 20720, lr = 0.0001
I0522 10:59:07.342684 19861 solver.cpp:239] Iteration 20740 (9.1624 iter/s, 2.18284s/20 iters), loss = 0.00133902
I0522 10:59:07.342803 19861 solver.cpp:258]     Train net output #0: loss = 0.00133895 (* 1 = 0.00133895 loss)
I0522 10:59:07.342808 19861 sgd_solver.cpp:112] Iteration 20740, lr = 0.0001
I0522 10:59:09.902743 19861 solver.cpp:239] Iteration 20760 (7.81269 iter/s, 2.55994s/20 iters), loss = 0.000921677
I0522 10:59:09.902848 19861 solver.cpp:258]     Train net output #0: loss = 0.000921602 (* 1 = 0.000921602 loss)
I0522 10:59:09.902856 19861 sgd_solver.cpp:112] Iteration 20760, lr = 0.0001
I0522 10:59:12.057488 19861 solver.cpp:239] Iteration 20780 (9.28231 iter/s, 2.15464s/20 iters), loss = 0.00136053
I0522 10:59:12.057551 19861 solver.cpp:258]     Train net output #0: loss = 0.00136046 (* 1 = 0.00136046 loss)
I0522 10:59:12.057555 19861 sgd_solver.cpp:112] Iteration 20780, lr = 0.0001
I0522 10:59:14.230383 19861 solver.cpp:239] Iteration 20800 (9.2047 iter/s, 2.1728s/20 iters), loss = 0.000343378
I0522 10:59:14.230491 19861 solver.cpp:258]     Train net output #0: loss = 0.000343304 (* 1 = 0.000343304 loss)
I0522 10:59:14.230499 19861 sgd_solver.cpp:112] Iteration 20800, lr = 0.0001
I0522 10:59:16.701848 19861 solver.cpp:239] Iteration 20820 (8.09272 iter/s, 2.47136s/20 iters), loss = 0.000631238
I0522 10:59:16.701913 19861 solver.cpp:258]     Train net output #0: loss = 0.000631163 (* 1 = 0.000631163 loss)
I0522 10:59:16.701918 19861 sgd_solver.cpp:112] Iteration 20820, lr = 0.0001
I0522 10:59:17.554169 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:59:18.857795 19861 solver.cpp:239] Iteration 20840 (9.27697 iter/s, 2.15588s/20 iters), loss = 0.000644258
I0522 10:59:18.857851 19861 solver.cpp:258]     Train net output #0: loss = 0.000644183 (* 1 = 0.000644183 loss)
I0522 10:59:18.857854 19861 sgd_solver.cpp:112] Iteration 20840, lr = 0.0001
I0522 10:59:21.089558 19861 solver.cpp:239] Iteration 20860 (8.96175 iter/s, 2.23171s/20 iters), loss = 0.00091872
I0522 10:59:21.089609 19861 solver.cpp:258]     Train net output #0: loss = 0.000918645 (* 1 = 0.000918645 loss)
I0522 10:59:21.089613 19861 sgd_solver.cpp:112] Iteration 20860, lr = 0.0001
I0522 10:59:23.268319 19861 solver.cpp:239] Iteration 20880 (9.17985 iter/s, 2.17868s/20 iters), loss = 0.000457327
I0522 10:59:23.268446 19861 solver.cpp:258]     Train net output #0: loss = 0.000457252 (* 1 = 0.000457252 loss)
I0522 10:59:23.268456 19861 sgd_solver.cpp:112] Iteration 20880, lr = 0.0001
I0522 10:59:25.732197 19861 solver.cpp:239] Iteration 20900 (8.11776 iter/s, 2.46373s/20 iters), loss = 0.000862502
I0522 10:59:25.732292 19861 solver.cpp:258]     Train net output #0: loss = 0.000862427 (* 1 = 0.000862427 loss)
I0522 10:59:25.732300 19861 sgd_solver.cpp:112] Iteration 20900, lr = 0.0001
I0522 10:59:27.878059 19861 solver.cpp:239] Iteration 20920 (9.32074 iter/s, 2.14575s/20 iters), loss = 0.000486143
I0522 10:59:27.891151 19861 solver.cpp:258]     Train net output #0: loss = 0.000486068 (* 1 = 0.000486068 loss)
I0522 10:59:27.891175 19861 sgd_solver.cpp:112] Iteration 20920, lr = 0.0001
I0522 10:59:29.987463 19861 solver.cpp:239] Iteration 20940 (9.54055 iter/s, 2.09631s/20 iters), loss = 0.000153204
I0522 10:59:30.000659 19861 solver.cpp:258]     Train net output #0: loss = 0.000153129 (* 1 = 0.000153129 loss)
I0522 10:59:30.000676 19861 sgd_solver.cpp:112] Iteration 20940, lr = 0.0001
I0522 10:59:32.535573 19861 solver.cpp:239] Iteration 20960 (7.8898 iter/s, 2.53492s/20 iters), loss = 0.00050665
I0522 10:59:32.535636 19861 solver.cpp:258]     Train net output #0: loss = 0.000506576 (* 1 = 0.000506576 loss)
I0522 10:59:32.535704 19861 sgd_solver.cpp:112] Iteration 20960, lr = 0.0001
I0522 10:59:34.726876 19861 solver.cpp:239] Iteration 20980 (9.12723 iter/s, 2.19125s/20 iters), loss = 0.000652543
I0522 10:59:34.740062 19861 solver.cpp:258]     Train net output #0: loss = 0.000652468 (* 1 = 0.000652468 loss)
I0522 10:59:34.740068 19861 sgd_solver.cpp:112] Iteration 20980, lr = 0.0001
I0522 10:59:34.829710 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:59:36.715467 19861 solver.cpp:347] Iteration 21000, Testing net (#0)
I0522 10:59:39.586877 19861 blocking_queue.cpp:49] Waiting for data
I0522 10:59:40.546576 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:59:44.505332 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:59:48.719946 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:59:52.720278 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 10:59:53.098060 19861 solver.cpp:414]     Test net output #0: accuracy = 0.878402
I0522 10:59:53.098117 19861 solver.cpp:414]     Test net output #1: loss = 0.79349 (* 1 = 0.79349 loss)
I0522 10:59:53.249944 19861 solver.cpp:239] Iteration 21000 (1.0805 iter/s, 18.51s/20 iters), loss = 0.000848578
I0522 10:59:53.251906 19861 solver.cpp:258]     Train net output #0: loss = 0.000848503 (* 1 = 0.000848503 loss)
I0522 10:59:53.251937 19861 sgd_solver.cpp:112] Iteration 21000, lr = 0.0001
I0522 10:59:55.708353 19861 solver.cpp:239] Iteration 21020 (8.14185 iter/s, 2.45644s/20 iters), loss = 0.00121085
I0522 10:59:55.708425 19861 solver.cpp:258]     Train net output #0: loss = 0.00121077 (* 1 = 0.00121077 loss)
I0522 10:59:55.708431 19861 sgd_solver.cpp:112] Iteration 21020, lr = 0.0001
I0522 10:59:57.959165 19861 solver.cpp:239] Iteration 21040 (8.88597 iter/s, 2.25074s/20 iters), loss = 7.96595e-05
I0522 10:59:57.959218 19861 solver.cpp:258]     Train net output #0: loss = 7.95851e-05 (* 1 = 7.95851e-05 loss)
I0522 10:59:57.959223 19861 sgd_solver.cpp:112] Iteration 21040, lr = 0.0001
I0522 11:00:00.119210 19861 solver.cpp:239] Iteration 21060 (9.25932 iter/s, 2.15999s/20 iters), loss = 0.000222754
I0522 11:00:00.119267 19861 solver.cpp:258]     Train net output #0: loss = 0.00022268 (* 1 = 0.00022268 loss)
I0522 11:00:00.119272 19861 sgd_solver.cpp:112] Iteration 21060, lr = 0.0001
I0522 11:00:02.707963 19861 solver.cpp:239] Iteration 21080 (7.7259 iter/s, 2.58869s/20 iters), loss = 0.000847473
I0522 11:00:02.717947 19861 solver.cpp:258]     Train net output #0: loss = 0.000847399 (* 1 = 0.000847399 loss)
I0522 11:00:02.717954 19861 sgd_solver.cpp:112] Iteration 21080, lr = 0.0001
I0522 11:00:04.905957 19861 solver.cpp:239] Iteration 21100 (9.14073 iter/s, 2.18801s/20 iters), loss = 0.00398758
I0522 11:00:04.906229 19861 solver.cpp:258]     Train net output #0: loss = 0.00398751 (* 1 = 0.00398751 loss)
I0522 11:00:04.906234 19861 sgd_solver.cpp:112] Iteration 21100, lr = 0.0001
I0522 11:00:07.114769 19861 solver.cpp:239] Iteration 21120 (9.05579 iter/s, 2.20853s/20 iters), loss = 0.00159034
I0522 11:00:07.114843 19861 solver.cpp:258]     Train net output #0: loss = 0.00159027 (* 1 = 0.00159027 loss)
I0522 11:00:07.114848 19861 sgd_solver.cpp:112] Iteration 21120, lr = 0.0001
I0522 11:00:09.008249 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:00:09.617585 19861 solver.cpp:239] Iteration 21140 (7.99123 iter/s, 2.50274s/20 iters), loss = 0.000379527
I0522 11:00:09.626881 19861 solver.cpp:258]     Train net output #0: loss = 0.000379452 (* 1 = 0.000379452 loss)
I0522 11:00:09.626890 19861 sgd_solver.cpp:112] Iteration 21140, lr = 0.0001
I0522 11:00:11.799343 19861 solver.cpp:239] Iteration 21160 (9.20619 iter/s, 2.17245s/20 iters), loss = 0.00109539
I0522 11:00:11.799427 19861 solver.cpp:258]     Train net output #0: loss = 0.00109532 (* 1 = 0.00109532 loss)
I0522 11:00:11.799430 19861 sgd_solver.cpp:112] Iteration 21160, lr = 0.0001
I0522 11:00:13.719455 19861 blocking_queue.cpp:49] Waiting for data
I0522 11:00:13.992808 19861 solver.cpp:239] Iteration 21180 (9.11829 iter/s, 2.19339s/20 iters), loss = 0.000387323
I0522 11:00:13.992848 19861 solver.cpp:258]     Train net output #0: loss = 0.000387249 (* 1 = 0.000387249 loss)
I0522 11:00:13.992853 19861 sgd_solver.cpp:112] Iteration 21180, lr = 0.0001
I0522 11:00:16.518707 19861 solver.cpp:239] Iteration 21200 (7.91811 iter/s, 2.52586s/20 iters), loss = 0.00151948
I0522 11:00:16.518761 19861 solver.cpp:258]     Train net output #0: loss = 0.0015194 (* 1 = 0.0015194 loss)
I0522 11:00:16.518765 19861 sgd_solver.cpp:112] Iteration 21200, lr = 0.0001
I0522 11:00:18.742086 19861 solver.cpp:239] Iteration 21220 (8.99559 iter/s, 2.22331s/20 iters), loss = 0.000693295
I0522 11:00:18.755255 19861 solver.cpp:258]     Train net output #0: loss = 0.000693221 (* 1 = 0.000693221 loss)
I0522 11:00:18.755264 19861 sgd_solver.cpp:112] Iteration 21220, lr = 0.0001
I0522 11:00:20.937069 19861 solver.cpp:239] Iteration 21240 (9.16673 iter/s, 2.1818s/20 iters), loss = 0.000955344
I0522 11:00:20.937127 19861 solver.cpp:258]     Train net output #0: loss = 0.000955269 (* 1 = 0.000955269 loss)
I0522 11:00:20.937134 19861 sgd_solver.cpp:112] Iteration 21240, lr = 0.0001
I0522 11:00:23.173606 19861 solver.cpp:239] Iteration 21260 (8.9426 iter/s, 2.23649s/20 iters), loss = 0.000631962
I0522 11:00:23.173632 19861 solver.cpp:258]     Train net output #0: loss = 0.000631888 (* 1 = 0.000631888 loss)
I0522 11:00:23.173635 19861 sgd_solver.cpp:112] Iteration 21260, lr = 0.0001
I0522 11:00:25.788494 19861 solver.cpp:239] Iteration 21280 (7.64863 iter/s, 2.61485s/20 iters), loss = 0.000303101
I0522 11:00:25.801868 19861 solver.cpp:258]     Train net output #0: loss = 0.000303027 (* 1 = 0.000303027 loss)
I0522 11:00:25.801877 19861 sgd_solver.cpp:112] Iteration 21280, lr = 0.0001
I0522 11:00:26.588730 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:00:27.969272 19861 solver.cpp:239] Iteration 21300 (9.22766 iter/s, 2.1674s/20 iters), loss = 0.00091965
I0522 11:00:27.969336 19861 solver.cpp:258]     Train net output #0: loss = 0.000919575 (* 1 = 0.000919575 loss)
I0522 11:00:27.969341 19861 sgd_solver.cpp:112] Iteration 21300, lr = 0.0001
I0522 11:00:30.218340 19861 solver.cpp:239] Iteration 21320 (8.89281 iter/s, 2.24901s/20 iters), loss = 0.00157396
I0522 11:00:30.218379 19861 solver.cpp:258]     Train net output #0: loss = 0.00157389 (* 1 = 0.00157389 loss)
I0522 11:00:30.218382 19861 sgd_solver.cpp:112] Iteration 21320, lr = 0.0001
I0522 11:00:32.782850 19861 solver.cpp:239] Iteration 21340 (7.79887 iter/s, 2.56447s/20 iters), loss = 0.00186839
I0522 11:00:32.791936 19861 solver.cpp:258]     Train net output #0: loss = 0.00186832 (* 1 = 0.00186832 loss)
I0522 11:00:32.791944 19861 sgd_solver.cpp:112] Iteration 21340, lr = 0.0001
I0522 11:00:34.947103 19861 solver.cpp:239] Iteration 21360 (9.28006 iter/s, 2.15516s/20 iters), loss = 0.000434092
I0522 11:00:34.947393 19861 solver.cpp:258]     Train net output #0: loss = 0.000434017 (* 1 = 0.000434017 loss)
I0522 11:00:34.947397 19861 sgd_solver.cpp:112] Iteration 21360, lr = 0.0001
I0522 11:00:37.176621 19861 solver.cpp:239] Iteration 21380 (8.97175 iter/s, 2.22922s/20 iters), loss = 0.000281482
I0522 11:00:37.176688 19861 solver.cpp:258]     Train net output #0: loss = 0.000281407 (* 1 = 0.000281407 loss)
I0522 11:00:37.176693 19861 sgd_solver.cpp:112] Iteration 21380, lr = 0.0001
I0522 11:00:39.758410 19861 solver.cpp:239] Iteration 21400 (7.74679 iter/s, 2.58171s/20 iters), loss = 0.000208785
I0522 11:00:39.758478 19861 solver.cpp:258]     Train net output #0: loss = 0.000208711 (* 1 = 0.000208711 loss)
I0522 11:00:39.758482 19861 sgd_solver.cpp:112] Iteration 21400, lr = 0.0001
I0522 11:00:41.946162 19861 solver.cpp:239] Iteration 21420 (9.14214 iter/s, 2.18767s/20 iters), loss = 0.000374519
I0522 11:00:41.946226 19861 solver.cpp:258]     Train net output #0: loss = 0.000374445 (* 1 = 0.000374445 loss)
I0522 11:00:41.946236 19861 sgd_solver.cpp:112] Iteration 21420, lr = 0.0001
I0522 11:00:44.095698 19861 solver.cpp:239] Iteration 21440 (9.30464 iter/s, 2.14946s/20 iters), loss = 0.000275315
I0522 11:00:44.095757 19861 solver.cpp:258]     Train net output #0: loss = 0.000275241 (* 1 = 0.000275241 loss)
I0522 11:00:44.095762 19861 sgd_solver.cpp:112] Iteration 21440, lr = 0.0001
I0522 11:00:44.180094 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:00:46.335136 19861 solver.cpp:239] Iteration 21460 (8.93108 iter/s, 2.23937s/20 iters), loss = 0.000227405
I0522 11:00:46.335192 19861 solver.cpp:258]     Train net output #0: loss = 0.000227331 (* 1 = 0.000227331 loss)
I0522 11:00:46.335202 19861 sgd_solver.cpp:112] Iteration 21460, lr = 0.0001
I0522 11:00:48.777648 19861 solver.cpp:239] Iteration 21480 (8.19615 iter/s, 2.44017s/20 iters), loss = 9.21346e-05
I0522 11:00:48.791061 19861 solver.cpp:258]     Train net output #0: loss = 9.20604e-05 (* 1 = 9.20604e-05 loss)
I0522 11:00:48.791075 19861 sgd_solver.cpp:112] Iteration 21480, lr = 0.0001
I0522 11:00:50.961201 19861 solver.cpp:239] Iteration 21500 (9.21598 iter/s, 2.17014s/20 iters), loss = 0.000541073
I0522 11:00:50.970654 19861 solver.cpp:258]     Train net output #0: loss = 0.000540999 (* 1 = 0.000540999 loss)
I0522 11:00:50.970660 19861 sgd_solver.cpp:112] Iteration 21500, lr = 0.0001
I0522 11:00:53.157112 19861 solver.cpp:239] Iteration 21520 (9.14732 iter/s, 2.18643s/20 iters), loss = 0.000620879
I0522 11:00:53.157204 19861 solver.cpp:258]     Train net output #0: loss = 0.000620805 (* 1 = 0.000620805 loss)
I0522 11:00:53.157209 19861 sgd_solver.cpp:112] Iteration 21520, lr = 0.0001
I0522 11:00:55.615689 19861 solver.cpp:239] Iteration 21540 (8.13517 iter/s, 2.45846s/20 iters), loss = 0.000991959
I0522 11:00:55.615795 19861 solver.cpp:258]     Train net output #0: loss = 0.000991885 (* 1 = 0.000991885 loss)
I0522 11:00:55.615800 19861 sgd_solver.cpp:112] Iteration 21540, lr = 0.0001
I0522 11:00:57.786662 19861 solver.cpp:239] Iteration 21560 (9.21296 iter/s, 2.17086s/20 iters), loss = 0.000634148
I0522 11:00:57.796255 19861 solver.cpp:258]     Train net output #0: loss = 0.000634074 (* 1 = 0.000634074 loss)
I0522 11:00:57.796263 19861 sgd_solver.cpp:112] Iteration 21560, lr = 0.0001
I0522 11:00:59.988559 19861 solver.cpp:239] Iteration 21580 (9.12281 iter/s, 2.19231s/20 iters), loss = 0.000275851
I0522 11:00:59.997632 19861 solver.cpp:258]     Train net output #0: loss = 0.000275776 (* 1 = 0.000275776 loss)
I0522 11:00:59.997642 19861 sgd_solver.cpp:112] Iteration 21580, lr = 0.0001
I0522 11:01:01.511806 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:01:02.471248 19861 solver.cpp:239] Iteration 21600 (8.08539 iter/s, 2.4736s/20 iters), loss = 0.000717891
I0522 11:01:02.471365 19861 solver.cpp:258]     Train net output #0: loss = 0.000717816 (* 1 = 0.000717816 loss)
I0522 11:01:02.471371 19861 sgd_solver.cpp:112] Iteration 21600, lr = 0.0001
I0522 11:01:04.671039 19861 solver.cpp:239] Iteration 21620 (9.09231 iter/s, 2.19966s/20 iters), loss = 0.000946092
I0522 11:01:04.671185 19861 solver.cpp:258]     Train net output #0: loss = 0.000946017 (* 1 = 0.000946017 loss)
I0522 11:01:04.671190 19861 sgd_solver.cpp:112] Iteration 21620, lr = 0.0001
I0522 11:01:06.872004 19861 solver.cpp:239] Iteration 21640 (9.08754 iter/s, 2.20082s/20 iters), loss = 0.000145651
I0522 11:01:06.872323 19861 solver.cpp:258]     Train net output #0: loss = 0.000145576 (* 1 = 0.000145576 loss)
I0522 11:01:06.872328 19861 sgd_solver.cpp:112] Iteration 21640, lr = 0.0001
I0522 11:01:09.061640 19861 solver.cpp:239] Iteration 21660 (9.13539 iter/s, 2.18929s/20 iters), loss = 0.00171158
I0522 11:01:09.061753 19861 solver.cpp:258]     Train net output #0: loss = 0.00171151 (* 1 = 0.00171151 loss)
I0522 11:01:09.061764 19861 sgd_solver.cpp:112] Iteration 21660, lr = 0.0001
I0522 11:01:11.519084 19861 solver.cpp:239] Iteration 21680 (8.13892 iter/s, 2.45733s/20 iters), loss = 0.000861432
I0522 11:01:11.519156 19861 solver.cpp:258]     Train net output #0: loss = 0.000861357 (* 1 = 0.000861357 loss)
I0522 11:01:11.519160 19861 sgd_solver.cpp:112] Iteration 21680, lr = 0.0001
I0522 11:01:13.753155 19861 solver.cpp:239] Iteration 21700 (8.95251 iter/s, 2.23401s/20 iters), loss = 0.000371994
I0522 11:01:13.753185 19861 solver.cpp:258]     Train net output #0: loss = 0.000371919 (* 1 = 0.000371919 loss)
I0522 11:01:13.753190 19861 sgd_solver.cpp:112] Iteration 21700, lr = 0.0001
I0522 11:01:15.945008 19861 solver.cpp:239] Iteration 21720 (9.12487 iter/s, 2.19181s/20 iters), loss = 0.000528035
I0522 11:01:15.945070 19861 solver.cpp:258]     Train net output #0: loss = 0.00052796 (* 1 = 0.00052796 loss)
I0522 11:01:15.945075 19861 sgd_solver.cpp:112] Iteration 21720, lr = 0.0001
I0522 11:01:18.479130 19861 solver.cpp:239] Iteration 21740 (7.89247 iter/s, 2.53406s/20 iters), loss = 0.000236363
I0522 11:01:18.479182 19861 solver.cpp:258]     Train net output #0: loss = 0.000236288 (* 1 = 0.000236288 loss)
I0522 11:01:18.479187 19861 sgd_solver.cpp:112] Iteration 21740, lr = 0.0001
I0522 11:01:19.232653 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:01:20.671123 19861 solver.cpp:239] Iteration 21760 (9.12434 iter/s, 2.19194s/20 iters), loss = 0.000433308
I0522 11:01:20.671178 19861 solver.cpp:258]     Train net output #0: loss = 0.000433233 (* 1 = 0.000433233 loss)
I0522 11:01:20.671182 19861 sgd_solver.cpp:112] Iteration 21760, lr = 0.0001
I0522 11:01:22.833040 19861 solver.cpp:239] Iteration 21780 (9.25131 iter/s, 2.16186s/20 iters), loss = 0.00022928
I0522 11:01:22.833102 19861 solver.cpp:258]     Train net output #0: loss = 0.000229205 (* 1 = 0.000229205 loss)
I0522 11:01:22.833107 19861 sgd_solver.cpp:112] Iteration 21780, lr = 0.0001
I0522 11:01:25.293159 19861 solver.cpp:239] Iteration 21800 (8.1299 iter/s, 2.46006s/20 iters), loss = 0.000200438
I0522 11:01:25.293201 19861 solver.cpp:258]     Train net output #0: loss = 0.000200363 (* 1 = 0.000200363 loss)
I0522 11:01:25.293205 19861 sgd_solver.cpp:112] Iteration 21800, lr = 0.0001
I0522 11:01:27.768023 19861 solver.cpp:239] Iteration 21820 (8.08158 iter/s, 2.47477s/20 iters), loss = 0.000278352
I0522 11:01:27.768311 19861 solver.cpp:258]     Train net output #0: loss = 0.000278277 (* 1 = 0.000278277 loss)
I0522 11:01:27.768342 19861 sgd_solver.cpp:112] Iteration 21820, lr = 0.0001
I0522 11:01:30.549767 19861 solver.cpp:239] Iteration 21840 (7.19048 iter/s, 2.78146s/20 iters), loss = 0.00130073
I0522 11:01:30.549845 19861 solver.cpp:258]     Train net output #0: loss = 0.00130066 (* 1 = 0.00130066 loss)
I0522 11:01:30.549856 19861 sgd_solver.cpp:112] Iteration 21840, lr = 0.0001
I0522 11:01:33.128163 19861 solver.cpp:239] Iteration 21860 (7.75703 iter/s, 2.57831s/20 iters), loss = 0.000148381
I0522 11:01:33.128253 19861 solver.cpp:258]     Train net output #0: loss = 0.000148306 (* 1 = 0.000148306 loss)
I0522 11:01:33.128259 19861 sgd_solver.cpp:112] Iteration 21860, lr = 0.0001
I0522 11:01:35.761768 19861 solver.cpp:239] Iteration 21880 (7.59446 iter/s, 2.6335s/20 iters), loss = 0.000304442
I0522 11:01:35.761883 19861 solver.cpp:258]     Train net output #0: loss = 0.000304367 (* 1 = 0.000304367 loss)
I0522 11:01:35.761891 19861 sgd_solver.cpp:112] Iteration 21880, lr = 0.0001
I0522 11:01:37.925945 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:01:37.952502 19861 solver.cpp:239] Iteration 21900 (9.12983 iter/s, 2.19062s/20 iters), loss = 0.000277294
I0522 11:01:37.962710 19861 solver.cpp:258]     Train net output #0: loss = 0.00027722 (* 1 = 0.00027722 loss)
I0522 11:01:37.962718 19861 sgd_solver.cpp:112] Iteration 21900, lr = 0.0001
I0522 11:01:40.037155 19861 solver.cpp:239] Iteration 21920 (9.64119 iter/s, 2.07443s/20 iters), loss = 0.000259367
I0522 11:01:40.037240 19861 solver.cpp:258]     Train net output #0: loss = 0.000259293 (* 1 = 0.000259293 loss)
I0522 11:01:40.037245 19861 sgd_solver.cpp:112] Iteration 21920, lr = 0.0001
I0522 11:01:42.405397 19861 solver.cpp:239] Iteration 21940 (8.44538 iter/s, 2.36816s/20 iters), loss = 0.000584482
I0522 11:01:42.416656 19861 solver.cpp:258]     Train net output #0: loss = 0.000584407 (* 1 = 0.000584407 loss)
I0522 11:01:42.416663 19861 sgd_solver.cpp:112] Iteration 21940, lr = 0.0001
I0522 11:01:44.523618 19861 solver.cpp:239] Iteration 21960 (9.49242 iter/s, 2.10694s/20 iters), loss = 0.000216697
I0522 11:01:44.523715 19861 solver.cpp:258]     Train net output #0: loss = 0.000216622 (* 1 = 0.000216622 loss)
I0522 11:01:44.523720 19861 sgd_solver.cpp:112] Iteration 21960, lr = 0.0001
I0522 11:01:46.623905 19861 solver.cpp:239] Iteration 21980 (9.52301 iter/s, 2.10018s/20 iters), loss = 0.00211663
I0522 11:01:46.623980 19861 solver.cpp:258]     Train net output #0: loss = 0.00211656 (* 1 = 0.00211656 loss)
I0522 11:01:46.623983 19861 sgd_solver.cpp:112] Iteration 21980, lr = 0.0001
I0522 11:01:48.594404 19861 solver.cpp:347] Iteration 22000, Testing net (#0)
I0522 11:01:52.359321 19861 blocking_queue.cpp:49] Waiting for data
I0522 11:01:52.533285 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:01:56.497758 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:02:00.694468 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:02:04.849972 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:02:05.102290 19861 solver.cpp:414]     Test net output #0: accuracy = 0.877882
I0522 11:02:05.102342 19861 solver.cpp:414]     Test net output #1: loss = 0.789868 (* 1 = 0.789868 loss)
I0522 11:02:05.201122 19861 solver.cpp:239] Iteration 22000 (1.07659 iter/s, 18.5772s/20 iters), loss = 0.000619104
I0522 11:02:05.202993 19861 solver.cpp:258]     Train net output #0: loss = 0.000619029 (* 1 = 0.000619029 loss)
I0522 11:02:05.203002 19861 sgd_solver.cpp:112] Iteration 22000, lr = 0.0001
I0522 11:02:07.324115 19861 solver.cpp:239] Iteration 22020 (9.42911 iter/s, 2.12109s/20 iters), loss = 0.000441412
I0522 11:02:07.324215 19861 solver.cpp:258]     Train net output #0: loss = 0.000441338 (* 1 = 0.000441338 loss)
I0522 11:02:07.324221 19861 sgd_solver.cpp:112] Iteration 22020, lr = 0.0001
I0522 11:02:09.440887 19861 solver.cpp:239] Iteration 22040 (9.44881 iter/s, 2.11667s/20 iters), loss = 0.000107466
I0522 11:02:09.449965 19861 solver.cpp:258]     Train net output #0: loss = 0.000107393 (* 1 = 0.000107393 loss)
I0522 11:02:09.449975 19861 sgd_solver.cpp:112] Iteration 22040, lr = 0.0001
I0522 11:02:10.880245 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:02:11.592192 19861 solver.cpp:239] Iteration 22060 (9.33614 iter/s, 2.14221s/20 iters), loss = 0.000949705
I0522 11:02:11.605692 19861 solver.cpp:258]     Train net output #0: loss = 0.000949631 (* 1 = 0.000949631 loss)
I0522 11:02:11.605703 19861 sgd_solver.cpp:112] Iteration 22060, lr = 0.0001
I0522 11:02:14.131655 19861 solver.cpp:239] Iteration 22080 (7.91781 iter/s, 2.52595s/20 iters), loss = 0.00051942
I0522 11:02:14.131741 19861 solver.cpp:258]     Train net output #0: loss = 0.000519347 (* 1 = 0.000519347 loss)
I0522 11:02:14.131745 19861 sgd_solver.cpp:112] Iteration 22080, lr = 0.0001
I0522 11:02:16.265043 19861 solver.cpp:239] Iteration 22100 (9.37518 iter/s, 2.13329s/20 iters), loss = 0.00101592
I0522 11:02:16.274549 19861 solver.cpp:258]     Train net output #0: loss = 0.00101585 (* 1 = 0.00101585 loss)
I0522 11:02:16.274556 19861 sgd_solver.cpp:112] Iteration 22100, lr = 0.0001
I0522 11:02:18.294373 19861 solver.cpp:239] Iteration 22120 (9.9019 iter/s, 2.01981s/20 iters), loss = 0.005598
I0522 11:02:18.303797 19861 solver.cpp:258]     Train net output #0: loss = 0.00559793 (* 1 = 0.00559793 loss)
I0522 11:02:18.303805 19861 sgd_solver.cpp:112] Iteration 22120, lr = 0.0001
I0522 11:02:20.332125 19861 solver.cpp:239] Iteration 22140 (9.86035 iter/s, 2.02833s/20 iters), loss = 0.00041061
I0522 11:02:20.341531 19861 solver.cpp:258]     Train net output #0: loss = 0.000410537 (* 1 = 0.000410537 loss)
I0522 11:02:20.341538 19861 sgd_solver.cpp:112] Iteration 22140, lr = 0.0001
I0522 11:02:22.369129 19861 solver.cpp:239] Iteration 22160 (9.86398 iter/s, 2.02758s/20 iters), loss = 0.000708508
I0522 11:02:22.369222 19861 solver.cpp:258]     Train net output #0: loss = 0.000708435 (* 1 = 0.000708435 loss)
I0522 11:02:22.369226 19861 sgd_solver.cpp:112] Iteration 22160, lr = 0.0001
I0522 11:02:26.000895 19861 solver.cpp:239] Iteration 22180 (5.5071 iter/s, 3.63168s/20 iters), loss = 9.15835e-05
I0522 11:02:26.000941 19861 solver.cpp:258]     Train net output #0: loss = 9.15103e-05 (* 1 = 9.15103e-05 loss)
I0522 11:02:26.000944 19861 sgd_solver.cpp:112] Iteration 22180, lr = 0.0001
I0522 11:02:28.140408 19861 solver.cpp:239] Iteration 22200 (9.34818 iter/s, 2.13946s/20 iters), loss = 9.04484e-05
I0522 11:02:28.149880 19861 solver.cpp:258]     Train net output #0: loss = 9.03754e-05 (* 1 = 9.03754e-05 loss)
I0522 11:02:28.149888 19861 sgd_solver.cpp:112] Iteration 22200, lr = 0.0001
I0522 11:02:28.786974 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:02:30.189780 19861 solver.cpp:239] Iteration 22220 (9.80455 iter/s, 2.03987s/20 iters), loss = 0.00063857
I0522 11:02:30.189882 19861 solver.cpp:258]     Train net output #0: loss = 0.000638497 (* 1 = 0.000638497 loss)
I0522 11:02:30.189891 19861 sgd_solver.cpp:112] Iteration 22220, lr = 0.0001
I0522 11:02:32.247160 19861 solver.cpp:239] Iteration 22240 (9.72162 iter/s, 2.05727s/20 iters), loss = 0.000473752
I0522 11:02:32.247236 19861 solver.cpp:258]     Train net output #0: loss = 0.000473678 (* 1 = 0.000473678 loss)
I0522 11:02:32.247244 19861 sgd_solver.cpp:112] Iteration 22240, lr = 0.0001
I0522 11:02:35.084791 19861 solver.cpp:239] Iteration 22260 (7.0483 iter/s, 2.83756s/20 iters), loss = 0.000421321
I0522 11:02:35.094209 19861 solver.cpp:258]     Train net output #0: loss = 0.000421248 (* 1 = 0.000421248 loss)
I0522 11:02:35.094218 19861 sgd_solver.cpp:112] Iteration 22260, lr = 0.0001
I0522 11:02:37.410311 19861 blocking_queue.cpp:49] Waiting for data
I0522 11:02:37.877543 19861 solver.cpp:239] Iteration 22280 (7.18564 iter/s, 2.78333s/20 iters), loss = 0.000881184
I0522 11:02:37.887096 19861 solver.cpp:258]     Train net output #0: loss = 0.000881111 (* 1 = 0.000881111 loss)
I0522 11:02:37.887104 19861 sgd_solver.cpp:112] Iteration 22280, lr = 0.0001
I0522 11:02:39.919034 19861 solver.cpp:239] Iteration 22300 (9.84286 iter/s, 2.03193s/20 iters), loss = 0.000317088
I0522 11:02:39.928650 19861 solver.cpp:258]     Train net output #0: loss = 0.000317016 (* 1 = 0.000317016 loss)
I0522 11:02:39.928658 19861 sgd_solver.cpp:112] Iteration 22300, lr = 0.0001
I0522 11:02:41.964382 19861 solver.cpp:239] Iteration 22320 (9.82496 iter/s, 2.03563s/20 iters), loss = 0.000420058
I0522 11:02:41.974030 19861 solver.cpp:258]     Train net output #0: loss = 0.000419986 (* 1 = 0.000419986 loss)
I0522 11:02:41.974038 19861 sgd_solver.cpp:112] Iteration 22320, lr = 0.0001
I0522 11:02:44.234288 19861 solver.cpp:239] Iteration 22340 (8.84863 iter/s, 2.26024s/20 iters), loss = 0.000919461
I0522 11:02:44.247337 19861 solver.cpp:258]     Train net output #0: loss = 0.000919389 (* 1 = 0.000919389 loss)
I0522 11:02:44.247360 19861 sgd_solver.cpp:112] Iteration 22340, lr = 0.0001
I0522 11:02:47.542547 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:02:47.685691 19861 solver.cpp:239] Iteration 22360 (5.81678 iter/s, 3.43833s/20 iters), loss = 0.000154984
I0522 11:02:47.685817 19861 solver.cpp:258]     Train net output #0: loss = 0.000154911 (* 1 = 0.000154911 loss)
I0522 11:02:47.685832 19861 sgd_solver.cpp:112] Iteration 22360, lr = 0.0001
I0522 11:02:49.881846 19861 solver.cpp:239] Iteration 22380 (9.10761 iter/s, 2.19597s/20 iters), loss = 0.000120998
I0522 11:02:49.882002 19861 solver.cpp:258]     Train net output #0: loss = 0.000120925 (* 1 = 0.000120925 loss)
I0522 11:02:49.882009 19861 sgd_solver.cpp:112] Iteration 22380, lr = 0.0001
I0522 11:02:52.081017 19861 solver.cpp:239] Iteration 22400 (9.09504 iter/s, 2.199s/20 iters), loss = 0.000241601
I0522 11:02:52.081097 19861 solver.cpp:258]     Train net output #0: loss = 0.000241527 (* 1 = 0.000241527 loss)
I0522 11:02:52.081106 19861 sgd_solver.cpp:112] Iteration 22400, lr = 0.0001
I0522 11:02:54.279431 19861 solver.cpp:239] Iteration 22420 (9.09786 iter/s, 2.19832s/20 iters), loss = 0.0002064
I0522 11:02:54.279511 19861 solver.cpp:258]     Train net output #0: loss = 0.000206327 (* 1 = 0.000206327 loss)
I0522 11:02:54.279520 19861 sgd_solver.cpp:112] Iteration 22420, lr = 0.0001
I0522 11:02:57.834820 19861 solver.cpp:239] Iteration 22440 (5.62539 iter/s, 3.55531s/20 iters), loss = 0.0020793
I0522 11:02:57.845197 19861 solver.cpp:258]     Train net output #0: loss = 0.00207922 (* 1 = 0.00207922 loss)
I0522 11:02:57.845209 19861 sgd_solver.cpp:112] Iteration 22440, lr = 0.0001
I0522 11:02:59.888846 19861 solver.cpp:239] Iteration 22460 (9.78692 iter/s, 2.04354s/20 iters), loss = 0.000792784
I0522 11:02:59.898366 19861 solver.cpp:258]     Train net output #0: loss = 0.000792711 (* 1 = 0.000792711 loss)
I0522 11:02:59.898378 19861 sgd_solver.cpp:112] Iteration 22460, lr = 0.0001
I0522 11:03:01.938211 19861 solver.cpp:239] Iteration 22480 (9.80472 iter/s, 2.03983s/20 iters), loss = 0.00195077
I0522 11:03:01.947607 19861 solver.cpp:258]     Train net output #0: loss = 0.0019507 (* 1 = 0.0019507 loss)
I0522 11:03:01.947616 19861 sgd_solver.cpp:112] Iteration 22480, lr = 0.0001
I0522 11:03:03.986946 19861 solver.cpp:239] Iteration 22500 (9.80715 iter/s, 2.03933s/20 iters), loss = 0.000821874
I0522 11:03:03.996531 19861 solver.cpp:258]     Train net output #0: loss = 0.000821801 (* 1 = 0.000821801 loss)
I0522 11:03:03.996539 19861 sgd_solver.cpp:112] Iteration 22500, lr = 0.0001
I0522 11:03:05.271299 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:03:06.044050 19861 solver.cpp:239] Iteration 22520 (9.76805 iter/s, 2.04749s/20 iters), loss = 0.000209683
I0522 11:03:06.056552 19861 solver.cpp:258]     Train net output #0: loss = 0.000209609 (* 1 = 0.000209609 loss)
I0522 11:03:06.056588 19861 sgd_solver.cpp:112] Iteration 22520, lr = 0.0001
I0522 11:03:09.603107 19861 solver.cpp:239] Iteration 22540 (5.63921 iter/s, 3.5466s/20 iters), loss = 0.00856575
I0522 11:03:09.612641 19861 solver.cpp:258]     Train net output #0: loss = 0.00856567 (* 1 = 0.00856567 loss)
I0522 11:03:09.612648 19861 sgd_solver.cpp:112] Iteration 22540, lr = 0.0001
I0522 11:03:11.665158 19861 solver.cpp:239] Iteration 22560 (9.74417 iter/s, 2.05251s/20 iters), loss = 0.0013813
I0522 11:03:11.674754 19861 solver.cpp:258]     Train net output #0: loss = 0.00138123 (* 1 = 0.00138123 loss)
I0522 11:03:11.674763 19861 sgd_solver.cpp:112] Iteration 22560, lr = 0.0001
I0522 11:03:13.712054 19861 solver.cpp:239] Iteration 22580 (9.81698 iter/s, 2.03729s/20 iters), loss = 0.000366328
I0522 11:03:13.721585 19861 solver.cpp:258]     Train net output #0: loss = 0.000366255 (* 1 = 0.000366255 loss)
I0522 11:03:13.721594 19861 sgd_solver.cpp:112] Iteration 22580, lr = 0.0001
I0522 11:03:15.764101 19861 solver.cpp:239] Iteration 22600 (9.79187 iter/s, 2.04251s/20 iters), loss = 0.000351465
I0522 11:03:15.773774 19861 solver.cpp:258]     Train net output #0: loss = 0.000351392 (* 1 = 0.000351392 loss)
I0522 11:03:15.773782 19861 sgd_solver.cpp:112] Iteration 22600, lr = 0.0001
I0522 11:03:18.878208 19861 solver.cpp:239] Iteration 22620 (6.44239 iter/s, 3.10444s/20 iters), loss = 0.000558131
I0522 11:03:18.887749 19861 solver.cpp:258]     Train net output #0: loss = 0.000558057 (* 1 = 0.000558057 loss)
I0522 11:03:18.887756 19861 sgd_solver.cpp:112] Iteration 22620, lr = 0.0001
I0522 11:03:21.437944 19861 solver.cpp:239] Iteration 22640 (7.84259 iter/s, 2.55018s/20 iters), loss = 0.000232189
I0522 11:03:21.447574 19861 solver.cpp:258]     Train net output #0: loss = 0.000232115 (* 1 = 0.000232115 loss)
I0522 11:03:21.447582 19861 sgd_solver.cpp:112] Iteration 22640, lr = 0.0001
I0522 11:03:23.497714 19861 solver.cpp:239] Iteration 22660 (9.75546 iter/s, 2.05013s/20 iters), loss = 0.00675217
I0522 11:03:23.507302 19861 solver.cpp:258]     Train net output #0: loss = 0.00675209 (* 1 = 0.00675209 loss)
I0522 11:03:23.507310 19861 sgd_solver.cpp:112] Iteration 22660, lr = 0.0001
I0522 11:03:24.079795 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:03:25.553416 19861 solver.cpp:239] Iteration 22680 (9.77463 iter/s, 2.04611s/20 iters), loss = 0.0005533
I0522 11:03:25.563477 19861 solver.cpp:258]     Train net output #0: loss = 0.000553225 (* 1 = 0.000553225 loss)
I0522 11:03:25.563484 19861 sgd_solver.cpp:112] Iteration 22680, lr = 0.0001
I0522 11:03:27.618866 19861 solver.cpp:239] Iteration 22700 (9.73054 iter/s, 2.05538s/20 iters), loss = 0.000218722
I0522 11:03:27.628760 19861 solver.cpp:258]     Train net output #0: loss = 0.000218647 (* 1 = 0.000218647 loss)
I0522 11:03:27.628768 19861 sgd_solver.cpp:112] Iteration 22700, lr = 0.0001
I0522 11:03:31.195230 19861 solver.cpp:239] Iteration 22720 (5.60777 iter/s, 3.56648s/20 iters), loss = 0.000510855
I0522 11:03:31.215113 19861 solver.cpp:258]     Train net output #0: loss = 0.000510781 (* 1 = 0.000510781 loss)
I0522 11:03:31.215127 19861 sgd_solver.cpp:112] Iteration 22720, lr = 0.0001
I0522 11:03:33.425515 19861 solver.cpp:239] Iteration 22740 (9.04822 iter/s, 2.21038s/20 iters), loss = 0.000656454
I0522 11:03:33.425604 19861 solver.cpp:258]     Train net output #0: loss = 0.000656379 (* 1 = 0.000656379 loss)
I0522 11:03:33.425609 19861 sgd_solver.cpp:112] Iteration 22740, lr = 0.0001
I0522 11:03:35.622161 19861 solver.cpp:239] Iteration 22760 (9.1052 iter/s, 2.19655s/20 iters), loss = 0.00157716
I0522 11:03:35.622252 19861 solver.cpp:258]     Train net output #0: loss = 0.00157709 (* 1 = 0.00157709 loss)
I0522 11:03:35.622262 19861 sgd_solver.cpp:112] Iteration 22760, lr = 0.0001
I0522 11:03:37.839411 19861 solver.cpp:239] Iteration 22780 (9.02056 iter/s, 2.21716s/20 iters), loss = 0.000218009
I0522 11:03:37.848825 19861 solver.cpp:258]     Train net output #0: loss = 0.000217934 (* 1 = 0.000217934 loss)
I0522 11:03:37.848832 19861 sgd_solver.cpp:112] Iteration 22780, lr = 0.0001
I0522 11:03:40.052345 19861 solver.cpp:239] Iteration 22800 (9.0764 iter/s, 2.20352s/20 iters), loss = 0.000198461
I0522 11:03:40.052413 19861 solver.cpp:258]     Train net output #0: loss = 0.000198386 (* 1 = 0.000198386 loss)
I0522 11:03:40.052417 19861 sgd_solver.cpp:112] Iteration 22800, lr = 0.0001
I0522 11:03:43.459343 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:03:43.576647 19861 solver.cpp:239] Iteration 22820 (5.67498 iter/s, 3.52424s/20 iters), loss = 0.000311534
I0522 11:03:43.586033 19861 solver.cpp:258]     Train net output #0: loss = 0.000311458 (* 1 = 0.000311458 loss)
I0522 11:03:43.586040 19861 sgd_solver.cpp:112] Iteration 22820, lr = 0.0001
I0522 11:03:45.629803 19861 solver.cpp:239] Iteration 22840 (9.78587 iter/s, 2.04376s/20 iters), loss = 0.00223993
I0522 11:03:45.639292 19861 solver.cpp:258]     Train net output #0: loss = 0.00223985 (* 1 = 0.00223985 loss)
I0522 11:03:45.639300 19861 sgd_solver.cpp:112] Iteration 22840, lr = 0.0001
I0522 11:03:47.683666 19861 solver.cpp:239] Iteration 22860 (9.78308 iter/s, 2.04435s/20 iters), loss = 0.00190665
I0522 11:03:47.693055 19861 solver.cpp:258]     Train net output #0: loss = 0.00190658 (* 1 = 0.00190658 loss)
I0522 11:03:47.693063 19861 sgd_solver.cpp:112] Iteration 22860, lr = 0.0001
I0522 11:03:49.748522 19861 solver.cpp:239] Iteration 22880 (9.73019 iter/s, 2.05546s/20 iters), loss = 0.000209382
I0522 11:03:49.758050 19861 solver.cpp:258]     Train net output #0: loss = 0.000209307 (* 1 = 0.000209307 loss)
I0522 11:03:49.758059 19861 sgd_solver.cpp:112] Iteration 22880, lr = 0.0001
I0522 11:03:52.218452 19861 solver.cpp:239] Iteration 22900 (8.12877 iter/s, 2.4604s/20 iters), loss = 0.000554174
I0522 11:03:52.232311 19861 solver.cpp:258]     Train net output #0: loss = 0.000554099 (* 1 = 0.000554099 loss)
I0522 11:03:52.232319 19861 sgd_solver.cpp:112] Iteration 22900, lr = 0.0001
I0522 11:03:55.405412 19861 solver.cpp:239] Iteration 22920 (6.30304 iter/s, 3.17307s/20 iters), loss = 0.00192919
I0522 11:03:55.414964 19861 solver.cpp:258]     Train net output #0: loss = 0.00192911 (* 1 = 0.00192911 loss)
I0522 11:03:55.414973 19861 sgd_solver.cpp:112] Iteration 22920, lr = 0.0001
I0522 11:03:57.445600 19861 solver.cpp:239] Iteration 22940 (9.8492 iter/s, 2.03062s/20 iters), loss = 0.000378462
I0522 11:03:57.455313 19861 solver.cpp:258]     Train net output #0: loss = 0.000378388 (* 1 = 0.000378388 loss)
I0522 11:03:57.455323 19861 sgd_solver.cpp:112] Iteration 22940, lr = 0.0001
I0522 11:03:59.488988 19861 solver.cpp:239] Iteration 22960 (9.83451 iter/s, 2.03365s/20 iters), loss = 0.000346925
I0522 11:03:59.498435 19861 solver.cpp:258]     Train net output #0: loss = 0.000346851 (* 1 = 0.000346851 loss)
I0522 11:03:59.498443 19861 sgd_solver.cpp:112] Iteration 22960, lr = 0.0001
I0522 11:04:00.749428 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:04:01.538019 19861 solver.cpp:239] Iteration 22980 (9.80596 iter/s, 2.03958s/20 iters), loss = 0.000237729
I0522 11:04:01.547708 19861 solver.cpp:258]     Train net output #0: loss = 0.000237654 (* 1 = 0.000237654 loss)
I0522 11:04:01.547716 19861 sgd_solver.cpp:112] Iteration 22980, lr = 0.0001
I0522 11:04:04.938740 19861 solver.cpp:347] Iteration 23000, Testing net (#0)
I0522 11:04:09.617787 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:04:13.758319 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:04:13.800874 19861 blocking_queue.cpp:49] Waiting for data
I0522 11:04:18.888958 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:04:22.597002 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:04:22.651587 19861 solver.cpp:414]     Test net output #0: accuracy = 0.878183
I0522 11:04:22.651646 19861 solver.cpp:414]     Test net output #1: loss = 0.787812 (* 1 = 0.787812 loss)
I0522 11:04:22.748526 19861 solver.cpp:239] Iteration 23000 (0.943355 iter/s, 21.2009s/20 iters), loss = 0.000628434
I0522 11:04:22.750511 19861 solver.cpp:258]     Train net output #0: loss = 0.00062836 (* 1 = 0.00062836 loss)
I0522 11:04:22.750522 19861 sgd_solver.cpp:112] Iteration 23000, lr = 0.0001
I0522 11:04:24.938927 19861 solver.cpp:239] Iteration 23020 (9.13907 iter/s, 2.18841s/20 iters), loss = 0.000466792
I0522 11:04:24.939040 19861 solver.cpp:258]     Train net output #0: loss = 0.000466718 (* 1 = 0.000466718 loss)
I0522 11:04:24.939045 19861 sgd_solver.cpp:112] Iteration 23020, lr = 0.0001
I0522 11:04:28.362574 19861 solver.cpp:239] Iteration 23040 (5.84191 iter/s, 3.42354s/20 iters), loss = 0.00027134
I0522 11:04:28.372095 19861 solver.cpp:258]     Train net output #0: loss = 0.000271266 (* 1 = 0.000271266 loss)
I0522 11:04:28.372102 19861 sgd_solver.cpp:112] Iteration 23040, lr = 0.0001
I0522 11:04:30.403744 19861 solver.cpp:239] Iteration 23060 (9.84429 iter/s, 2.03164s/20 iters), loss = 0.000393249
I0522 11:04:30.413313 19861 solver.cpp:258]     Train net output #0: loss = 0.000393175 (* 1 = 0.000393175 loss)
I0522 11:04:30.413322 19861 sgd_solver.cpp:112] Iteration 23060, lr = 0.0001
I0522 11:04:32.442099 19861 solver.cpp:239] Iteration 23080 (9.85818 iter/s, 2.02877s/20 iters), loss = 0.000657884
I0522 11:04:32.451434 19861 solver.cpp:258]     Train net output #0: loss = 0.00065781 (* 1 = 0.00065781 loss)
I0522 11:04:32.451442 19861 sgd_solver.cpp:112] Iteration 23080, lr = 0.0001
I0522 11:04:34.480589 19861 solver.cpp:239] Iteration 23100 (9.85643 iter/s, 2.02913s/20 iters), loss = 0.000771
I0522 11:04:34.489984 19861 solver.cpp:258]     Train net output #0: loss = 0.000770926 (* 1 = 0.000770926 loss)
I0522 11:04:34.489991 19861 sgd_solver.cpp:112] Iteration 23100, lr = 0.0001
I0522 11:04:37.308794 19861 solver.cpp:239] Iteration 23120 (7.09518 iter/s, 2.81882s/20 iters), loss = 0.000265671
I0522 11:04:37.318228 19861 solver.cpp:258]     Train net output #0: loss = 0.000265596 (* 1 = 0.000265596 loss)
I0522 11:04:37.318235 19861 sgd_solver.cpp:112] Iteration 23120, lr = 0.0001
I0522 11:04:38.383939 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:04:40.104885 19861 solver.cpp:239] Iteration 23140 (7.17717 iter/s, 2.78662s/20 iters), loss = 0.000704984
I0522 11:04:40.114500 19861 solver.cpp:258]     Train net output #0: loss = 0.00070491 (* 1 = 0.00070491 loss)
I0522 11:04:40.114507 19861 sgd_solver.cpp:112] Iteration 23140, lr = 0.0001
I0522 11:04:42.148469 19861 solver.cpp:239] Iteration 23160 (9.83307 iter/s, 2.03395s/20 iters), loss = 0.000722104
I0522 11:04:42.157989 19861 solver.cpp:258]     Train net output #0: loss = 0.00072203 (* 1 = 0.00072203 loss)
I0522 11:04:42.157999 19861 sgd_solver.cpp:112] Iteration 23160, lr = 0.0001
I0522 11:04:44.194278 19861 solver.cpp:239] Iteration 23180 (9.82202 iter/s, 2.03624s/20 iters), loss = 0.00026577
I0522 11:04:44.194816 19861 solver.cpp:258]     Train net output #0: loss = 0.000265696 (* 1 = 0.000265696 loss)
I0522 11:04:44.194824 19861 sgd_solver.cpp:112] Iteration 23180, lr = 0.0001
I0522 11:04:47.193356 19861 solver.cpp:239] Iteration 23200 (6.66992 iter/s, 2.99854s/20 iters), loss = 0.000450054
I0522 11:04:47.206701 19861 solver.cpp:258]     Train net output #0: loss = 0.00044998 (* 1 = 0.00044998 loss)
I0522 11:04:47.206709 19861 sgd_solver.cpp:112] Iteration 23200, lr = 0.0001
I0522 11:04:49.236536 19861 solver.cpp:239] Iteration 23220 (9.85299 iter/s, 2.02984s/20 iters), loss = 0.00131736
I0522 11:04:49.245823 19861 solver.cpp:258]     Train net output #0: loss = 0.00131729 (* 1 = 0.00131729 loss)
I0522 11:04:49.245831 19861 sgd_solver.cpp:112] Iteration 23220, lr = 0.0001
I0522 11:04:51.284744 19861 solver.cpp:239] Iteration 23240 (9.80911 iter/s, 2.03892s/20 iters), loss = 0.00190905
I0522 11:04:51.294075 19861 solver.cpp:258]     Train net output #0: loss = 0.00190898 (* 1 = 0.00190898 loss)
I0522 11:04:51.294085 19861 sgd_solver.cpp:112] Iteration 23240, lr = 0.0001
I0522 11:04:53.334331 19861 solver.cpp:239] Iteration 23260 (9.80269 iter/s, 2.04026s/20 iters), loss = 0.000447756
I0522 11:04:53.343441 19861 solver.cpp:258]     Train net output #0: loss = 0.000447683 (* 1 = 0.000447683 loss)
I0522 11:04:53.343448 19861 sgd_solver.cpp:112] Iteration 23260, lr = 0.0001
I0522 11:04:55.216652 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:04:55.377962 19861 solver.cpp:239] Iteration 23280 (9.83032 iter/s, 2.03452s/20 iters), loss = 0.000302164
I0522 11:04:55.387050 19861 solver.cpp:258]     Train net output #0: loss = 0.000302091 (* 1 = 0.000302091 loss)
I0522 11:04:55.387058 19861 sgd_solver.cpp:112] Iteration 23280, lr = 0.0001
I0522 11:04:57.428450 19861 solver.cpp:239] Iteration 23300 (9.79719 iter/s, 2.0414s/20 iters), loss = 0.000271184
I0522 11:04:57.437620 19861 solver.cpp:258]     Train net output #0: loss = 0.000271111 (* 1 = 0.000271111 loss)
I0522 11:04:57.437626 19861 sgd_solver.cpp:112] Iteration 23300, lr = 0.0001
I0522 11:04:59.479045 19861 solver.cpp:239] Iteration 23320 (9.79708 iter/s, 2.04142s/20 iters), loss = 0.000888996
I0522 11:04:59.488149 19861 solver.cpp:258]     Train net output #0: loss = 0.000888924 (* 1 = 0.000888924 loss)
I0522 11:04:59.488157 19861 sgd_solver.cpp:112] Iteration 23320, lr = 0.0001
I0522 11:05:01.525902 19861 solver.cpp:239] Iteration 23340 (9.81473 iter/s, 2.03775s/20 iters), loss = 0.000721518
I0522 11:05:01.534992 19861 solver.cpp:258]     Train net output #0: loss = 0.000721446 (* 1 = 0.000721446 loss)
I0522 11:05:01.534999 19861 sgd_solver.cpp:112] Iteration 23340, lr = 0.0001
I0522 11:05:03.581125 19861 solver.cpp:239] Iteration 23360 (9.77454 iter/s, 2.04613s/20 iters), loss = 0.00126248
I0522 11:05:03.581171 19861 solver.cpp:258]     Train net output #0: loss = 0.0012624 (* 1 = 0.0012624 loss)
I0522 11:05:03.581176 19861 sgd_solver.cpp:112] Iteration 23360, lr = 0.0001
I0522 11:05:05.655217 19861 solver.cpp:239] Iteration 23380 (9.64298 iter/s, 2.07405s/20 iters), loss = 0.000204918
I0522 11:05:05.664515 19861 solver.cpp:258]     Train net output #0: loss = 0.000204846 (* 1 = 0.000204846 loss)
I0522 11:05:05.664522 19861 sgd_solver.cpp:112] Iteration 23380, lr = 0.0001
I0522 11:05:07.731832 19861 solver.cpp:239] Iteration 23400 (9.67441 iter/s, 2.06731s/20 iters), loss = 0.000124677
I0522 11:05:07.741088 19861 solver.cpp:258]     Train net output #0: loss = 0.000124605 (* 1 = 0.000124605 loss)
I0522 11:05:07.741099 19861 sgd_solver.cpp:112] Iteration 23400, lr = 0.0001
I0522 11:05:09.797381 19861 solver.cpp:239] Iteration 23420 (9.72623 iter/s, 2.05629s/20 iters), loss = 0.000588755
I0522 11:05:09.806977 19861 solver.cpp:258]     Train net output #0: loss = 0.000588683 (* 1 = 0.000588683 loss)
I0522 11:05:09.806983 19861 sgd_solver.cpp:112] Iteration 23420, lr = 0.0001
I0522 11:05:10.991029 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:05:11.864221 19861 solver.cpp:239] Iteration 23440 (9.72175 iter/s, 2.05724s/20 iters), loss = 0.000401961
I0522 11:05:11.873615 19861 solver.cpp:258]     Train net output #0: loss = 0.000401889 (* 1 = 0.000401889 loss)
I0522 11:05:11.873621 19861 sgd_solver.cpp:112] Iteration 23440, lr = 0.0001
I0522 11:05:13.924099 19861 solver.cpp:239] Iteration 23460 (9.75385 iter/s, 2.05047s/20 iters), loss = 0.000300956
I0522 11:05:13.924178 19861 solver.cpp:258]     Train net output #0: loss = 0.000300883 (* 1 = 0.000300883 loss)
I0522 11:05:13.924183 19861 sgd_solver.cpp:112] Iteration 23460, lr = 0.0001
I0522 11:05:15.970611 19861 solver.cpp:239] Iteration 23480 (9.77312 iter/s, 2.04643s/20 iters), loss = 0.000246858
I0522 11:05:15.980013 19861 solver.cpp:258]     Train net output #0: loss = 0.000246785 (* 1 = 0.000246785 loss)
I0522 11:05:15.980020 19861 sgd_solver.cpp:112] Iteration 23480, lr = 0.0001
I0522 11:05:18.026114 19861 solver.cpp:239] Iteration 23500 (9.77468 iter/s, 2.0461s/20 iters), loss = 0.000186628
I0522 11:05:18.035733 19861 solver.cpp:258]     Train net output #0: loss = 0.000186555 (* 1 = 0.000186555 loss)
I0522 11:05:18.035740 19861 sgd_solver.cpp:112] Iteration 23500, lr = 0.0001
I0522 11:05:20.407253 19861 solver.cpp:239] Iteration 23520 (8.4334 iter/s, 2.37152s/20 iters), loss = 0.000590948
I0522 11:05:20.416326 19861 solver.cpp:258]     Train net output #0: loss = 0.000590876 (* 1 = 0.000590876 loss)
I0522 11:05:20.416332 19861 sgd_solver.cpp:112] Iteration 23520, lr = 0.0001
I0522 11:05:22.465924 19861 solver.cpp:239] Iteration 23540 (9.75804 iter/s, 2.04959s/20 iters), loss = 0.00127327
I0522 11:05:22.475492 19861 solver.cpp:258]     Train net output #0: loss = 0.0012732 (* 1 = 0.0012732 loss)
I0522 11:05:22.475499 19861 sgd_solver.cpp:112] Iteration 23540, lr = 0.0001
I0522 11:05:24.538882 19861 solver.cpp:239] Iteration 23560 (9.69278 iter/s, 2.06339s/20 iters), loss = 0.00324027
I0522 11:05:24.548276 19861 solver.cpp:258]     Train net output #0: loss = 0.0032402 (* 1 = 0.0032402 loss)
I0522 11:05:24.548283 19861 sgd_solver.cpp:112] Iteration 23560, lr = 0.0001
I0522 11:05:25.940743 19861 blocking_queue.cpp:49] Waiting for data
I0522 11:05:26.624827 19861 solver.cpp:239] Iteration 23580 (9.63137 iter/s, 2.07655s/20 iters), loss = 0.000195566
I0522 11:05:26.634418 19861 solver.cpp:258]     Train net output #0: loss = 0.000195493 (* 1 = 0.000195493 loss)
I0522 11:05:26.634428 19861 sgd_solver.cpp:112] Iteration 23580, lr = 0.0001
I0522 11:05:27.104183 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:05:28.693532 19861 solver.cpp:239] Iteration 23600 (9.71293 iter/s, 2.05911s/20 iters), loss = 0.000853995
I0522 11:05:28.702608 19861 solver.cpp:258]     Train net output #0: loss = 0.000853922 (* 1 = 0.000853922 loss)
I0522 11:05:28.702618 19861 sgd_solver.cpp:112] Iteration 23600, lr = 0.0001
I0522 11:05:30.782917 19861 solver.cpp:239] Iteration 23620 (9.61397 iter/s, 2.08031s/20 iters), loss = 0.000376893
I0522 11:05:30.793429 19861 solver.cpp:258]     Train net output #0: loss = 0.00037682 (* 1 = 0.00037682 loss)
I0522 11:05:30.793437 19861 sgd_solver.cpp:112] Iteration 23620, lr = 0.0001
I0522 11:05:33.131501 19861 solver.cpp:239] Iteration 23640 (8.5541 iter/s, 2.33806s/20 iters), loss = 0.000233478
I0522 11:05:33.131582 19861 solver.cpp:258]     Train net output #0: loss = 0.000233406 (* 1 = 0.000233406 loss)
I0522 11:05:33.131587 19861 sgd_solver.cpp:112] Iteration 23640, lr = 0.0001
I0522 11:05:35.241619 19861 solver.cpp:239] Iteration 23660 (9.4786 iter/s, 2.11002s/20 iters), loss = 0.000779421
I0522 11:05:35.241714 19861 solver.cpp:258]     Train net output #0: loss = 0.000779349 (* 1 = 0.000779349 loss)
I0522 11:05:35.241719 19861 sgd_solver.cpp:112] Iteration 23660, lr = 0.0001
I0522 11:05:37.356034 19861 solver.cpp:239] Iteration 23680 (9.45941 iter/s, 2.1143s/20 iters), loss = 0.000505073
I0522 11:05:37.356143 19861 solver.cpp:258]     Train net output #0: loss = 0.000505 (* 1 = 0.000505 loss)
I0522 11:05:37.356150 19861 sgd_solver.cpp:112] Iteration 23680, lr = 0.0001
I0522 11:05:39.487682 19861 solver.cpp:239] Iteration 23700 (9.38289 iter/s, 2.13154s/20 iters), loss = 9.63711e-05
I0522 11:05:39.499948 19861 solver.cpp:258]     Train net output #0: loss = 9.62985e-05 (* 1 = 9.62985e-05 loss)
I0522 11:05:39.499958 19861 sgd_solver.cpp:112] Iteration 23700, lr = 0.0001
I0522 11:05:41.815222 19861 solver.cpp:239] Iteration 23720 (8.63829 iter/s, 2.31527s/20 iters), loss = 0.000720751
I0522 11:05:41.824295 19861 solver.cpp:258]     Train net output #0: loss = 0.000720679 (* 1 = 0.000720679 loss)
I0522 11:05:41.824301 19861 sgd_solver.cpp:112] Iteration 23720, lr = 0.0001
I0522 11:05:43.695631 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:05:43.933964 19861 solver.cpp:239] Iteration 23740 (9.48023 iter/s, 2.10965s/20 iters), loss = 0.000546143
I0522 11:05:43.934098 19861 solver.cpp:258]     Train net output #0: loss = 0.000546071 (* 1 = 0.000546071 loss)
I0522 11:05:43.934103 19861 sgd_solver.cpp:112] Iteration 23740, lr = 0.0001
I0522 11:05:46.032227 19861 solver.cpp:239] Iteration 23760 (9.53239 iter/s, 2.09811s/20 iters), loss = 0.000568778
I0522 11:05:46.032642 19861 solver.cpp:258]     Train net output #0: loss = 0.000568706 (* 1 = 0.000568706 loss)
I0522 11:05:46.032650 19861 sgd_solver.cpp:112] Iteration 23760, lr = 0.0001
I0522 11:05:48.430145 19861 solver.cpp:239] Iteration 23780 (8.34202 iter/s, 2.3975s/20 iters), loss = 0.000379015
I0522 11:05:48.430203 19861 solver.cpp:258]     Train net output #0: loss = 0.000378943 (* 1 = 0.000378943 loss)
I0522 11:05:48.430208 19861 sgd_solver.cpp:112] Iteration 23780, lr = 0.0001
I0522 11:05:50.574327 19861 solver.cpp:239] Iteration 23800 (9.32786 iter/s, 2.14411s/20 iters), loss = 0.00181559
I0522 11:05:50.574384 19861 solver.cpp:258]     Train net output #0: loss = 0.00181552 (* 1 = 0.00181552 loss)
I0522 11:05:50.574388 19861 sgd_solver.cpp:112] Iteration 23800, lr = 0.0001
I0522 11:05:52.688585 19861 solver.cpp:239] Iteration 23820 (9.45991 iter/s, 2.11419s/20 iters), loss = 0.000227092
I0522 11:05:52.701978 19861 solver.cpp:258]     Train net output #0: loss = 0.000227019 (* 1 = 0.000227019 loss)
I0522 11:05:52.701987 19861 sgd_solver.cpp:112] Iteration 23820, lr = 0.0001
I0522 11:05:54.839993 19861 solver.cpp:239] Iteration 23840 (9.35446 iter/s, 2.13802s/20 iters), loss = 0.000814311
I0522 11:05:54.849068 19861 solver.cpp:258]     Train net output #0: loss = 0.000814238 (* 1 = 0.000814238 loss)
I0522 11:05:54.849076 19861 sgd_solver.cpp:112] Iteration 23840, lr = 0.0001
I0522 11:05:57.196333 19861 solver.cpp:239] Iteration 23860 (8.52057 iter/s, 2.34726s/20 iters), loss = 0.000218001
I0522 11:05:57.196395 19861 solver.cpp:258]     Train net output #0: loss = 0.000217927 (* 1 = 0.000217927 loss)
I0522 11:05:57.196399 19861 sgd_solver.cpp:112] Iteration 23860, lr = 0.0001
I0522 11:05:59.353482 19861 solver.cpp:239] Iteration 23880 (9.27186 iter/s, 2.15706s/20 iters), loss = 0.000240155
I0522 11:05:59.353575 19861 solver.cpp:258]     Train net output #0: loss = 0.000240082 (* 1 = 0.000240082 loss)
I0522 11:05:59.353580 19861 sgd_solver.cpp:112] Iteration 23880, lr = 0.0001
I0522 11:06:00.526087 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:06:01.521625 19861 solver.cpp:239] Iteration 23900 (9.22496 iter/s, 2.16803s/20 iters), loss = 0.000442712
I0522 11:06:01.521716 19861 solver.cpp:258]     Train net output #0: loss = 0.000442639 (* 1 = 0.000442639 loss)
I0522 11:06:01.521721 19861 sgd_solver.cpp:112] Iteration 23900, lr = 0.0001
I0522 11:06:03.863122 19861 solver.cpp:239] Iteration 23920 (8.5419 iter/s, 2.3414s/20 iters), loss = 0.000385936
I0522 11:06:03.876684 19861 solver.cpp:258]     Train net output #0: loss = 0.000385863 (* 1 = 0.000385863 loss)
I0522 11:06:03.876693 19861 sgd_solver.cpp:112] Iteration 23920, lr = 0.0001
I0522 11:06:05.964012 19861 solver.cpp:239] Iteration 23940 (9.58162 iter/s, 2.08733s/20 iters), loss = 0.000114995
I0522 11:06:05.973086 19861 solver.cpp:258]     Train net output #0: loss = 0.000114922 (* 1 = 0.000114922 loss)
I0522 11:06:05.973093 19861 sgd_solver.cpp:112] Iteration 23940, lr = 0.0001
I0522 11:06:08.089179 19861 solver.cpp:239] Iteration 23960 (9.45143 iter/s, 2.11608s/20 iters), loss = 0.000199778
I0522 11:06:08.102835 19861 solver.cpp:258]     Train net output #0: loss = 0.000199704 (* 1 = 0.000199704 loss)
I0522 11:06:08.102843 19861 sgd_solver.cpp:112] Iteration 23960, lr = 0.0001
I0522 11:06:10.540990 19861 solver.cpp:239] Iteration 23980 (8.203 iter/s, 2.43813s/20 iters), loss = 0.000776353
I0522 11:06:10.541096 19861 solver.cpp:258]     Train net output #0: loss = 0.00077628 (* 1 = 0.00077628 loss)
I0522 11:06:10.541100 19861 sgd_solver.cpp:112] Iteration 23980, lr = 0.0001
I0522 11:06:12.506008 19861 solver.cpp:347] Iteration 24000, Testing net (#0)
I0522 11:06:17.523353 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:06:21.552640 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:06:23.169260 19861 blocking_queue.cpp:49] Waiting for data
I0522 11:06:25.762799 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:06:29.686439 19861 solver.cpp:414]     Test net output #0: accuracy = 0.879122
I0522 11:06:29.686501 19861 solver.cpp:414]     Test net output #1: loss = 0.79173 (* 1 = 0.79173 loss)
I0522 11:06:29.784508 19861 solver.cpp:239] Iteration 24000 (1.03931 iter/s, 19.2435s/20 iters), loss = 0.000197245
I0522 11:06:29.786952 19861 solver.cpp:258]     Train net output #0: loss = 0.000197172 (* 1 = 0.000197172 loss)
I0522 11:06:29.786960 19861 sgd_solver.cpp:112] Iteration 24000, lr = 0.0001
I0522 11:06:32.240453 19861 solver.cpp:239] Iteration 24020 (8.15162 iter/s, 2.4535s/20 iters), loss = 0.00165296
I0522 11:06:32.240491 19861 solver.cpp:258]     Train net output #0: loss = 0.00165288 (* 1 = 0.00165288 loss)
I0522 11:06:32.240495 19861 sgd_solver.cpp:112] Iteration 24020, lr = 0.0001
I0522 11:06:34.386544 19861 solver.cpp:239] Iteration 24040 (9.31951 iter/s, 2.14604s/20 iters), loss = 0.000543304
I0522 11:06:34.386597 19861 solver.cpp:258]     Train net output #0: loss = 0.00054323 (* 1 = 0.00054323 loss)
I0522 11:06:34.386601 19861 sgd_solver.cpp:112] Iteration 24040, lr = 0.0001
I0522 11:06:34.850884 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:06:36.508304 19861 solver.cpp:239] Iteration 24060 (9.42639 iter/s, 2.1217s/20 iters), loss = 0.00043552
I0522 11:06:36.508352 19861 solver.cpp:258]     Train net output #0: loss = 0.000435447 (* 1 = 0.000435447 loss)
I0522 11:06:36.508356 19861 sgd_solver.cpp:112] Iteration 24060, lr = 0.0001
I0522 11:06:38.641149 19861 solver.cpp:239] Iteration 24080 (9.37742 iter/s, 2.13278s/20 iters), loss = 0.000115469
I0522 11:06:38.654536 19861 solver.cpp:258]     Train net output #0: loss = 0.000115396 (* 1 = 0.000115396 loss)
I0522 11:06:38.654543 19861 sgd_solver.cpp:112] Iteration 24080, lr = 0.0001
I0522 11:06:41.062654 19861 solver.cpp:239] Iteration 24100 (8.30525 iter/s, 2.40812s/20 iters), loss = 0.000150647
I0522 11:06:41.075888 19861 solver.cpp:258]     Train net output #0: loss = 0.000150574 (* 1 = 0.000150574 loss)
I0522 11:06:41.075896 19861 sgd_solver.cpp:112] Iteration 24100, lr = 0.0001
I0522 11:06:43.207459 19861 solver.cpp:239] Iteration 24120 (9.38276 iter/s, 2.13157s/20 iters), loss = 0.000186349
I0522 11:06:43.207499 19861 solver.cpp:258]     Train net output #0: loss = 0.000186275 (* 1 = 0.000186275 loss)
I0522 11:06:43.207504 19861 sgd_solver.cpp:112] Iteration 24120, lr = 0.0001
I0522 11:06:45.395552 19861 solver.cpp:239] Iteration 24140 (9.14063 iter/s, 2.18803s/20 iters), loss = 0.000219086
I0522 11:06:45.395633 19861 solver.cpp:258]     Train net output #0: loss = 0.000219013 (* 1 = 0.000219013 loss)
I0522 11:06:45.395637 19861 sgd_solver.cpp:112] Iteration 24140, lr = 0.0001
I0522 11:06:47.848786 19861 solver.cpp:239] Iteration 24160 (8.15294 iter/s, 2.4531s/20 iters), loss = 0.000185394
I0522 11:06:47.849442 19861 solver.cpp:258]     Train net output #0: loss = 0.00018532 (* 1 = 0.00018532 loss)
I0522 11:06:47.849449 19861 sgd_solver.cpp:112] Iteration 24160, lr = 0.0001
I0522 11:06:49.996480 19861 solver.cpp:239] Iteration 24180 (9.31518 iter/s, 2.14703s/20 iters), loss = 0.000173657
I0522 11:06:49.996522 19861 solver.cpp:258]     Train net output #0: loss = 0.000173583 (* 1 = 0.000173583 loss)
I0522 11:06:49.996527 19861 sgd_solver.cpp:112] Iteration 24180, lr = 0.0001
I0522 11:06:51.843928 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:06:52.107089 19861 solver.cpp:239] Iteration 24200 (9.47622 iter/s, 2.11055s/20 iters), loss = 0.000651253
I0522 11:06:52.107163 19861 solver.cpp:258]     Train net output #0: loss = 0.000651179 (* 1 = 0.000651179 loss)
I0522 11:06:52.107168 19861 sgd_solver.cpp:112] Iteration 24200, lr = 0.0001
I0522 11:06:54.219385 19861 solver.cpp:239] Iteration 24220 (9.47159 iter/s, 2.11158s/20 iters), loss = 0.000594089
I0522 11:06:54.243647 19861 solver.cpp:258]     Train net output #0: loss = 0.000594016 (* 1 = 0.000594016 loss)
I0522 11:06:54.243671 19861 sgd_solver.cpp:112] Iteration 24220, lr = 0.0001
I0522 11:06:56.650759 19861 solver.cpp:239] Iteration 24240 (8.30868 iter/s, 2.40712s/20 iters), loss = 0.000218404
I0522 11:06:56.663782 19861 solver.cpp:258]     Train net output #0: loss = 0.00021833 (* 1 = 0.00021833 loss)
I0522 11:06:56.663790 19861 sgd_solver.cpp:112] Iteration 24240, lr = 0.0001
I0522 11:06:58.759171 19861 solver.cpp:239] Iteration 24260 (9.54484 iter/s, 2.09537s/20 iters), loss = 0.000187042
I0522 11:06:58.759251 19861 solver.cpp:258]     Train net output #0: loss = 0.000186968 (* 1 = 0.000186968 loss)
I0522 11:06:58.759255 19861 sgd_solver.cpp:112] Iteration 24260, lr = 0.0001
I0522 11:07:00.884404 19861 solver.cpp:239] Iteration 24280 (9.4111 iter/s, 2.12515s/20 iters), loss = 0.000174206
I0522 11:07:00.884449 19861 solver.cpp:258]     Train net output #0: loss = 0.000174132 (* 1 = 0.000174132 loss)
I0522 11:07:00.884452 19861 sgd_solver.cpp:112] Iteration 24280, lr = 0.0001
I0522 11:07:03.336942 19861 solver.cpp:239] Iteration 24300 (8.15496 iter/s, 2.45249s/20 iters), loss = 0.000639183
I0522 11:07:03.346365 19861 solver.cpp:258]     Train net output #0: loss = 0.000639109 (* 1 = 0.000639109 loss)
I0522 11:07:03.346372 19861 sgd_solver.cpp:112] Iteration 24300, lr = 0.0001
I0522 11:07:05.439668 19861 solver.cpp:239] Iteration 24320 (9.55428 iter/s, 2.0933s/20 iters), loss = 0.000228021
I0522 11:07:05.448745 19861 solver.cpp:258]     Train net output #0: loss = 0.000227947 (* 1 = 0.000227947 loss)
I0522 11:07:05.448751 19861 sgd_solver.cpp:112] Iteration 24320, lr = 0.0001
I0522 11:07:07.529381 19861 solver.cpp:239] Iteration 24340 (9.61242 iter/s, 2.08064s/20 iters), loss = 6.04583e-05
I0522 11:07:07.538928 19861 solver.cpp:258]     Train net output #0: loss = 6.03839e-05 (* 1 = 6.03839e-05 loss)
I0522 11:07:07.538935 19861 sgd_solver.cpp:112] Iteration 24340, lr = 0.0001
I0522 11:07:08.652719 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:07:09.640532 19861 solver.cpp:239] Iteration 24360 (9.51657 iter/s, 2.1016s/20 iters), loss = 0.000357798
I0522 11:07:09.640581 19861 solver.cpp:258]     Train net output #0: loss = 0.000357724 (* 1 = 0.000357724 loss)
I0522 11:07:09.640586 19861 sgd_solver.cpp:112] Iteration 24360, lr = 0.0001
I0522 11:07:12.094875 19861 solver.cpp:239] Iteration 24380 (8.14909 iter/s, 2.45426s/20 iters), loss = 0.000322561
I0522 11:07:12.094976 19861 solver.cpp:258]     Train net output #0: loss = 0.000322486 (* 1 = 0.000322486 loss)
I0522 11:07:12.094980 19861 sgd_solver.cpp:112] Iteration 24380, lr = 0.0001
I0522 11:07:14.224552 19861 solver.cpp:239] Iteration 24400 (9.39153 iter/s, 2.12958s/20 iters), loss = 0.000237469
I0522 11:07:14.237890 19861 solver.cpp:258]     Train net output #0: loss = 0.000237394 (* 1 = 0.000237394 loss)
I0522 11:07:14.237895 19861 sgd_solver.cpp:112] Iteration 24400, lr = 0.0001
I0522 11:07:16.361901 19861 solver.cpp:239] Iteration 24420 (9.41612 iter/s, 2.12402s/20 iters), loss = 0.000102172
I0522 11:07:16.371001 19861 solver.cpp:258]     Train net output #0: loss = 0.000102098 (* 1 = 0.000102098 loss)
I0522 11:07:16.371008 19861 sgd_solver.cpp:112] Iteration 24420, lr = 0.0001
I0522 11:07:18.714021 19861 solver.cpp:239] Iteration 24440 (8.53601 iter/s, 2.34302s/20 iters), loss = 0.000310841
I0522 11:07:18.714262 19861 solver.cpp:258]     Train net output #0: loss = 0.000310767 (* 1 = 0.000310767 loss)
I0522 11:07:18.714269 19861 sgd_solver.cpp:112] Iteration 24440, lr = 0.0001
I0522 11:07:20.845824 19861 solver.cpp:239] Iteration 24460 (9.38278 iter/s, 2.13156s/20 iters), loss = 0.000654075
I0522 11:07:20.855067 19861 solver.cpp:258]     Train net output #0: loss = 0.000654 (* 1 = 0.000654 loss)
I0522 11:07:20.855075 19861 sgd_solver.cpp:112] Iteration 24460, lr = 0.0001
I0522 11:07:22.972754 19861 solver.cpp:239] Iteration 24480 (9.44439 iter/s, 2.11766s/20 iters), loss = 0.00129442
I0522 11:07:22.972862 19861 solver.cpp:258]     Train net output #0: loss = 0.00129434 (* 1 = 0.00129434 loss)
I0522 11:07:22.972872 19861 sgd_solver.cpp:112] Iteration 24480, lr = 0.0001
I0522 11:07:25.101999 19861 solver.cpp:239] Iteration 24500 (9.39348 iter/s, 2.12914s/20 iters), loss = 0.000121506
I0522 11:07:25.111841 19861 solver.cpp:258]     Train net output #0: loss = 0.000121431 (* 1 = 0.000121431 loss)
I0522 11:07:25.111853 19861 sgd_solver.cpp:112] Iteration 24500, lr = 0.0001
I0522 11:07:25.768564 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:07:27.527885 19861 solver.cpp:239] Iteration 24520 (8.27806 iter/s, 2.41602s/20 iters), loss = 0.00057546
I0522 11:07:27.527969 19861 solver.cpp:258]     Train net output #0: loss = 0.000575385 (* 1 = 0.000575385 loss)
I0522 11:07:27.527973 19861 sgd_solver.cpp:112] Iteration 24520, lr = 0.0001
I0522 11:07:29.620841 19861 solver.cpp:239] Iteration 24540 (9.55631 iter/s, 2.09286s/20 iters), loss = 0.000694656
I0522 11:07:29.620925 19861 solver.cpp:258]     Train net output #0: loss = 0.000694582 (* 1 = 0.000694582 loss)
I0522 11:07:29.620929 19861 sgd_solver.cpp:112] Iteration 24540, lr = 0.0001
I0522 11:07:31.734812 19861 solver.cpp:239] Iteration 24560 (9.46135 iter/s, 2.11386s/20 iters), loss = 0.000198326
I0522 11:07:31.734897 19861 solver.cpp:258]     Train net output #0: loss = 0.000198251 (* 1 = 0.000198251 loss)
I0522 11:07:31.734901 19861 sgd_solver.cpp:112] Iteration 24560, lr = 0.0001
I0522 11:07:34.230752 19861 solver.cpp:239] Iteration 24580 (8.01331 iter/s, 2.49585s/20 iters), loss = 0.00217049
I0522 11:07:34.240643 19861 solver.cpp:258]     Train net output #0: loss = 0.00217042 (* 1 = 0.00217042 loss)
I0522 11:07:34.240653 19861 sgd_solver.cpp:112] Iteration 24580, lr = 0.0001
I0522 11:07:36.362782 19861 solver.cpp:239] Iteration 24600 (9.42457 iter/s, 2.12211s/20 iters), loss = 0.000292138
I0522 11:07:36.362869 19861 solver.cpp:258]     Train net output #0: loss = 0.000292063 (* 1 = 0.000292063 loss)
I0522 11:07:36.362875 19861 sgd_solver.cpp:112] Iteration 24600, lr = 0.0001
I0522 11:07:38.469142 19861 solver.cpp:239] Iteration 24620 (9.49545 iter/s, 2.10627s/20 iters), loss = 0.000158263
I0522 11:07:38.478703 19861 solver.cpp:258]     Train net output #0: loss = 0.000158188 (* 1 = 0.000158188 loss)
I0522 11:07:38.478718 19861 sgd_solver.cpp:112] Iteration 24620, lr = 0.0001
I0522 11:07:40.607374 19861 solver.cpp:239] Iteration 24640 (9.39551 iter/s, 2.12868s/20 iters), loss = 0.000274995
I0522 11:07:40.607457 19861 solver.cpp:258]     Train net output #0: loss = 0.00027492 (* 1 = 0.00027492 loss)
I0522 11:07:40.607461 19861 sgd_solver.cpp:112] Iteration 24640, lr = 0.0001
I0522 11:07:42.653313 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:07:43.103765 19861 solver.cpp:239] Iteration 24660 (8.01185 iter/s, 2.4963s/20 iters), loss = 0.00312135
I0522 11:07:43.103817 19861 solver.cpp:258]     Train net output #0: loss = 0.00312128 (* 1 = 0.00312128 loss)
I0522 11:07:43.103821 19861 sgd_solver.cpp:112] Iteration 24660, lr = 0.0001
I0522 11:07:45.211449 19861 solver.cpp:239] Iteration 24680 (9.48939 iter/s, 2.10762s/20 iters), loss = 0.00168079
I0522 11:07:45.211525 19861 solver.cpp:258]     Train net output #0: loss = 0.00168071 (* 1 = 0.00168071 loss)
I0522 11:07:45.211529 19861 sgd_solver.cpp:112] Iteration 24680, lr = 0.0001
I0522 11:07:45.786381 19861 blocking_queue.cpp:49] Waiting for data
I0522 11:07:47.322876 19861 solver.cpp:239] Iteration 24700 (9.4727 iter/s, 2.11133s/20 iters), loss = 9.60871e-05
I0522 11:07:47.332607 19861 solver.cpp:258]     Train net output #0: loss = 9.60117e-05 (* 1 = 9.60117e-05 loss)
I0522 11:07:47.332621 19861 sgd_solver.cpp:112] Iteration 24700, lr = 0.0001
I0522 11:07:49.798578 19861 solver.cpp:239] Iteration 24720 (8.11039 iter/s, 2.46597s/20 iters), loss = 0.00104843
I0522 11:07:49.798785 19861 solver.cpp:258]     Train net output #0: loss = 0.00104836 (* 1 = 0.00104836 loss)
I0522 11:07:49.798789 19861 sgd_solver.cpp:112] Iteration 24720, lr = 0.0001
I0522 11:07:51.973449 19861 solver.cpp:239] Iteration 24740 (9.19684 iter/s, 2.17466s/20 iters), loss = 0.000135013
I0522 11:07:51.973502 19861 solver.cpp:258]     Train net output #0: loss = 0.000134938 (* 1 = 0.000134938 loss)
I0522 11:07:51.973506 19861 sgd_solver.cpp:112] Iteration 24740, lr = 0.0001
I0522 11:07:54.118930 19861 solver.cpp:239] Iteration 24760 (9.32216 iter/s, 2.14543s/20 iters), loss = 0.000124592
I0522 11:07:54.128531 19861 solver.cpp:258]     Train net output #0: loss = 0.000124517 (* 1 = 0.000124517 loss)
I0522 11:07:54.128540 19861 sgd_solver.cpp:112] Iteration 24760, lr = 0.0001
I0522 11:07:56.286592 19861 solver.cpp:239] Iteration 24780 (9.26754 iter/s, 2.15807s/20 iters), loss = 0.000141755
I0522 11:07:56.286614 19861 solver.cpp:258]     Train net output #0: loss = 0.00014168 (* 1 = 0.00014168 loss)
I0522 11:07:56.286618 19861 sgd_solver.cpp:112] Iteration 24780, lr = 0.0001
I0522 11:07:58.664471 19861 solver.cpp:239] Iteration 24800 (8.41099 iter/s, 2.37784s/20 iters), loss = 0.000439232
I0522 11:07:58.664551 19861 solver.cpp:258]     Train net output #0: loss = 0.000439157 (* 1 = 0.000439157 loss)
I0522 11:07:58.664554 19861 sgd_solver.cpp:112] Iteration 24800, lr = 0.0001
I0522 11:07:59.704154 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:08:00.792374 19861 solver.cpp:239] Iteration 24820 (9.39931 iter/s, 2.12782s/20 iters), loss = 0.00195352
I0522 11:08:00.801597 19861 solver.cpp:258]     Train net output #0: loss = 0.00195344 (* 1 = 0.00195344 loss)
I0522 11:08:00.801604 19861 sgd_solver.cpp:112] Iteration 24820, lr = 0.0001
I0522 11:08:02.932798 19861 solver.cpp:239] Iteration 24840 (9.38444 iter/s, 2.13119s/20 iters), loss = 0.000251429
I0522 11:08:02.932885 19861 solver.cpp:258]     Train net output #0: loss = 0.000251354 (* 1 = 0.000251354 loss)
I0522 11:08:02.932889 19861 sgd_solver.cpp:112] Iteration 24840, lr = 0.0001
I0522 11:08:05.388973 19861 solver.cpp:239] Iteration 24860 (8.14305 iter/s, 2.45608s/20 iters), loss = 0.000481972
I0522 11:08:05.389029 19861 solver.cpp:258]     Train net output #0: loss = 0.000481896 (* 1 = 0.000481896 loss)
I0522 11:08:05.389034 19861 sgd_solver.cpp:112] Iteration 24860, lr = 0.0001
I0522 11:08:07.516615 19861 solver.cpp:239] Iteration 24880 (9.40036 iter/s, 2.12758s/20 iters), loss = 0.000326806
I0522 11:08:07.516664 19861 solver.cpp:258]     Train net output #0: loss = 0.00032673 (* 1 = 0.00032673 loss)
I0522 11:08:07.516667 19861 sgd_solver.cpp:112] Iteration 24880, lr = 0.0001
I0522 11:08:09.626531 19861 solver.cpp:239] Iteration 24900 (9.47931 iter/s, 2.10986s/20 iters), loss = 0.000200566
I0522 11:08:09.636390 19861 solver.cpp:258]     Train net output #0: loss = 0.00020049 (* 1 = 0.00020049 loss)
I0522 11:08:09.636397 19861 sgd_solver.cpp:112] Iteration 24900, lr = 0.0001
I0522 11:08:11.742547 19861 solver.cpp:239] Iteration 24920 (9.49597 iter/s, 2.10616s/20 iters), loss = 0.000711967
I0522 11:08:11.742595 19861 solver.cpp:258]     Train net output #0: loss = 0.000711891 (* 1 = 0.000711891 loss)
I0522 11:08:11.742599 19861 sgd_solver.cpp:112] Iteration 24920, lr = 0.0001
I0522 11:08:14.159453 19861 solver.cpp:239] Iteration 24940 (8.27525 iter/s, 2.41684s/20 iters), loss = 0.000655961
I0522 11:08:14.159525 19861 solver.cpp:258]     Train net output #0: loss = 0.000655885 (* 1 = 0.000655885 loss)
I0522 11:08:14.159530 19861 sgd_solver.cpp:112] Iteration 24940, lr = 0.0001
I0522 11:08:16.300081 19861 solver.cpp:239] Iteration 24960 (9.34346 iter/s, 2.14053s/20 iters), loss = 0.00172028
I0522 11:08:16.300164 19861 solver.cpp:258]     Train net output #0: loss = 0.0017202 (* 1 = 0.0017202 loss)
I0522 11:08:16.300169 19861 sgd_solver.cpp:112] Iteration 24960, lr = 0.0001
I0522 11:08:16.672734 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:08:18.439397 19861 solver.cpp:239] Iteration 24980 (9.34912 iter/s, 2.13924s/20 iters), loss = 0.000224405
I0522 11:08:18.452793 19861 solver.cpp:258]     Train net output #0: loss = 0.00022433 (* 1 = 0.00022433 loss)
I0522 11:08:18.452802 19861 sgd_solver.cpp:112] Iteration 24980, lr = 0.0001
I0522 11:08:20.739518 19861 solver.cpp:347] Iteration 25000, Testing net (#0)
I0522 11:08:20.929849 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:08:25.038476 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:08:29.260545 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:08:32.380445 19861 blocking_queue.cpp:49] Waiting for data
I0522 11:08:33.265962 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:08:37.277757 19861 solver.cpp:414]     Test net output #0: accuracy = 0.880122
I0522 11:08:37.277794 19861 solver.cpp:414]     Test net output #1: loss = 0.782704 (* 1 = 0.782704 loss)
I0522 11:08:37.378830 19861 solver.cpp:239] Iteration 25000 (1.05674 iter/s, 18.9261s/20 iters), loss = 0.000455104
I0522 11:08:37.381345 19861 solver.cpp:258]     Train net output #0: loss = 0.000455029 (* 1 = 0.000455029 loss)
I0522 11:08:37.381356 19861 sgd_solver.cpp:112] Iteration 25000, lr = 0.0001
I0522 11:08:39.516232 19861 solver.cpp:239] Iteration 25020 (9.36828 iter/s, 2.13486s/20 iters), loss = 0.000266893
I0522 11:08:39.516322 19861 solver.cpp:258]     Train net output #0: loss = 0.000266818 (* 1 = 0.000266818 loss)
I0522 11:08:39.516327 19861 sgd_solver.cpp:112] Iteration 25020, lr = 0.0001
I0522 11:08:41.714915 19861 solver.cpp:239] Iteration 25040 (9.09678 iter/s, 2.19858s/20 iters), loss = 0.00062234
I0522 11:08:41.727862 19861 solver.cpp:258]     Train net output #0: loss = 0.000622265 (* 1 = 0.000622265 loss)
I0522 11:08:41.727870 19861 sgd_solver.cpp:112] Iteration 25040, lr = 0.0001
I0522 11:08:44.197784 19861 solver.cpp:239] Iteration 25060 (8.09748 iter/s, 2.4699s/20 iters), loss = 0.00135197
I0522 11:08:44.197863 19861 solver.cpp:258]     Train net output #0: loss = 0.00135189 (* 1 = 0.00135189 loss)
I0522 11:08:44.197867 19861 sgd_solver.cpp:112] Iteration 25060, lr = 0.0001
I0522 11:08:46.389880 19861 solver.cpp:239] Iteration 25080 (9.12406 iter/s, 2.19201s/20 iters), loss = 0.00066539
I0522 11:08:46.389945 19861 solver.cpp:258]     Train net output #0: loss = 0.000665314 (* 1 = 0.000665314 loss)
I0522 11:08:46.389950 19861 sgd_solver.cpp:112] Iteration 25080, lr = 0.0001
I0522 11:08:48.559043 19861 solver.cpp:239] Iteration 25100 (9.22046 iter/s, 2.16909s/20 iters), loss = 0.000646396
I0522 11:08:48.559089 19861 solver.cpp:258]     Train net output #0: loss = 0.000646321 (* 1 = 0.000646321 loss)
I0522 11:08:48.559093 19861 sgd_solver.cpp:112] Iteration 25100, lr = 0.0001
I0522 11:08:50.620384 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:08:51.090782 19861 solver.cpp:239] Iteration 25120 (7.90001 iter/s, 2.53164s/20 iters), loss = 0.00406295
I0522 11:08:51.091184 19861 solver.cpp:258]     Train net output #0: loss = 0.00406287 (* 1 = 0.00406287 loss)
I0522 11:08:51.091197 19861 sgd_solver.cpp:112] Iteration 25120, lr = 0.0001
I0522 11:08:53.296926 19861 solver.cpp:239] Iteration 25140 (9.06722 iter/s, 2.20575s/20 iters), loss = 0.000271914
I0522 11:08:53.296980 19861 solver.cpp:258]     Train net output #0: loss = 0.000271839 (* 1 = 0.000271839 loss)
I0522 11:08:53.296984 19861 sgd_solver.cpp:112] Iteration 25140, lr = 0.0001
I0522 11:08:55.507272 19861 solver.cpp:239] Iteration 25160 (9.0486 iter/s, 2.21029s/20 iters), loss = 0.000174405
I0522 11:08:55.507323 19861 solver.cpp:258]     Train net output #0: loss = 0.00017433 (* 1 = 0.00017433 loss)
I0522 11:08:55.507328 19861 sgd_solver.cpp:112] Iteration 25160, lr = 0.0001
I0522 11:08:58.019624 19861 solver.cpp:239] Iteration 25180 (7.96091 iter/s, 2.51228s/20 iters), loss = 0.000153803
I0522 11:08:58.019743 19861 solver.cpp:258]     Train net output #0: loss = 0.000153727 (* 1 = 0.000153727 loss)
I0522 11:08:58.019748 19861 sgd_solver.cpp:112] Iteration 25180, lr = 0.0001
I0522 11:09:00.233525 19861 solver.cpp:239] Iteration 25200 (9.03437 iter/s, 2.21377s/20 iters), loss = 0.000772619
I0522 11:09:00.246868 19861 solver.cpp:258]     Train net output #0: loss = 0.000772543 (* 1 = 0.000772543 loss)
I0522 11:09:00.246878 19861 sgd_solver.cpp:112] Iteration 25200, lr = 0.0001
I0522 11:09:02.383734 19861 solver.cpp:239] Iteration 25220 (9.35962 iter/s, 2.13684s/20 iters), loss = 0.000289571
I0522 11:09:02.383849 19861 solver.cpp:258]     Train net output #0: loss = 0.000289495 (* 1 = 0.000289495 loss)
I0522 11:09:02.383855 19861 sgd_solver.cpp:112] Iteration 25220, lr = 0.0001
I0522 11:09:04.774266 19861 solver.cpp:239] Iteration 25240 (8.36674 iter/s, 2.39042s/20 iters), loss = 0.000402039
I0522 11:09:04.783345 19861 solver.cpp:258]     Train net output #0: loss = 0.000401964 (* 1 = 0.000401964 loss)
I0522 11:09:04.783352 19861 sgd_solver.cpp:112] Iteration 25240, lr = 0.0001
I0522 11:09:06.955054 19861 solver.cpp:239] Iteration 25260 (9.20934 iter/s, 2.17171s/20 iters), loss = 0.000257698
I0522 11:09:06.955098 19861 solver.cpp:258]     Train net output #0: loss = 0.000257623 (* 1 = 0.000257623 loss)
I0522 11:09:06.955102 19861 sgd_solver.cpp:112] Iteration 25260, lr = 0.0001
I0522 11:09:08.022935 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:09:09.159986 19861 solver.cpp:239] Iteration 25280 (9.07075 iter/s, 2.20489s/20 iters), loss = 0.000425253
I0522 11:09:09.169071 19861 solver.cpp:258]     Train net output #0: loss = 0.000425178 (* 1 = 0.000425178 loss)
I0522 11:09:09.169080 19861 sgd_solver.cpp:112] Iteration 25280, lr = 0.0001
I0522 11:09:11.357182 19861 solver.cpp:239] Iteration 25300 (9.14034 iter/s, 2.1881s/20 iters), loss = 0.000206612
I0522 11:09:11.367002 19861 solver.cpp:258]     Train net output #0: loss = 0.000206537 (* 1 = 0.000206537 loss)
I0522 11:09:11.367015 19861 sgd_solver.cpp:112] Iteration 25300, lr = 0.0001
I0522 11:09:13.802222 19861 solver.cpp:239] Iteration 25320 (8.21286 iter/s, 2.4352s/20 iters), loss = 0.000183312
I0522 11:09:13.811661 19861 solver.cpp:258]     Train net output #0: loss = 0.000183237 (* 1 = 0.000183237 loss)
I0522 11:09:13.811682 19861 sgd_solver.cpp:112] Iteration 25320, lr = 0.0001
I0522 11:09:15.844995 19861 solver.cpp:239] Iteration 25340 (9.83604 iter/s, 2.03334s/20 iters), loss = 0.000129005
I0522 11:09:15.854413 19861 solver.cpp:258]     Train net output #0: loss = 0.00012893 (* 1 = 0.00012893 loss)
I0522 11:09:15.854424 19861 sgd_solver.cpp:112] Iteration 25340, lr = 0.0001
I0522 11:09:17.893395 19861 solver.cpp:239] Iteration 25360 (9.80884 iter/s, 2.03898s/20 iters), loss = 0.000599359
I0522 11:09:17.902892 19861 solver.cpp:258]     Train net output #0: loss = 0.000599284 (* 1 = 0.000599284 loss)
I0522 11:09:17.902906 19861 sgd_solver.cpp:112] Iteration 25360, lr = 0.0001
I0522 11:09:19.941262 19861 solver.cpp:239] Iteration 25380 (9.81184 iter/s, 2.03835s/20 iters), loss = 0.000861216
I0522 11:09:19.950718 19861 solver.cpp:258]     Train net output #0: loss = 0.000861141 (* 1 = 0.000861141 loss)
I0522 11:09:19.950752 19861 sgd_solver.cpp:112] Iteration 25380, lr = 0.0001
I0522 11:09:22.748647 19861 solver.cpp:239] Iteration 25400 (7.14813 iter/s, 2.79793s/20 iters), loss = 0.000744124
I0522 11:09:22.758075 19861 solver.cpp:258]     Train net output #0: loss = 0.000744049 (* 1 = 0.000744049 loss)
I0522 11:09:22.758082 19861 sgd_solver.cpp:112] Iteration 25400, lr = 0.0001
I0522 11:09:25.547124 19861 solver.cpp:239] Iteration 25420 (7.17094 iter/s, 2.78903s/20 iters), loss = 0.000540683
I0522 11:09:25.556643 19861 solver.cpp:258]     Train net output #0: loss = 0.000540608 (* 1 = 0.000540608 loss)
I0522 11:09:25.556651 19861 sgd_solver.cpp:112] Iteration 25420, lr = 0.0001
I0522 11:09:25.815887 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:09:27.587289 19861 solver.cpp:239] Iteration 25440 (9.84918 iter/s, 2.03063s/20 iters), loss = 0.00041734
I0522 11:09:27.596693 19861 solver.cpp:258]     Train net output #0: loss = 0.000417265 (* 1 = 0.000417265 loss)
I0522 11:09:27.596701 19861 sgd_solver.cpp:112] Iteration 25440, lr = 0.0001
I0522 11:09:29.628397 19861 solver.cpp:239] Iteration 25460 (9.84401 iter/s, 2.03169s/20 iters), loss = 0.0004795
I0522 11:09:29.637982 19861 solver.cpp:258]     Train net output #0: loss = 0.000479425 (* 1 = 0.000479425 loss)
I0522 11:09:29.637995 19861 sgd_solver.cpp:112] Iteration 25460, lr = 0.0001
I0522 11:09:31.667804 19861 solver.cpp:239] Iteration 25480 (9.85312 iter/s, 2.02981s/20 iters), loss = 0.000424731
I0522 11:09:31.677219 19861 solver.cpp:258]     Train net output #0: loss = 0.000424656 (* 1 = 0.000424656 loss)
I0522 11:09:31.677227 19861 sgd_solver.cpp:112] Iteration 25480, lr = 0.0001
I0522 11:09:35.247153 19861 solver.cpp:239] Iteration 25500 (5.60234 iter/s, 3.56994s/20 iters), loss = 0.0011117
I0522 11:09:35.258602 19861 solver.cpp:258]     Train net output #0: loss = 0.00111163 (* 1 = 0.00111163 loss)
I0522 11:09:35.258610 19861 sgd_solver.cpp:112] Iteration 25500, lr = 0.0001
I0522 11:09:37.312229 19861 solver.cpp:239] Iteration 25520 (9.73894 iter/s, 2.05361s/20 iters), loss = 0.000369374
I0522 11:09:37.321835 19861 solver.cpp:258]     Train net output #0: loss = 0.000369299 (* 1 = 0.000369299 loss)
I0522 11:09:37.321842 19861 sgd_solver.cpp:112] Iteration 25520, lr = 0.0001
I0522 11:09:39.359200 19861 solver.cpp:239] Iteration 25540 (9.81669 iter/s, 2.03735s/20 iters), loss = 0.000781671
I0522 11:09:39.359299 19861 solver.cpp:258]     Train net output #0: loss = 0.000781596 (* 1 = 0.000781596 loss)
I0522 11:09:39.359304 19861 sgd_solver.cpp:112] Iteration 25540, lr = 0.0001
I0522 11:09:41.403825 19861 solver.cpp:239] Iteration 25560 (9.78267 iter/s, 2.04443s/20 iters), loss = 0.0015126
I0522 11:09:41.413220 19861 solver.cpp:258]     Train net output #0: loss = 0.00151252 (* 1 = 0.00151252 loss)
I0522 11:09:41.413228 19861 sgd_solver.cpp:112] Iteration 25560, lr = 0.0001
I0522 11:09:43.326558 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:09:44.310176 19861 solver.cpp:239] Iteration 25580 (6.90379 iter/s, 2.89696s/20 iters), loss = 0.000312113
I0522 11:09:44.319782 19861 solver.cpp:258]     Train net output #0: loss = 0.000312039 (* 1 = 0.000312039 loss)
I0522 11:09:44.319790 19861 sgd_solver.cpp:112] Iteration 25580, lr = 0.0001
I0522 11:09:47.138469 19861 solver.cpp:239] Iteration 25600 (7.0957 iter/s, 2.81861s/20 iters), loss = 0.00016932
I0522 11:09:47.138548 19861 solver.cpp:258]     Train net output #0: loss = 0.000169246 (* 1 = 0.000169246 loss)
I0522 11:09:47.138556 19861 sgd_solver.cpp:112] Iteration 25600, lr = 0.0001
I0522 11:09:49.358666 19861 solver.cpp:239] Iteration 25620 (9.00858 iter/s, 2.22011s/20 iters), loss = 0.000180352
I0522 11:09:49.358736 19861 solver.cpp:258]     Train net output #0: loss = 0.000180278 (* 1 = 0.000180278 loss)
I0522 11:09:49.358741 19861 sgd_solver.cpp:112] Iteration 25620, lr = 0.0001
I0522 11:09:51.565181 19861 solver.cpp:239] Iteration 25640 (9.06441 iter/s, 2.20643s/20 iters), loss = 0.000418693
I0522 11:09:51.565260 19861 solver.cpp:258]     Train net output #0: loss = 0.000418619 (* 1 = 0.000418619 loss)
I0522 11:09:51.565266 19861 sgd_solver.cpp:112] Iteration 25640, lr = 0.0001
I0522 11:09:53.750887 19861 solver.cpp:239] Iteration 25660 (9.15072 iter/s, 2.18562s/20 iters), loss = 0.00025591
I0522 11:09:53.751691 19861 solver.cpp:258]     Train net output #0: loss = 0.000255836 (* 1 = 0.000255836 loss)
I0522 11:09:53.751698 19861 sgd_solver.cpp:112] Iteration 25660, lr = 0.0001
I0522 11:09:57.264348 19861 solver.cpp:239] Iteration 25680 (5.69372 iter/s, 3.51264s/20 iters), loss = 0.000235622
I0522 11:09:57.264436 19861 solver.cpp:258]     Train net output #0: loss = 0.000235548 (* 1 = 0.000235548 loss)
I0522 11:09:57.264441 19861 sgd_solver.cpp:112] Iteration 25680, lr = 0.0001
I0522 11:09:59.314402 19861 solver.cpp:239] Iteration 25700 (9.75642 iter/s, 2.04993s/20 iters), loss = 0.0003374
I0522 11:09:59.323873 19861 solver.cpp:258]     Train net output #0: loss = 0.000337326 (* 1 = 0.000337326 loss)
I0522 11:09:59.323886 19861 sgd_solver.cpp:112] Iteration 25700, lr = 0.0001
I0522 11:10:01.362618 19861 solver.cpp:239] Iteration 25720 (9.81008 iter/s, 2.03872s/20 iters), loss = 0.000172929
I0522 11:10:01.372159 19861 solver.cpp:258]     Train net output #0: loss = 0.000172855 (* 1 = 0.000172855 loss)
I0522 11:10:01.372172 19861 sgd_solver.cpp:112] Iteration 25720, lr = 0.0001
I0522 11:10:02.261112 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:10:03.410611 19861 solver.cpp:239] Iteration 25740 (9.81116 iter/s, 2.03849s/20 iters), loss = 0.000376005
I0522 11:10:03.420049 19861 solver.cpp:258]     Train net output #0: loss = 0.000375931 (* 1 = 0.000375931 loss)
I0522 11:10:03.420058 19861 sgd_solver.cpp:112] Iteration 25740, lr = 0.0001
I0522 11:10:05.984143 19861 solver.cpp:239] Iteration 25760 (7.80002 iter/s, 2.5641s/20 iters), loss = 0.000716122
I0522 11:10:05.994120 19861 solver.cpp:258]     Train net output #0: loss = 0.000716048 (* 1 = 0.000716048 loss)
I0522 11:10:05.994127 19861 sgd_solver.cpp:112] Iteration 25760, lr = 0.0001
I0522 11:10:09.136592 19861 solver.cpp:239] Iteration 25780 (6.36443 iter/s, 3.14247s/20 iters), loss = 8.30641e-05
I0522 11:10:09.136667 19861 solver.cpp:258]     Train net output #0: loss = 8.299e-05 (* 1 = 8.299e-05 loss)
I0522 11:10:09.136672 19861 sgd_solver.cpp:112] Iteration 25780, lr = 0.0001
I0522 11:10:11.338135 19861 solver.cpp:239] Iteration 25800 (9.08488 iter/s, 2.20146s/20 iters), loss = 0.000150389
I0522 11:10:11.338188 19861 solver.cpp:258]     Train net output #0: loss = 0.000150315 (* 1 = 0.000150315 loss)
I0522 11:10:11.338196 19861 sgd_solver.cpp:112] Iteration 25800, lr = 0.0001
I0522 11:10:13.539299 19861 solver.cpp:239] Iteration 25820 (9.08636 iter/s, 2.2011s/20 iters), loss = 0.000325795
I0522 11:10:13.539353 19861 solver.cpp:258]     Train net output #0: loss = 0.000325721 (* 1 = 0.000325721 loss)
I0522 11:10:13.539357 19861 sgd_solver.cpp:112] Iteration 25820, lr = 0.0001
I0522 11:10:15.752313 19861 solver.cpp:239] Iteration 25840 (9.0377 iter/s, 2.21295s/20 iters), loss = 0.00124227
I0522 11:10:15.752370 19861 solver.cpp:258]     Train net output #0: loss = 0.0012422 (* 1 = 0.0012422 loss)
I0522 11:10:15.752375 19861 sgd_solver.cpp:112] Iteration 25840, lr = 0.0001
I0522 11:10:19.369629 19861 solver.cpp:239] Iteration 25860 (5.52904 iter/s, 3.61727s/20 iters), loss = 0.000143838
I0522 11:10:19.369678 19861 solver.cpp:258]     Train net output #0: loss = 0.000143764 (* 1 = 0.000143764 loss)
I0522 11:10:19.369683 19861 sgd_solver.cpp:112] Iteration 25860, lr = 0.0001
I0522 11:10:21.447625 19861 solver.cpp:239] Iteration 25880 (9.62489 iter/s, 2.07794s/20 iters), loss = 0.000532164
I0522 11:10:21.457253 19861 solver.cpp:258]     Train net output #0: loss = 0.000532089 (* 1 = 0.000532089 loss)
I0522 11:10:21.457265 19861 sgd_solver.cpp:112] Iteration 25880, lr = 0.0001
I0522 11:10:21.680011 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:10:23.491648 19861 solver.cpp:239] Iteration 25900 (9.83103 iter/s, 2.03437s/20 iters), loss = 0.000420119
I0522 11:10:23.501263 19861 solver.cpp:258]     Train net output #0: loss = 0.000420044 (* 1 = 0.000420044 loss)
I0522 11:10:23.501278 19861 sgd_solver.cpp:112] Iteration 25900, lr = 0.0001
I0522 11:10:25.535204 19861 solver.cpp:239] Iteration 25920 (9.8332 iter/s, 2.03393s/20 iters), loss = 0.000807755
I0522 11:10:25.544750 19861 solver.cpp:258]     Train net output #0: loss = 0.00080768 (* 1 = 0.00080768 loss)
I0522 11:10:25.544760 19861 sgd_solver.cpp:112] Iteration 25920, lr = 0.0001
I0522 11:10:28.655027 19861 solver.cpp:239] Iteration 25940 (6.43028 iter/s, 3.11029s/20 iters), loss = 0.000154706
I0522 11:10:28.664285 19861 solver.cpp:258]     Train net output #0: loss = 0.000154632 (* 1 = 0.000154632 loss)
I0522 11:10:28.664294 19861 sgd_solver.cpp:112] Iteration 25940, lr = 0.0001
I0522 11:10:31.289386 19861 solver.cpp:239] Iteration 25960 (7.61878 iter/s, 2.62509s/20 iters), loss = 0.00015346
I0522 11:10:31.289467 19861 solver.cpp:258]     Train net output #0: loss = 0.000153386 (* 1 = 0.000153386 loss)
I0522 11:10:31.289477 19861 sgd_solver.cpp:112] Iteration 25960, lr = 0.0001
I0522 11:10:33.492556 19861 solver.cpp:239] Iteration 25980 (9.07814 iter/s, 2.20309s/20 iters), loss = 0.000118402
I0522 11:10:33.492602 19861 solver.cpp:258]     Train net output #0: loss = 0.000118328 (* 1 = 0.000118328 loss)
I0522 11:10:33.492606 19861 sgd_solver.cpp:112] Iteration 25980, lr = 0.0001
I0522 11:10:34.988003 19861 blocking_queue.cpp:49] Waiting for data
I0522 11:10:35.398831 19861 solver.cpp:347] Iteration 26000, Testing net (#0)
I0522 11:10:35.800895 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:10:42.437377 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:10:46.115296 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:10:51.168431 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:10:54.415520 19861 solver.cpp:414]     Test net output #0: accuracy = 0.879902
I0522 11:10:54.415601 19861 solver.cpp:414]     Test net output #1: loss = 0.781702 (* 1 = 0.781702 loss)
I0522 11:10:54.512861 19861 solver.cpp:239] Iteration 26000 (0.951459 iter/s, 21.0204s/20 iters), loss = 0.000183224
I0522 11:10:54.514994 19861 solver.cpp:258]     Train net output #0: loss = 0.00018315 (* 1 = 0.00018315 loss)
I0522 11:10:54.515012 19861 sgd_solver.cpp:112] Iteration 26000, lr = 0.0001
I0522 11:10:56.563041 19861 solver.cpp:239] Iteration 26020 (9.76546 iter/s, 2.04803s/20 iters), loss = 0.000776712
I0522 11:10:56.563345 19861 solver.cpp:258]     Train net output #0: loss = 0.000776637 (* 1 = 0.000776637 loss)
I0522 11:10:56.563356 19861 sgd_solver.cpp:112] Iteration 26020, lr = 0.0001
I0522 11:10:58.146951 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:10:58.629024 19861 solver.cpp:239] Iteration 26040 (9.68233 iter/s, 2.06562s/20 iters), loss = 0.000141466
I0522 11:10:58.629160 19861 solver.cpp:258]     Train net output #0: loss = 0.000141392 (* 1 = 0.000141392 loss)
I0522 11:10:58.629173 19861 sgd_solver.cpp:112] Iteration 26040, lr = 0.0001
I0522 11:10:58.629668 19861 blocking_queue.cpp:49] Waiting for data
I0522 11:11:02.161953 19861 solver.cpp:239] Iteration 26060 (5.66124 iter/s, 3.5328s/20 iters), loss = 0.00022366
I0522 11:11:02.171562 19861 solver.cpp:258]     Train net output #0: loss = 0.000223586 (* 1 = 0.000223586 loss)
I0522 11:11:02.171571 19861 sgd_solver.cpp:112] Iteration 26060, lr = 0.0001
I0522 11:11:04.272368 19861 solver.cpp:239] Iteration 26080 (9.52022 iter/s, 2.10079s/20 iters), loss = 0.00036809
I0522 11:11:04.281769 19861 solver.cpp:258]     Train net output #0: loss = 0.000368017 (* 1 = 0.000368017 loss)
I0522 11:11:04.281775 19861 sgd_solver.cpp:112] Iteration 26080, lr = 0.0001
I0522 11:11:06.319015 19861 solver.cpp:239] Iteration 26100 (9.81724 iter/s, 2.03723s/20 iters), loss = 0.000599285
I0522 11:11:06.328627 19861 solver.cpp:258]     Train net output #0: loss = 0.000599212 (* 1 = 0.000599212 loss)
I0522 11:11:06.328636 19861 sgd_solver.cpp:112] Iteration 26100, lr = 0.0001
I0522 11:11:08.366634 19861 solver.cpp:239] Iteration 26120 (9.81356 iter/s, 2.038s/20 iters), loss = 0.000254821
I0522 11:11:08.376277 19861 solver.cpp:258]     Train net output #0: loss = 0.000254748 (* 1 = 0.000254748 loss)
I0522 11:11:08.376286 19861 sgd_solver.cpp:112] Iteration 26120, lr = 0.0001
I0522 11:11:11.970508 19861 solver.cpp:239] Iteration 26140 (5.56447 iter/s, 3.59424s/20 iters), loss = 0.000157915
I0522 11:11:11.979693 19861 solver.cpp:258]     Train net output #0: loss = 0.000157842 (* 1 = 0.000157842 loss)
I0522 11:11:11.979707 19861 sgd_solver.cpp:112] Iteration 26140, lr = 0.0001
I0522 11:11:14.349344 19861 solver.cpp:239] Iteration 26160 (8.44011 iter/s, 2.36964s/20 iters), loss = 0.000188218
I0522 11:11:14.358991 19861 solver.cpp:258]     Train net output #0: loss = 0.000188145 (* 1 = 0.000188145 loss)
I0522 11:11:14.359001 19861 sgd_solver.cpp:112] Iteration 26160, lr = 0.0001
I0522 11:11:16.397559 19861 solver.cpp:239] Iteration 26180 (9.81086 iter/s, 2.03856s/20 iters), loss = 0.000427274
I0522 11:11:16.407081 19861 solver.cpp:258]     Train net output #0: loss = 0.000427201 (* 1 = 0.000427201 loss)
I0522 11:11:16.407089 19861 sgd_solver.cpp:112] Iteration 26180, lr = 0.0001
I0522 11:11:17.267396 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:11:18.446974 19861 solver.cpp:239] Iteration 26200 (9.80445 iter/s, 2.03989s/20 iters), loss = 0.000332126
I0522 11:11:18.456672 19861 solver.cpp:258]     Train net output #0: loss = 0.000332053 (* 1 = 0.000332053 loss)
I0522 11:11:18.456681 19861 sgd_solver.cpp:112] Iteration 26200, lr = 0.0001
I0522 11:11:21.591181 19861 solver.cpp:239] Iteration 26220 (6.38058 iter/s, 3.13451s/20 iters), loss = 0.000141823
I0522 11:11:21.600396 19861 solver.cpp:258]     Train net output #0: loss = 0.00014175 (* 1 = 0.00014175 loss)
I0522 11:11:21.600404 19861 sgd_solver.cpp:112] Iteration 26220, lr = 0.0001
I0522 11:11:24.205586 19861 solver.cpp:239] Iteration 26240 (7.677 iter/s, 2.60518s/20 iters), loss = 0.002546
I0522 11:11:24.205677 19861 solver.cpp:258]     Train net output #0: loss = 0.00254593 (* 1 = 0.00254593 loss)
I0522 11:11:24.205682 19861 sgd_solver.cpp:112] Iteration 26240, lr = 0.0001
I0522 11:11:26.395705 19861 solver.cpp:239] Iteration 26260 (9.13235 iter/s, 2.19002s/20 iters), loss = 0.000407497
I0522 11:11:26.395823 19861 solver.cpp:258]     Train net output #0: loss = 0.000407424 (* 1 = 0.000407424 loss)
I0522 11:11:26.395830 19861 sgd_solver.cpp:112] Iteration 26260, lr = 0.0001
I0522 11:11:28.587258 19861 solver.cpp:239] Iteration 26280 (9.12646 iter/s, 2.19143s/20 iters), loss = 7.22866e-05
I0522 11:11:28.587546 19861 solver.cpp:258]     Train net output #0: loss = 7.22136e-05 (* 1 = 7.22136e-05 loss)
I0522 11:11:28.587555 19861 sgd_solver.cpp:112] Iteration 26280, lr = 0.0001
I0522 11:11:30.789484 19861 solver.cpp:239] Iteration 26300 (9.08331 iter/s, 2.20184s/20 iters), loss = 0.000133238
I0522 11:11:30.789943 19861 solver.cpp:258]     Train net output #0: loss = 0.000133166 (* 1 = 0.000133166 loss)
I0522 11:11:30.789979 19861 sgd_solver.cpp:112] Iteration 26300, lr = 0.0001
I0522 11:11:34.196054 19861 solver.cpp:239] Iteration 26320 (5.87173 iter/s, 3.40615s/20 iters), loss = 0.00563829
I0522 11:11:34.196099 19861 solver.cpp:258]     Train net output #0: loss = 0.00563822 (* 1 = 0.00563822 loss)
I0522 11:11:34.196103 19861 sgd_solver.cpp:112] Iteration 26320, lr = 0.0001
I0522 11:11:36.242081 19861 solver.cpp:239] Iteration 26340 (9.77535 iter/s, 2.04596s/20 iters), loss = 0.000438201
I0522 11:11:36.251539 19861 solver.cpp:258]     Train net output #0: loss = 0.000438128 (* 1 = 0.000438128 loss)
I0522 11:11:36.251549 19861 sgd_solver.cpp:112] Iteration 26340, lr = 0.0001
I0522 11:11:36.402541 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:11:38.290613 19861 solver.cpp:239] Iteration 26360 (9.8085 iter/s, 2.03905s/20 iters), loss = 0.000885613
I0522 11:11:38.300143 19861 solver.cpp:258]     Train net output #0: loss = 0.00088554 (* 1 = 0.00088554 loss)
I0522 11:11:38.300155 19861 sgd_solver.cpp:112] Iteration 26360, lr = 0.0001
I0522 11:11:41.343890 19861 solver.cpp:239] Iteration 26380 (6.57086 iter/s, 3.04374s/20 iters), loss = 0.000845673
I0522 11:11:41.352973 19861 solver.cpp:258]     Train net output #0: loss = 0.0008456 (* 1 = 0.0008456 loss)
I0522 11:11:41.352986 19861 sgd_solver.cpp:112] Iteration 26380, lr = 0.0001
I0522 11:11:43.404821 19861 solver.cpp:239] Iteration 26400 (9.74729 iter/s, 2.05185s/20 iters), loss = 0.0018357
I0522 11:11:43.414079 19861 solver.cpp:258]     Train net output #0: loss = 0.00183562 (* 1 = 0.00183562 loss)
I0522 11:11:43.414088 19861 sgd_solver.cpp:112] Iteration 26400, lr = 0.0001
I0522 11:11:45.454409 19861 solver.cpp:239] Iteration 26420 (9.80233 iter/s, 2.04033s/20 iters), loss = 0.000958488
I0522 11:11:45.463639 19861 solver.cpp:258]     Train net output #0: loss = 0.000958414 (* 1 = 0.000958414 loss)
I0522 11:11:45.463649 19861 sgd_solver.cpp:112] Iteration 26420, lr = 0.0001
I0522 11:11:47.509867 19861 solver.cpp:239] Iteration 26440 (9.77409 iter/s, 2.04623s/20 iters), loss = 0.000234893
I0522 11:11:47.519081 19861 solver.cpp:258]     Train net output #0: loss = 0.00023482 (* 1 = 0.00023482 loss)
I0522 11:11:47.519090 19861 sgd_solver.cpp:112] Iteration 26440, lr = 0.0001
I0522 11:11:49.558831 19861 solver.cpp:239] Iteration 26460 (9.80511 iter/s, 2.03975s/20 iters), loss = 0.000516584
I0522 11:11:49.568073 19861 solver.cpp:258]     Train net output #0: loss = 0.00051651 (* 1 = 0.00051651 loss)
I0522 11:11:49.568079 19861 sgd_solver.cpp:112] Iteration 26460, lr = 0.0001
I0522 11:11:51.605710 19861 solver.cpp:239] Iteration 26480 (9.8153 iter/s, 2.03764s/20 iters), loss = 0.000412431
I0522 11:11:51.615192 19861 solver.cpp:258]     Train net output #0: loss = 0.000412357 (* 1 = 0.000412357 loss)
I0522 11:11:51.615201 19861 sgd_solver.cpp:112] Iteration 26480, lr = 0.0001
I0522 11:11:53.121681 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:11:53.664561 19861 solver.cpp:239] Iteration 26500 (9.75919 iter/s, 2.04935s/20 iters), loss = 0.000220822
I0522 11:11:53.664645 19861 solver.cpp:258]     Train net output #0: loss = 0.000220749 (* 1 = 0.000220749 loss)
I0522 11:11:53.664650 19861 sgd_solver.cpp:112] Iteration 26500, lr = 0.0001
I0522 11:11:55.734938 19861 solver.cpp:239] Iteration 26520 (9.66048 iter/s, 2.07029s/20 iters), loss = 0.000249564
I0522 11:11:55.744160 19861 solver.cpp:258]     Train net output #0: loss = 0.00024949 (* 1 = 0.00024949 loss)
I0522 11:11:55.744168 19861 sgd_solver.cpp:112] Iteration 26520, lr = 0.0001
I0522 11:11:57.794610 19861 solver.cpp:239] Iteration 26540 (9.75397 iter/s, 2.05045s/20 iters), loss = 0.000388028
I0522 11:11:57.803970 19861 solver.cpp:258]     Train net output #0: loss = 0.000387954 (* 1 = 0.000387954 loss)
I0522 11:11:57.803977 19861 sgd_solver.cpp:112] Iteration 26540, lr = 0.0001
I0522 11:11:59.847934 19861 solver.cpp:239] Iteration 26560 (9.78491 iter/s, 2.04396s/20 iters), loss = 0.00058395
I0522 11:11:59.848152 19861 solver.cpp:258]     Train net output #0: loss = 0.000583877 (* 1 = 0.000583877 loss)
I0522 11:11:59.848160 19861 sgd_solver.cpp:112] Iteration 26560, lr = 0.0001
I0522 11:12:01.904122 19861 solver.cpp:239] Iteration 26580 (9.7278 iter/s, 2.05596s/20 iters), loss = 0.000660484
I0522 11:12:01.904186 19861 solver.cpp:258]     Train net output #0: loss = 0.000660411 (* 1 = 0.000660411 loss)
I0522 11:12:01.904191 19861 sgd_solver.cpp:112] Iteration 26580, lr = 0.0001
I0522 11:12:03.981441 19861 solver.cpp:239] Iteration 26600 (9.62812 iter/s, 2.07725s/20 iters), loss = 0.000144898
I0522 11:12:03.991451 19861 solver.cpp:258]     Train net output #0: loss = 0.000144825 (* 1 = 0.000144825 loss)
I0522 11:12:03.991457 19861 sgd_solver.cpp:112] Iteration 26600, lr = 0.0001
I0522 11:12:06.053398 19861 solver.cpp:239] Iteration 26620 (9.6996 iter/s, 2.06194s/20 iters), loss = 0.000592975
I0522 11:12:06.062804 19861 solver.cpp:258]     Train net output #0: loss = 0.000592902 (* 1 = 0.000592902 loss)
I0522 11:12:06.062814 19861 sgd_solver.cpp:112] Iteration 26620, lr = 0.0001
I0522 11:12:08.500968 19861 solver.cpp:239] Iteration 26640 (8.20289 iter/s, 2.43817s/20 iters), loss = 0.000830224
I0522 11:12:08.501019 19861 solver.cpp:258]     Train net output #0: loss = 0.00083015 (* 1 = 0.00083015 loss)
I0522 11:12:08.501024 19861 sgd_solver.cpp:112] Iteration 26640, lr = 0.0001
I0522 11:12:09.278873 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:12:10.715277 19861 solver.cpp:239] Iteration 26660 (9.03236 iter/s, 2.21426s/20 iters), loss = 0.000222037
I0522 11:12:10.724406 19861 solver.cpp:258]     Train net output #0: loss = 0.000221964 (* 1 = 0.000221964 loss)
I0522 11:12:10.724416 19861 sgd_solver.cpp:112] Iteration 26660, lr = 0.0001
I0522 11:12:12.785791 19861 solver.cpp:239] Iteration 26680 (9.70227 iter/s, 2.06137s/20 iters), loss = 0.000502397
I0522 11:12:12.795892 19861 solver.cpp:258]     Train net output #0: loss = 0.000502323 (* 1 = 0.000502323 loss)
I0522 11:12:12.795959 19861 sgd_solver.cpp:112] Iteration 26680, lr = 0.0001
I0522 11:12:14.883131 19861 solver.cpp:239] Iteration 26700 (9.58195 iter/s, 2.08726s/20 iters), loss = 0.000765258
I0522 11:12:14.892629 19861 solver.cpp:258]     Train net output #0: loss = 0.000765184 (* 1 = 0.000765184 loss)
I0522 11:12:14.892635 19861 sgd_solver.cpp:112] Iteration 26700, lr = 0.0001
I0522 11:12:17.003319 19861 solver.cpp:239] Iteration 26720 (9.47567 iter/s, 2.11067s/20 iters), loss = 0.000350312
I0522 11:12:17.003407 19861 solver.cpp:258]     Train net output #0: loss = 0.000350238 (* 1 = 0.000350238 loss)
I0522 11:12:17.003410 19861 sgd_solver.cpp:112] Iteration 26720, lr = 0.0001
I0522 11:12:19.134006 19861 solver.cpp:239] Iteration 26740 (9.38702 iter/s, 2.1306s/20 iters), loss = 0.000396946
I0522 11:12:19.134042 19861 solver.cpp:258]     Train net output #0: loss = 0.000396872 (* 1 = 0.000396872 loss)
I0522 11:12:19.134047 19861 sgd_solver.cpp:112] Iteration 26740, lr = 0.0001
I0522 11:12:21.496615 19861 solver.cpp:239] Iteration 26760 (8.46539 iter/s, 2.36256s/20 iters), loss = 0.000127763
I0522 11:12:21.496665 19861 solver.cpp:258]     Train net output #0: loss = 0.000127689 (* 1 = 0.000127689 loss)
I0522 11:12:21.496668 19861 sgd_solver.cpp:112] Iteration 26760, lr = 0.0001
I0522 11:12:23.664623 19861 solver.cpp:239] Iteration 26780 (9.2253 iter/s, 2.16795s/20 iters), loss = 0.000556159
I0522 11:12:23.664678 19861 solver.cpp:258]     Train net output #0: loss = 0.000556085 (* 1 = 0.000556085 loss)
I0522 11:12:23.664681 19861 sgd_solver.cpp:112] Iteration 26780, lr = 0.0001
I0522 11:12:25.814041 19861 solver.cpp:239] Iteration 26800 (9.30511 iter/s, 2.14936s/20 iters), loss = 0.000570428
I0522 11:12:25.814092 19861 solver.cpp:258]     Train net output #0: loss = 0.000570354 (* 1 = 0.000570354 loss)
I0522 11:12:25.814096 19861 sgd_solver.cpp:112] Iteration 26800, lr = 0.0001
I0522 11:12:25.968732 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:12:27.999204 19861 solver.cpp:239] Iteration 26820 (9.15325 iter/s, 2.18502s/20 iters), loss = 0.000126776
I0522 11:12:27.999589 19861 solver.cpp:258]     Train net output #0: loss = 0.000126702 (* 1 = 0.000126702 loss)
I0522 11:12:27.999596 19861 sgd_solver.cpp:112] Iteration 26820, lr = 0.0001
I0522 11:12:30.456622 19861 solver.cpp:239] Iteration 26840 (8.13987 iter/s, 2.45704s/20 iters), loss = 0.000748613
I0522 11:12:30.457037 19861 solver.cpp:258]     Train net output #0: loss = 0.000748539 (* 1 = 0.000748539 loss)
I0522 11:12:30.457042 19861 sgd_solver.cpp:112] Iteration 26840, lr = 0.0001
I0522 11:12:32.641091 19861 solver.cpp:239] Iteration 26860 (9.15732 iter/s, 2.18405s/20 iters), loss = 0.000265643
I0522 11:12:32.641142 19861 solver.cpp:258]     Train net output #0: loss = 0.000265569 (* 1 = 0.000265569 loss)
I0522 11:12:32.641146 19861 sgd_solver.cpp:112] Iteration 26860, lr = 0.0001
I0522 11:12:34.805250 19861 solver.cpp:239] Iteration 26880 (9.2417 iter/s, 2.16411s/20 iters), loss = 0.000189219
I0522 11:12:34.814327 19861 solver.cpp:258]     Train net output #0: loss = 0.000189145 (* 1 = 0.000189145 loss)
I0522 11:12:34.814334 19861 sgd_solver.cpp:112] Iteration 26880, lr = 0.0001
I0522 11:12:37.251554 19861 solver.cpp:239] Iteration 26900 (8.2061 iter/s, 2.43721s/20 iters), loss = 0.000272754
I0522 11:12:37.251641 19861 solver.cpp:258]     Train net output #0: loss = 0.00027268 (* 1 = 0.00027268 loss)
I0522 11:12:37.251644 19861 sgd_solver.cpp:112] Iteration 26900, lr = 0.0001
I0522 11:12:39.394457 19861 solver.cpp:239] Iteration 26920 (9.33356 iter/s, 2.1428s/20 iters), loss = 0.000210125
I0522 11:12:39.407673 19861 solver.cpp:258]     Train net output #0: loss = 0.000210051 (* 1 = 0.000210051 loss)
I0522 11:12:39.407680 19861 sgd_solver.cpp:112] Iteration 26920, lr = 0.0001
I0522 11:12:41.544564 19861 solver.cpp:239] Iteration 26940 (9.35943 iter/s, 2.13688s/20 iters), loss = 0.000204399
I0522 11:12:41.544639 19861 solver.cpp:258]     Train net output #0: loss = 0.000204325 (* 1 = 0.000204325 loss)
I0522 11:12:41.544643 19861 sgd_solver.cpp:112] Iteration 26940, lr = 0.0001
I0522 11:12:43.106962 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:12:43.904958 19861 solver.cpp:239] Iteration 26960 (8.47343 iter/s, 2.36032s/20 iters), loss = 0.00086831
I0522 11:12:43.914078 19861 solver.cpp:258]     Train net output #0: loss = 0.000868236 (* 1 = 0.000868236 loss)
I0522 11:12:43.914085 19861 sgd_solver.cpp:112] Iteration 26960, lr = 0.0001
I0522 11:12:46.049369 19861 solver.cpp:239] Iteration 26980 (9.3665 iter/s, 2.13527s/20 iters), loss = 0.000529106
I0522 11:12:46.049453 19861 solver.cpp:258]     Train net output #0: loss = 0.000529032 (* 1 = 0.000529032 loss)
I0522 11:12:46.049458 19861 sgd_solver.cpp:112] Iteration 26980, lr = 0.0001
I0522 11:12:48.037748 19861 solver.cpp:347] Iteration 27000, Testing net (#0)
I0522 11:12:48.628482 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:12:52.060729 19861 blocking_queue.cpp:49] Waiting for data
I0522 11:12:53.053828 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:12:57.134158 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:13:01.431020 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:13:04.956547 19861 solver.cpp:414]     Test net output #0: accuracy = 0.880463
I0522 11:13:04.956601 19861 solver.cpp:414]     Test net output #1: loss = 0.779701 (* 1 = 0.779701 loss)
I0522 11:13:05.054455 19861 solver.cpp:239] Iteration 27000 (1.05235 iter/s, 19.0051s/20 iters), loss = 0.000339075
I0522 11:13:05.056915 19861 solver.cpp:258]     Train net output #0: loss = 0.000339002 (* 1 = 0.000339002 loss)
I0522 11:13:05.056929 19861 sgd_solver.cpp:112] Iteration 27000, lr = 0.0001
I0522 11:13:07.433638 19861 solver.cpp:239] Iteration 27020 (8.41493 iter/s, 2.37673s/20 iters), loss = 0.000180703
I0522 11:13:07.433667 19861 solver.cpp:258]     Train net output #0: loss = 0.000180629 (* 1 = 0.000180629 loss)
I0522 11:13:07.433671 19861 sgd_solver.cpp:112] Iteration 27020, lr = 0.0001
I0522 11:13:09.594705 19861 solver.cpp:239] Iteration 27040 (9.2548 iter/s, 2.16104s/20 iters), loss = 0.00142907
I0522 11:13:09.605475 19861 solver.cpp:258]     Train net output #0: loss = 0.001429 (* 1 = 0.001429 loss)
I0522 11:13:09.605482 19861 sgd_solver.cpp:112] Iteration 27040, lr = 0.0001
I0522 11:13:11.735110 19861 solver.cpp:239] Iteration 27060 (9.3913 iter/s, 2.12963s/20 iters), loss = 0.000370964
I0522 11:13:11.735148 19861 solver.cpp:258]     Train net output #0: loss = 0.000370891 (* 1 = 0.000370891 loss)
I0522 11:13:11.735152 19861 sgd_solver.cpp:112] Iteration 27060, lr = 0.0001
I0522 11:13:14.161659 19861 solver.cpp:239] Iteration 27080 (8.24231 iter/s, 2.4265s/20 iters), loss = 0.000224188
I0522 11:13:14.161720 19861 solver.cpp:258]     Train net output #0: loss = 0.000224115 (* 1 = 0.000224115 loss)
I0522 11:13:14.161725 19861 sgd_solver.cpp:112] Iteration 27080, lr = 0.0001
I0522 11:13:16.329133 19861 solver.cpp:239] Iteration 27100 (9.2277 iter/s, 2.16739s/20 iters), loss = 0.000197983
I0522 11:13:16.329231 19861 solver.cpp:258]     Train net output #0: loss = 0.00019791 (* 1 = 0.00019791 loss)
I0522 11:13:16.329236 19861 sgd_solver.cpp:112] Iteration 27100, lr = 0.0001
I0522 11:13:17.144608 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:13:18.499475 19861 solver.cpp:239] Iteration 27120 (9.21555 iter/s, 2.17024s/20 iters), loss = 0.00133109
I0522 11:13:18.499526 19861 solver.cpp:258]     Train net output #0: loss = 0.00133101 (* 1 = 0.00133101 loss)
I0522 11:13:18.499529 19861 sgd_solver.cpp:112] Iteration 27120, lr = 0.0001
I0522 11:13:20.858323 19861 solver.cpp:239] Iteration 27140 (8.47897 iter/s, 2.35878s/20 iters), loss = 0.00157029
I0522 11:13:20.858402 19861 solver.cpp:258]     Train net output #0: loss = 0.00157021 (* 1 = 0.00157021 loss)
I0522 11:13:20.858407 19861 sgd_solver.cpp:112] Iteration 27140, lr = 0.0001
I0522 11:13:23.037818 19861 solver.cpp:239] Iteration 27160 (9.17674 iter/s, 2.17942s/20 iters), loss = 0.000220689
I0522 11:13:23.037847 19861 solver.cpp:258]     Train net output #0: loss = 0.000220615 (* 1 = 0.000220615 loss)
I0522 11:13:23.037851 19861 sgd_solver.cpp:112] Iteration 27160, lr = 0.0001
I0522 11:13:25.273625 19861 solver.cpp:239] Iteration 27180 (8.94546 iter/s, 2.23577s/20 iters), loss = 0.000125504
I0522 11:13:25.273675 19861 solver.cpp:258]     Train net output #0: loss = 0.00012543 (* 1 = 0.00012543 loss)
I0522 11:13:25.273679 19861 sgd_solver.cpp:112] Iteration 27180, lr = 0.0001
I0522 11:13:27.575254 19861 solver.cpp:239] Iteration 27200 (8.68975 iter/s, 2.30156s/20 iters), loss = 7.13555e-05
I0522 11:13:27.587927 19861 solver.cpp:258]     Train net output #0: loss = 7.12819e-05 (* 1 = 7.12819e-05 loss)
I0522 11:13:27.587937 19861 sgd_solver.cpp:112] Iteration 27200, lr = 0.0001
I0522 11:13:29.839570 19861 solver.cpp:239] Iteration 27220 (8.8825 iter/s, 2.25162s/20 iters), loss = 0.00164146
I0522 11:13:29.839664 19861 solver.cpp:258]     Train net output #0: loss = 0.00164139 (* 1 = 0.00164139 loss)
I0522 11:13:29.839668 19861 sgd_solver.cpp:112] Iteration 27220, lr = 0.0001
I0522 11:13:31.955070 19861 solver.cpp:239] Iteration 27240 (9.45444 iter/s, 2.11541s/20 iters), loss = 0.000675639
I0522 11:13:31.955257 19861 solver.cpp:258]     Train net output #0: loss = 0.000675565 (* 1 = 0.000675565 loss)
I0522 11:13:31.955261 19861 sgd_solver.cpp:112] Iteration 27240, lr = 0.0001
I0522 11:13:32.330083 19861 blocking_queue.cpp:49] Waiting for data
I0522 11:13:34.103355 19861 solver.cpp:239] Iteration 27260 (9.31058 iter/s, 2.14809s/20 iters), loss = 0.00031268
I0522 11:13:34.103389 19861 solver.cpp:258]     Train net output #0: loss = 0.000312607 (* 1 = 0.000312607 loss)
I0522 11:13:34.103394 19861 sgd_solver.cpp:112] Iteration 27260, lr = 0.0001
I0522 11:13:34.168509 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:13:36.476281 19861 solver.cpp:239] Iteration 27280 (8.42857 iter/s, 2.37288s/20 iters), loss = 0.000232735
I0522 11:13:36.485824 19861 solver.cpp:258]     Train net output #0: loss = 0.000232662 (* 1 = 0.000232662 loss)
I0522 11:13:36.485831 19861 sgd_solver.cpp:112] Iteration 27280, lr = 0.0001
I0522 11:13:38.599720 19861 solver.cpp:239] Iteration 27300 (9.46122 iter/s, 2.11389s/20 iters), loss = 0.000192119
I0522 11:13:38.609202 19861 solver.cpp:258]     Train net output #0: loss = 0.000192047 (* 1 = 0.000192047 loss)
I0522 11:13:38.609210 19861 sgd_solver.cpp:112] Iteration 27300, lr = 0.0001
I0522 11:13:40.730844 19861 solver.cpp:239] Iteration 27320 (9.42663 iter/s, 2.12165s/20 iters), loss = 0.000409508
I0522 11:13:40.730866 19861 solver.cpp:258]     Train net output #0: loss = 0.000409436 (* 1 = 0.000409436 loss)
I0522 11:13:40.730870 19861 sgd_solver.cpp:112] Iteration 27320, lr = 0.0001
I0522 11:13:43.100145 19861 solver.cpp:239] Iteration 27340 (8.44138 iter/s, 2.36928s/20 iters), loss = 0.000715602
I0522 11:13:43.110627 19861 solver.cpp:258]     Train net output #0: loss = 0.00071553 (* 1 = 0.00071553 loss)
I0522 11:13:43.110635 19861 sgd_solver.cpp:112] Iteration 27340, lr = 0.0001
I0522 11:13:45.267328 19861 solver.cpp:239] Iteration 27360 (9.27342 iter/s, 2.1567s/20 iters), loss = 0.00015247
I0522 11:13:45.267364 19861 solver.cpp:258]     Train net output #0: loss = 0.000152398 (* 1 = 0.000152398 loss)
I0522 11:13:45.267369 19861 sgd_solver.cpp:112] Iteration 27360, lr = 0.0001
I0522 11:13:47.389786 19861 solver.cpp:239] Iteration 27380 (9.42319 iter/s, 2.12242s/20 iters), loss = 0.000612869
I0522 11:13:47.389816 19861 solver.cpp:258]     Train net output #0: loss = 0.000612797 (* 1 = 0.000612797 loss)
I0522 11:13:47.389820 19861 sgd_solver.cpp:112] Iteration 27380, lr = 0.0001
I0522 11:13:49.788631 19861 solver.cpp:239] Iteration 27400 (8.33753 iter/s, 2.39879s/20 iters), loss = 0.00173675
I0522 11:13:49.788718 19861 solver.cpp:258]     Train net output #0: loss = 0.00173668 (* 1 = 0.00173668 loss)
I0522 11:13:49.788724 19861 sgd_solver.cpp:112] Iteration 27400, lr = 0.0001
I0522 11:13:51.282974 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:13:51.943437 19861 solver.cpp:239] Iteration 27420 (9.28194 iter/s, 2.15472s/20 iters), loss = 0.000133635
I0522 11:13:51.943478 19861 solver.cpp:258]     Train net output #0: loss = 0.000133563 (* 1 = 0.000133563 loss)
I0522 11:13:51.943482 19861 sgd_solver.cpp:112] Iteration 27420, lr = 0.0001
I0522 11:13:54.060276 19861 solver.cpp:239] Iteration 27440 (9.44827 iter/s, 2.11679s/20 iters), loss = 0.000358982
I0522 11:13:54.060315 19861 solver.cpp:258]     Train net output #0: loss = 0.00035891 (* 1 = 0.00035891 loss)
I0522 11:13:54.060318 19861 sgd_solver.cpp:112] Iteration 27440, lr = 0.0001
I0522 11:13:56.189720 19861 solver.cpp:239] Iteration 27460 (9.39237 iter/s, 2.12939s/20 iters), loss = 0.000188859
I0522 11:13:56.189785 19861 solver.cpp:258]     Train net output #0: loss = 0.000188787 (* 1 = 0.000188787 loss)
I0522 11:13:56.189788 19861 sgd_solver.cpp:112] Iteration 27460, lr = 0.0001
I0522 11:13:58.574664 19861 solver.cpp:239] Iteration 27480 (8.38618 iter/s, 2.38488s/20 iters), loss = 0.000360193
I0522 11:13:58.574717 19861 solver.cpp:258]     Train net output #0: loss = 0.000360121 (* 1 = 0.000360121 loss)
I0522 11:13:58.574720 19861 sgd_solver.cpp:112] Iteration 27480, lr = 0.0001
I0522 11:14:00.710784 19861 solver.cpp:239] Iteration 27500 (9.36301 iter/s, 2.13607s/20 iters), loss = 0.000584409
I0522 11:14:00.720007 19861 solver.cpp:258]     Train net output #0: loss = 0.000584337 (* 1 = 0.000584337 loss)
I0522 11:14:00.720016 19861 sgd_solver.cpp:112] Iteration 27500, lr = 0.0001
I0522 11:14:02.848827 19861 solver.cpp:239] Iteration 27520 (9.39488 iter/s, 2.12882s/20 iters), loss = 0.000373002
I0522 11:14:02.849192 19861 solver.cpp:258]     Train net output #0: loss = 0.00037293 (* 1 = 0.00037293 loss)
I0522 11:14:02.849198 19861 sgd_solver.cpp:112] Iteration 27520, lr = 0.0001
I0522 11:14:05.273099 19861 solver.cpp:239] Iteration 27540 (8.25118 iter/s, 2.4239s/20 iters), loss = 0.000380613
I0522 11:14:05.286531 19861 solver.cpp:258]     Train net output #0: loss = 0.000380541 (* 1 = 0.000380541 loss)
I0522 11:14:05.286540 19861 sgd_solver.cpp:112] Iteration 27540, lr = 0.0001
I0522 11:14:07.423403 19861 solver.cpp:239] Iteration 27560 (9.35945 iter/s, 2.13688s/20 iters), loss = 0.000487247
I0522 11:14:07.423432 19861 solver.cpp:258]     Train net output #0: loss = 0.000487175 (* 1 = 0.000487175 loss)
I0522 11:14:07.423436 19861 sgd_solver.cpp:112] Iteration 27560, lr = 0.0001
I0522 11:14:08.177367 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:14:09.593444 19861 solver.cpp:239] Iteration 27580 (9.21655 iter/s, 2.17001s/20 iters), loss = 0.00118825
I0522 11:14:09.593482 19861 solver.cpp:258]     Train net output #0: loss = 0.00118817 (* 1 = 0.00118817 loss)
I0522 11:14:09.593487 19861 sgd_solver.cpp:112] Iteration 27580, lr = 0.0001
I0522 11:14:11.997126 19861 solver.cpp:239] Iteration 27600 (8.32071 iter/s, 2.40364s/20 iters), loss = 0.0011532
I0522 11:14:11.997171 19861 solver.cpp:258]     Train net output #0: loss = 0.00115313 (* 1 = 0.00115313 loss)
I0522 11:14:11.997175 19861 sgd_solver.cpp:112] Iteration 27600, lr = 0.0001
I0522 11:14:14.213883 19861 solver.cpp:239] Iteration 27620 (9.02234 iter/s, 2.21672s/20 iters), loss = 0.000691254
I0522 11:14:14.213909 19861 solver.cpp:258]     Train net output #0: loss = 0.000691182 (* 1 = 0.000691182 loss)
I0522 11:14:14.213913 19861 sgd_solver.cpp:112] Iteration 27620, lr = 0.0001
I0522 11:14:16.429795 19861 solver.cpp:239] Iteration 27640 (9.02572 iter/s, 2.21589s/20 iters), loss = 0.00290997
I0522 11:14:16.429819 19861 solver.cpp:258]     Train net output #0: loss = 0.00290989 (* 1 = 0.00290989 loss)
I0522 11:14:16.429823 19861 sgd_solver.cpp:112] Iteration 27640, lr = 0.0001
I0522 11:14:18.563385 19861 solver.cpp:239] Iteration 27660 (9.37396 iter/s, 2.13357s/20 iters), loss = 0.000510224
I0522 11:14:18.563413 19861 solver.cpp:258]     Train net output #0: loss = 0.000510152 (* 1 = 0.000510152 loss)
I0522 11:14:18.563417 19861 sgd_solver.cpp:112] Iteration 27660, lr = 0.0001
I0522 11:14:20.928519 19861 solver.cpp:239] Iteration 27680 (8.4563 iter/s, 2.3651s/20 iters), loss = 0.00041253
I0522 11:14:20.937597 19861 solver.cpp:258]     Train net output #0: loss = 0.000412458 (* 1 = 0.000412458 loss)
I0522 11:14:20.937604 19861 sgd_solver.cpp:112] Iteration 27680, lr = 0.0001
I0522 11:14:23.080981 19861 solver.cpp:239] Iteration 27700 (9.33101 iter/s, 2.14339s/20 iters), loss = 0.000106127
I0522 11:14:23.081007 19861 solver.cpp:258]     Train net output #0: loss = 0.000106055 (* 1 = 0.000106055 loss)
I0522 11:14:23.081010 19861 sgd_solver.cpp:112] Iteration 27700, lr = 0.0001
I0522 11:14:25.205826 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:14:25.219907 19861 solver.cpp:239] Iteration 27720 (9.35059 iter/s, 2.1389s/20 iters), loss = 0.000280513
I0522 11:14:25.233420 19861 solver.cpp:258]     Train net output #0: loss = 0.000280441 (* 1 = 0.000280441 loss)
I0522 11:14:25.233428 19861 sgd_solver.cpp:112] Iteration 27720, lr = 0.0001
I0522 11:14:27.507050 19861 solver.cpp:239] Iteration 27740 (8.79653 iter/s, 2.27362s/20 iters), loss = 5.58681e-05
I0522 11:14:27.507105 19861 solver.cpp:258]     Train net output #0: loss = 5.57959e-05 (* 1 = 5.57959e-05 loss)
I0522 11:14:27.507109 19861 sgd_solver.cpp:112] Iteration 27740, lr = 0.0001
I0522 11:14:29.617609 19861 solver.cpp:239] Iteration 27760 (9.47642 iter/s, 2.1105s/20 iters), loss = 0.000126234
I0522 11:14:29.617640 19861 solver.cpp:258]     Train net output #0: loss = 0.000126162 (* 1 = 0.000126162 loss)
I0522 11:14:29.617643 19861 sgd_solver.cpp:112] Iteration 27760, lr = 0.0001
I0522 11:14:31.736131 19861 solver.cpp:239] Iteration 27780 (9.44068 iter/s, 2.11849s/20 iters), loss = 0.000588517
I0522 11:14:31.747805 19861 solver.cpp:258]     Train net output #0: loss = 0.000588445 (* 1 = 0.000588445 loss)
I0522 11:14:31.747812 19861 sgd_solver.cpp:112] Iteration 27780, lr = 0.0001
I0522 11:14:33.873435 19861 solver.cpp:239] Iteration 27800 (9.40901 iter/s, 2.12562s/20 iters), loss = 0.000422784
I0522 11:14:33.887197 19861 solver.cpp:258]     Train net output #0: loss = 0.000422711 (* 1 = 0.000422711 loss)
I0522 11:14:33.887205 19861 sgd_solver.cpp:112] Iteration 27800, lr = 0.0001
I0522 11:14:36.314821 19861 solver.cpp:239] Iteration 27820 (8.23852 iter/s, 2.42762s/20 iters), loss = 0.000632061
I0522 11:14:36.314867 19861 solver.cpp:258]     Train net output #0: loss = 0.000631988 (* 1 = 0.000631988 loss)
I0522 11:14:36.314872 19861 sgd_solver.cpp:112] Iteration 27820, lr = 0.0001
I0522 11:14:38.439802 19861 solver.cpp:239] Iteration 27840 (9.41205 iter/s, 2.12494s/20 iters), loss = 0.000205829
I0522 11:14:38.450031 19861 solver.cpp:258]     Train net output #0: loss = 0.000205757 (* 1 = 0.000205757 loss)
I0522 11:14:38.450038 19861 sgd_solver.cpp:112] Iteration 27840, lr = 0.0001
I0522 11:14:40.569749 19861 solver.cpp:239] Iteration 27860 (9.43521 iter/s, 2.11972s/20 iters), loss = 7.03093e-05
I0522 11:14:40.569797 19861 solver.cpp:258]     Train net output #0: loss = 7.02374e-05 (* 1 = 7.02374e-05 loss)
I0522 11:14:40.569802 19861 sgd_solver.cpp:112] Iteration 27860, lr = 0.0001
I0522 11:14:42.043004 19867 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:14:42.959944 19861 solver.cpp:239] Iteration 27880 (8.3677 iter/s, 2.39014s/20 iters), loss = 0.00083106
I0522 11:14:42.959982 19861 solver.cpp:258]     Train net output #0: loss = 0.000830988 (* 1 = 0.000830988 loss)
I0522 11:14:42.959986 19861 sgd_solver.cpp:112] Iteration 27880, lr = 0.0001
I0522 11:14:45.149974 19861 solver.cpp:239] Iteration 27900 (9.13256 iter/s, 2.18997s/20 iters), loss = 0.000176947
I0522 11:14:45.150055 19861 solver.cpp:258]     Train net output #0: loss = 0.000176875 (* 1 = 0.000176875 loss)
I0522 11:14:45.150060 19861 sgd_solver.cpp:112] Iteration 27900, lr = 0.0001
I0522 11:14:47.306829 19861 solver.cpp:239] Iteration 27920 (9.27308 iter/s, 2.15678s/20 iters), loss = 0.00165049
I0522 11:14:47.319979 19861 solver.cpp:258]     Train net output #0: loss = 0.00165042 (* 1 = 0.00165042 loss)
I0522 11:14:47.319993 19861 sgd_solver.cpp:112] Iteration 27920, lr = 0.0001
I0522 11:14:49.669623 19861 solver.cpp:239] Iteration 27940 (8.51189 iter/s, 2.34965s/20 iters), loss = 0.000213398
I0522 11:14:49.678704 19861 solver.cpp:258]     Train net output #0: loss = 0.000213325 (* 1 = 0.000213325 loss)
I0522 11:14:49.678711 19861 sgd_solver.cpp:112] Iteration 27940, lr = 0.0001
I0522 11:14:51.783815 19861 solver.cpp:239] Iteration 27960 (9.5007 iter/s, 2.10511s/20 iters), loss = 0.000860287
I0522 11:14:51.797106 19861 solver.cpp:258]     Train net output #0: loss = 0.000860215 (* 1 = 0.000860215 loss)
I0522 11:14:51.797114 19861 sgd_solver.cpp:112] Iteration 27960, lr = 0.0001
I0522 11:14:53.900358 19861 solver.cpp:239] Iteration 27980 (9.5091 iter/s, 2.10325s/20 iters), loss = 0.000352952
I0522 11:14:53.900414 19861 solver.cpp:258]     Train net output #0: loss = 0.00035288 (* 1 = 0.00035288 loss)
I0522 11:14:53.900419 19861 sgd_solver.cpp:112] Iteration 27980, lr = 0.0001
I0522 11:14:55.884501 19861 solver.cpp:347] Iteration 28000, Testing net (#0)
I0522 11:14:56.637744 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:15:00.973244 19870 data_layer.cpp:73] Restarting data prefetching from start.
I0522 11:15:01.450150 19861 blocking_queue.cpp:49] Waiting for data
